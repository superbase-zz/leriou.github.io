[{"title":"对云服务和中间件的思考","url":"/2019-09-17-consider-for-tech/","content":"最近的一年多的时间我们的项目和服务都是使用的阿里云\n\n主要包括机器资源，容器服务和中间件服务，随着这段时间的使用，我有了点自己对云服务的想法想跟大家分享一下\n\n<!-- more -->\n\n# 云服务\n\n## 啥是云服务\n\n想聊云服务就需要先知道啥是云服务，简单的来讲**云服务就是你租借别人的机器，通过网络来自由使用这些机器** \n\n1. 机器是别人的，你只是租用\n2. 机器不在你这，你通过网络来进行操作\n\n早期的云服务提供商都是直接提供机器给你使用，你只要说你租几台什么配置的机器，用多久\n\n你可以自己在机器上搭建服务，配置，存储数据等\n\n后来云服务厂商帮你做的事情越来越多，开始帮你直接搭建服务，帮你存储数据，甚至帮你提供模式化业务的解决方案 \n\n这样一来就能更多的挣你的钱\n\n## 云服务的优势\n\n* 成本优势：按需分配\n* 快速搭建：云服务不需要企业自己搭建\n* 运维方便：弹性伸缩\n* 安全管理：统一的安全保障权限管理等\n\n这些都是云服务的优势，针对中小型企业真的很有吸引力\n\n当企业在初创的时候更多的应该关心如何快速的构建一套完整的业务系统出来， 这个时候怎么快就怎么来是最好的\n\n等到企业到了一定的规模以后，在考虑后续的数据隐私，业务定制化等特殊需求， 这个时候也可以选择自己构建服务， 但是以我个人经验\n\n现在的云服务也越来越高度定制化了，或许以后能完美的满足企业个性化需求也说不定\n\n当前的各种服务框架无一不是在朝着云服务的方向努力\n\n# 中间件的发展\n\n中间件一直是软件开发的中流砥柱\n\n近几年各种中间件和数据平台都发展的异常的快\n\n存储方面有TiDB和OceanBase， 消息中间件上又有pulsar这种新型消息中间件\n\n但是这些服务跟云原生环境的对接还没有做到无缝\n\n我觉得未来一段时间中间件服务的云化是一个很有前途的方向\n\n研究如何将中间件上云，如何支持多租户等\n\n# 大数据和人工智能的衰落\n\n最近一段时间有点感觉大数据和人工智能不太行了\n\n一个是大数据公司的衰落\n\n一个是深度学习方面算法方面遇到了瓶颈\n\n我觉得过去16-18年这段时间的深度学习的发展很大程度上是由于数据量和计算力的爆发和算法方面的进步三方面带来的\n\n但是当前的数据量和计算力也到达了一个瓶颈，算法方面又未有太大的突破\n\n我觉得现在这个情况搞深度学习研究倒不如搞算法的落地和产业化，先把过去的算法和模型好好的充分利用起来\n\n（未完待续）","categories":["中间件"],"tags":["思考"]},{"title":"排行榜系统设计","url":"/2019-06-01-recommended-system-ranking-system-md/","content":"\n# 为啥需要排行榜\n\n推荐系统有一个避不开的问题就是冷启动问题\n\n也就是新用户第一次进入应用的推荐，此时我们没有任何的用户行为信息， 无法根据用户行为进行推荐， 用户基础信息的推荐也极有可能没有构建完成\n\n此时就需要一种针对所有用户通用的推荐策略，防止推荐系统出现“开天窗” \n\n<!-- more -->\n\n我们一般使用以下策略来处理冷启动问题\n1. 最新内容\n2. 最火内容\n3. 实时基于用户属性进行分群，基于用户群进行推荐（比如，上海地区用户，女性用户，30-40岁用户）\n\n其中的最火内容就需要排行榜系统的支持\n\n# 排行榜系统\n\n排行榜系统一般有两种， 一种是类似于“本月最火歌曲排行”一种是“最近30天最火歌曲排行”\n\n## 固定时间范围的排行榜\n\n> 需求：统计本月播放次数最多的歌曲\n\n针对“本月最火歌曲”这种需求的排行榜，处理起来相对简单\n\n只要统计从本月有1号到现在的所有歌曲的播放数据就可以了，如果数据量不大且要求不高，可以定时每一段时间计算一次\n\n如果实时性要求较高， 也可以使用实时增量统计的方式，同时每天处理一次批量统计，做数据矫正\n\n具体就是每天计算一个排行榜之后， 使用流处理系统，当有新的播放事件，在榜单现有基础上做incr操作即可\n\n这种排行榜相对来说实现比较简单， 缺点也很明显\n\n比如今天如果是本月的1号， 那你的排行榜数据就由于样本数据有限，误差较大，无法起到排行榜真正的作用\n\n处理这种问题就需要“最近30天最火的歌曲”这种滚动排行榜\n\n## 滚动排行榜\n\n滚动排行榜是指基于最近一段时间范围的数据获得的排行榜统计结果  \n\n拿最近3天排行榜为例， 假设现在是是10号的10点钟， 那滚动排行榜覆盖的区间就是前推3天的数据  \n\n`7号从10点以后的数据 + 8，9号全天数据 + 10号截至目前的数据 的统计结果`\n\n滚动排行榜相对来说难度增加了很多\n\n如果数据量不大，对实时性要求不高的话， 也可以采用每一段时间计算一次最近3天的播放量的批量的方式\n\n但是如果数据量较大或者对实时性有要求较高，那就需要设计一个实时的滚动排行榜\n\n### 实时的滚动排行榜\n\n假如我要做3天的滚动歌曲榜单， 我就需要获取最近72小时的播放记录进行统计\n\n拿数据举例来说\n\n假设有如下的播放记录, 当前日期是 2019-04-04 13:00， 排行榜统计区间应该是 `04-01 13:00 ～ 04-04 13:00`  \n\n| 歌曲id | 播放时间          |\n| ------ | ----------------- |\n| 1009   | 2019-04-01  9:00  |\n| 1010   | 2019-04-01 14:00  |\n| 1020   | 2019-04-02  8:00  |\n| 1089   | 2019-04-03 10:00 |\n| 1010   | 2019-04-04  9:00 |\n| 1023   | 2019-04-04 12:00 |\n\n那我们获取到的3天榜单应该是这样(1009的播放记录已经过期)\n\n```\n//  歌曲id:播放次数\n{\n     1023:1,\n     1010:2，\n     1089:1，\n     1020:1\n}\n```\n\n排行榜处理过程最关键的有两点\n\n1. 对一个元素加分时，加当日周期榜、滚动榜；\n还需根据其在今日滚动榜中的分数s、及n-1天日榜中的分数r，计算出其在明日滚动榜中的初始分数s-r写入明日滚动榜中；\n即3个写操作；\n\n2. 如果一个元素在当日没有任何加分操作，那么不会触发写入初始分数操作，所以还需要一个离线工具补齐。\n该离线工具可提前一天运行，即当日运行离线工具补齐次日的滚动榜数据即可。\n\n\nR：每日的统计数据  S： 每日的滚动排行榜数据\n\ns-r > 0 才进行写入操作\n\n```\n以3天滚动榜为例，次日滚动榜初始态为当日滚动榜减去n-2天的日榜数据。\n     +-------------------------------------------+\n     |                                           |\n+----+---+   +--------+   +--------+             |\n| R(i-2) |   | R(i-1) |   |  R(i)  |             |\n+----+---+   +----+---+   +---+----+             |\n     |            |           |                  |\n     |            |           v+                 v-\n     |            |\n     |            |    +  +--------+        +--------+\n     |            +-----> |        |     +  |        |\n     |                 +  |  S(i)  | +---+> | S(i+1) |\n     +-----------------+> |        |        |        |\n                          +--------+        +--------+\n\n分数变化\n                                +--------------+\n                                |   AddScore   |\n                                +-+----+-----+-+\n                                  |+   |     |\n                                  v    |     |\n+--------+   +--------+   +--------+   |     |+\n| R(i-2) |   | R(i-1) |   |  R(i)  |   |     |\n+--------+   +--------+   +--------+   |     |\n                                       |     v\n                          +--------+   |    +--------+\n                          |  S(i)  |<--+    | S(i+1) |\n                          +--------+        +--------+\n                                                 ^\n                                                 |+\n                                          +------------+\n                                          |    Tool    |\n                                          +------------+\n```\n\n","categories":["推荐系统"],"tags":["推荐系统"]},{"title":"如何设计一个海量数据过滤模块","url":"/2019-04-01-recommended-system-filter-module-md/","content":"# 背景\n\n所有的推荐系统都有一个基本的要求：`不给用户推荐重复的信息`\n\n这里的重复的信息有两层含义  \n\n1. 这个信息是id完全相同的一条信息\n    这个很好理解，就是一模一样的两条信息，从数据库的角度将就是信息记录的主键id都相同\n    如果用户已经接受过一次id为10086的信息的推荐，那这个10086就不能出现在后续的同类推荐中\n\n2. 这两个个信息相似度很高，但是id不同\n    这种情况出现于两条信息内容相似，比如有两篇文章10001，10002都在说特朗普要在美国边境造墙的事情\n    那如果用户观看过10001，此时再给用户推荐10002，就可能会让用户觉得推荐的东西已经看到过了，毫无意义\n\n# 处理相同id的过滤\n\n我们的目的是给定一个id, 和一个已推荐集合，判断id是否在给定的集合以内\n\n## HashMap的方案\n\n如果集合数据量比较少的情况下，我们可以使用Java中的`HashSet`存储集合， 使用contains来直接判断id是否在给定集合中，其他编程语言中也都有类似`HashSet`的数据结构\n\n由于`HashSet`的底层原理是使用的`HashMap`， 所以我直接使用 `HashMap`来进行原理的说明\n\n这种做法的原理其实是先将我们要查找的数据进行hash散列，映射到一个固定长度的地址空间  \n然后使用数组存储，如果有多个id经过hash映射到相同的地址空间那就做一个链表，存储相同hashcode对应的值   \n\n具体结构如下：\n\n```\n|0|1009|0|1008|1998|\n    ↓           ↓ \n    107         87\n    ↓            \n    16\n```\n\n当我们查找id时， 也是先将要查找的id进行hash, 然后去对应的hashcode位置沿着链表/红黑树寻找是否有要查找的数字\n\n### 优点  \n\n1. 使用简单，比较通用\n2. 容易理解\n3. 无误判\n\n### 缺点\n1. 空间利用率太低\n\n## Bitmap\n\n考虑到`HashMap`的空间利用率太低，不适合海量数据的存储\n\n我们可以利用计算机存储的一些特性，用另外一种方式来\n\n我们都知道计算机底层是用bit来存储信息的，每个bit能存储一个0或者1的信息\n\n如果我们使用二进制bit的位置信息来表示数字，对应位的bit值是1来代表这个数字存在，我们就可以在极小的空间存储大量的信息\n\n使用时只需使用位运算，查看对应位置的bit值即可\n\nJava中的bitset，redis中的bit操作都提供了这种bitmap的实现\n\nbitmap的详情可以查看 [使用bitmap构建用户标签](https://leriou.github.io/2017-12-29-user-tag-sys-on-bitmap/)\n\n如下表示 【6，4，3】的集合 \n\n```\nbit值     0 1 0 1 1 0 0 0\n位        7 6 5 4 3 2 1 0\n```\n\n### 优点 \n1. 空间利用率高\n2. 性能好\n3. 无误判\n\n### 缺点\n1. 不够通用，要求数据的类型必须是数字且元素范围跨度不能太大\n\n## BloomFilter\n\nbloomfilter跟bitmap具有相似的原理， 都是使用位来存储信息，区别在于\n\nbitmap使用元素自身数字对应的位置信息来存储数据，如果要存储的元素是个字符串或者其他类型的数据就无法使用这种方式了，或者你要存储的数字范围特别的大，比如你要存储一个100亿的数字， 那样即使只有一个数字你也需要一个前面的位置都是0的100亿bit来表示，对空间的利用率还是不高 (现在有一些空间压缩的bitmap实现能一定程度解决数据范围分布过大和分布稀疏的问题)\n\nBloomFilter就是针对这些做了优化，如果我们把要处理的数字进行hash, 映射到一个固定长度的地址空间\n\n这样就同时解决了以上两个问题， 即缩减了映射的空间范围，又可以存储更通用的对象\n\n但是由于hash函数本身会有冲突，就会出现两个不同元素因为同样的hashcode而产生误判的情况\n\n处理这种情况的方法就是增加hash函数的数量， 假设两个元素使用一个函数冲突的概率是 0.01， 那如果我们使用3个不同的函数，每个函数足够均匀且误判率相同，对这两个元素进行hash, 那两个元素经过三个函数依然冲突的概率就是 0.000001， 但是基于概率的问题，误判率依然存在\n\n所以这种方法适合于允许一定误判率，并拥有海量数据要过滤的场景\n\n### 优点\n\n1. 通用\n2. 空间效率高\n3. 灵活，可以在性能和误判率之间做取舍\n\n### 缺点\n\n1. 有误判\n\n# 处理相似文本的重复\n\n能处理相同的id造成的重复之后，如果我们可以找出一个文章的相似内容， 只要把相似的内容id也添加到需要过滤的集合， 就可以完成对相似内容的过滤\n\n## simhash\n\n如果只是检测一模一样的两个字符串，那我们完全可以采用md5之类的摘要算法， 但是这种方法对文章内容又哪怕一个字的差别，就不再适用\n\n所以我们使用`simhash`来处理内容相似度的问题\n\nsimhash的核心思想是先提取文章的最重要核心特征， 如果两篇文章的核心特征重复度较高，那就是相似文章\n\n步骤如下\n\n1. 我们先对文本进行分词，并计算每个词的权重\n2. 对每个词进行hash，并把hash结果的对应二进制位的 0 变为 -1\n3. 把每个文章的每个词的处理过的hash值 * 权重，得到加权向量，并把每个加权向量相加得到最终向量\n4. 把这个最终向量中的负数变为0，正数变为1\n\n然后通过汉明距离比较二进制位不同的个数，其实就是计算两个指纹的异或结果，结果中如果包含较少的1， 比如小于3个， 那就说明内容相同\n","categories":["推荐系统"],"tags":["推荐系统"]},{"title":"浅谈推荐系统","url":"/2019-03-01-recommended-system-overview-md/","content":"\n**本文不打算讨论任何有关推荐系统的技术原理，技术类的文章会再其他几篇博文中讨论**\n\n# 什么是推荐系统\n\n到了2019年， `推荐系统`这个词已经被大多数人所知悉了   \n尤其是随着近几年头条，抖音这种几乎完全依靠机器学习的推荐算法崛起的互联网产品的大火， 导致大家对推荐系统的关注度进一步提高    \n那到底什么是推荐系统？\n\n> 推荐系统简单的说就是一种主动的信息搜索引擎  \n\n要解释这句话，得先了解搜索引擎\n\n## 搜索引擎\n\n早期互联网时代(90年代)，信息量爆发， 在当时的场景下出现了`搜索引擎`这种产品  \n并催生出了雅虎，谷歌，百度等一大批以搜索为核心服务的公司\n\n这个时期由于早期的互联网人群特征和信息传播成本的限制，信息总量相对较少，信息平均质量相对较高  \n用户使用搜索引擎，很容易通过几个关键字就找到自己想要的东西  \n\n到了20世纪初，随着计算机技术的发展和谷歌的三驾马车论文的发布，我们进入了一个叫“大数据”的时代  \n而在这个阶段，由于信息量的指数级增长，互联网普及到普通民众，互联网上的信息数量开始爆发，信息的平均质量也开始下降  \n\n各种搜索引擎开始出现一种情况，就是我们输入关键字以后，不是那么容易找到我们需要的信息了，往往会出现前几条都是广告的情况  \n换句话说，大家通过搜索引擎获取有效信息的成本增加了  \n\n## 现代搜索引擎\n\n出现这种情况的原因就是人们早期的搜索习惯是只使用关键字来进行搜索，等于说给搜索引擎的条件依然和90年代相同，但是可被搜索的内容相对90年代却增加了几千万倍 导致搜索引擎的搜索准确降低了\n\n后来搜索引擎厂商开始通过自发的收集用户的一些习惯和属性，比如地理位置，搜索时间，浏览记录等，帮助引擎提高搜索的准确度 \n这其实就是偷偷的替用户增加搜索条件 \n\n而这， 就是推荐系统的原型  \n**推荐系统就是给机器使用的无需人为触发的搜索引擎** \n\n如果搜索引擎可以通过学习你的习惯预测到你有可能搜索的关键词  \n比如你买了婴儿奶粉之后， 搜索引擎觉得你接下来可能会搜索尿布，那就可以帮你先搜索好尿布相关的信息 \n\n这时的搜索引擎就是推荐引擎\n\n# 推荐系统的要素  \n## 主动发现和展示信息  \n推荐系统和搜索引擎的主要区别在于两点\n1. 推荐系统的信息展示是主动式的， 搜索引擎是被动式了\n2. 推荐系统的真正的用户是业务方系统，搜索引擎的用户有可能是用户也有可能是广告商\n\n作为推荐系统， 一定要有主动发现信息的能力， 因为推荐的基础是搜索，搜索就必须有足够的持续不断的新信息流   \n而到目前为止这个主动发现信息的手段一般都是爬虫  \n现在其实已经出现了一种新型的信息产生手段--通过机器学习制作的知识图谱，不过目前的用户还不够广泛  \n\n推荐系统同时需要具有主动展示信息的能力  \n如果推荐系统不能主动展示用户可能感兴趣的信息，那不如叫一个留言板系统 \n\n## 个性化\n\n推荐系统既然要主动展示， 信息的量那么大，那到底展示些什么信息呢\n\n最近很多公司喜欢用一个时髦的词叫“个性化”或“千人千面”来标榜自己的推荐产品  \n意思就是每个用户看到的都是不一样的东西，我们是根据用户的习惯推荐的最符合你的产品 \n就好像个性化对于用户来说一定是好事一样  \n虽然很多的推荐系统都是个性化的， 其实个性化跟推荐系统本身没太大关系，不用推荐系统也可以个性化，用了推荐系统也不一定个性化\n\n不过一般来说，针对用户的不同，进行不同的展示，确实会起到一定的提升用户体验的作用\n\n你如果因为小米新手机开发布会即将召开就给一个华为的粉丝疯狂推荐小米发布会相关的内容， 我觉得系统可能会在1/3秒后就再也没有给这个用户推送内容的机会了 \n\n所以我们个性化推荐的目的有时候不一定是推荐喜好， 过滤不喜欢的也是推荐系统的职责\n\n# 推荐系统的优点\n\n## 对用户传达的信息效率更高\n\n推荐系统由于可以主动给用户展示信息， 相对而言比搜索系统展示信息的效率要高  \n展示信息的及时性也能得到保证， 毕竟用户如果不用搜索框你就告诉用户XXX和XXX离婚了，用户可能会觉得你这个搜索功能是不是坏掉了  \n\n但是如果你通过信息流进行推荐， 用户可能就会觉得你这个软件做的不错，新信息更新的很及时\n\n## 可能会提升用户体验\n\n我上文说过， 用户在获取信息的时候对信息大致是三种偏好， 1 喜欢，2 无感，3 厌恶\n\n搜索引擎很难通过用户输入的关键词来区分用户对信息的三种偏好， 用户输入了手机， 你不可能知道用户喜欢华为手机还是讨厌小米手机\n\n但是推荐就不同了，推荐系统一般是根据用户行为或者其他的社会热点，能一定程度预判用户对某元素的情感倾向 \n\n进而在展示信息时尽可能的避开用户不喜欢的雷区，推荐用户喜欢的内容\n\n## 更方便广告投放\n\n由于搜索引擎是被动式的，厂商不得不在用户输入搜索时进行广告展示，因为没有别的触发手段\n\n但是用户一般使用搜索引擎都是怀有明确目的的， 你此时如果投放的广告不合场景或者质量不高不够吸引人\n\n用户根本没有时间去浏览广告，更别提点击\n\n搜索引擎广告展示占用的是用户的主动动作时间，从情感上用户可能会觉得被广告厂商浪费了我宝贵的时间 \n\n但是推荐系统一般是用户使用产品的时间，广告可展示的时间范围更大，不容易引起用户反感\n\n# 推荐系统带来的隐忧\n\n## 隐私数据问题\n\n上文说了，推荐系统的本质是系统通过收集和分析用户行为或社会热点信息\n\n由系统通过分析产生的关键词，主动帮用户进行搜索， 这必然会涉及到用户的隐私行为信息收集  \n\n用户观看了什么，用户购买了什么，用户喜欢什么，用户做了什么  \n\n这些行为的价值有高有低， 但是一般厂商都会不分价值先全部搜集过来再说，这个信息搜集的边界很难把控\n\n搜集过来的信息到底用语什么用途也不好保证，说不好就越界了  \n\n现在也有越来越多的人反对厂商随意搜集用户信息，哪怕这有助于提升用户体验\n\n好在目前国内用户对隐私问题不是很在乎，所以这其实是国内在推荐领域弯道超车的一个大优势\n\n##  羊群效应和马太效应\n\n推荐系统的目的是尽可能的吸引用户， 落实到数据就是尽可能的提升用户点击率和留存\n\n那不可避免的就要推荐用户感兴趣的东西， 用户喜欢什么我们就推荐什么，我们推荐的同类内容越多用户可能会更喜欢这一类内容， 如此就形成一个循环，但是这样也会导致用户接触的信息范围越来越窄 \n\n这样一个很明显的效果就是某信息被人观看的越多， 热度就越高，说明大家都喜欢，就越容易被推荐给更多的人，就能获得更多的曝光次数，这样随着曝光次数的增加，该信息的热度就会更高，获取更多的曝光次数，形成一个循环\n\n最近的推荐系统领域都提倡给予用户一个惊喜度的评价指标就是推荐一些非用户固有的习惯，帮助用户探索新事物\n\n# 总结\n\n推荐系统其实就是一种特殊的搜索引擎\n\n不过是通过对更多的客观信息和用户行为信息的分析来对搜索条件进行补全，以获得更准确的搜索结果\n\n所以推荐系统的核心在于数据的分析和构建\n\n如何获得更准确的用户兴趣分析，同时如何在用户体验和用户隐私中做平衡是推荐系统永远的议题 \n\n自古以来，方便和安全就不可兼得 \n\n我们能做的就是在合适的场景，进行合适的选择","categories":["推荐系统"],"tags":["推荐系统"]},{"title":"MongoDB和Elasticsearch的对比","url":"/2019-01-09-mongodb-compareto-elasticsearch/","content":"# MongoDB  vs Elasticsearch\n\n|               |       MongoDB        |   ElasticSearch    | 备注                                                         |\n| :------------: | :------------------: | :----------------: | ------------------------------------------------------------ |\n|      定位      |    (文档型)数据库    |  (文档型)搜索引擎  | 一个管理数据,一个检索数据                                    |\n|    资源占用    |         一般         |         高         | mongo使用c++, es使用Java开发                                 |\n|    写入延迟    |          低          |         高         | es的写入延迟默认1s, 可配置, 但是要牺牲一些东西               |\n| 全文索引支持度 |         一般         |       非常好       | es本来就是搜索引擎, 这个没啥可比性                           |\n|   有无Schema   |          无          |         无         | 两者都是无Schema                                             |\n|  支持的数据量  |         PB+          |     TB+  ~ PB      | 两者支持的量并不好说的太死, 都支持分片和横向扩展, 但是相对来说MongoDB的数据量支持要更大一点 |\n|      性能      |        非常好        |         好         | MongoDB在大部分场景性能比es强的多得多                        |\n| 索引结构 | B树 | LSM树 | es追求写入吞吐量, MongoDB读写比较均衡 |\n|    操作接口    |         TCP          |   Restful(Http)    |                                                              |\n|  是否支持分片  |          是          |         是         |                                                              |\n|  是否支持副本  |          是          |         是         |                                                              |\n|    选主算法    |     Bully(霸凌)      |    Bully(霸凌)     | 相比于Paxos和Raft算法实现更简单并有一定的妥协                |\n|    扩展难度    |         容易         |      非常容易      | es真的是我用过的扩展最方便的存储系统之一                     |\n|    配置难度    |          难          |      非常容易      |                                                              |\n|    地理位置    |         支持         |        支持        |                                                              |\n|    运维工具    |         丰富         |        一般        |                                                              |\n|   插件和引擎   | 有多个存储引擎供选择 | 有大量插件可以使用 |                          -|\n\n# 两者的定位\n\n`MongoDB`和`Elasticsearch`都属于NoSQL大家族, 且都属于文档型数据存储\n\n所以这两者的很多功能和特性高度重合, 但其实两者定位完全不同     \n\n\nMongoDB 是 **文档型数据库**,  提供 **数据存储和管理服务**\nElasticsearch 是**搜索服务**, 提供 **数据检索服务**\n\n两者的很大区别在于源数据的存储和管理\n\n* MongoDB作为一个数据库产品, 是拥有源数据管理能力的     \n* Elasticsearch作为一个搜索引擎, 定位是**提供数据检索服务**, 也就是说我只管查, 不管写 ^_^, Elasticsearch的Mapping不可变也是为此服务的, 带来的代价就是` es不适合作为数据管理者`, es可以从其他数据源同步数据过来提供查询, 但是不适合自己对数据进行存储和管理 \n\nes更侧重数据的查询, 各种复杂的花式查询支持的很好, 相比来说 MongoDB的查询能力就显得比较平庸了\n\n由此可见, 对于个人, 如果你有一批数据要看, 但是不经常进行修改, 这个时候毫无疑问可以用es, 但是如果你还打算继续修改数据, 最好就是使用MongoDB，但其实对大多数人公司来讲，这两者的数据管理能力并没有多大的影响\n\n> ps: es修改Mapping的代价非常高, 所以我们一般都是把新数据重新写入一份新索引，然后直接切换读取的别名到新的索引\n\n# 两者读写数据的异同\n\n`MongoDB`和`ElasticSearch`都支持全文索引, 虽然MongoDB的全文索引效果完全无法跟es相比(es毕竟是专业的搜索引擎产品, 着重提供数据的检所支持, 这方面吊打MongoDB也是可以理解的)\n\nMongoDB虽然在支持的部分查询功能上稍微弱于es, 但是在大部分场景下性能方面完爆es, 不管是读性能, 还是写性能\n\nes的写入延迟默认为1s, 这个虽然是写入延迟的范畴, 但是毫无疑问是一大缺点, 虽然可以配置为更短的时间, 但是这样就要牺牲一定的数据吞吐量, 会造成更频繁的磁盘刷新操作\n\nes底层使用`Lucene`作为核心引擎, 很多es的设计就是为了匹配Lucene中的概念, 其实es可以看成一个lucene的proxy层包装,将lucene的原生接口封装的更好用, 同时还实现了很多管理和监控等辅助功能, 但是整体来说es上层的模块和lucene的隔阂还是挺明显的, 耦合度上有一定的欠缺\n\nMongoDB则是完整的一个单体数据库产品, 虽然内部的存储引擎也是可插拔式的, 整体而言还是更加的浑然一体\n\n> MongoDB支持多种存储引擎, 本文所有涉及mongo存储引擎的只谈默认的WiredTiger引擎, 其实还有某些方面更优秀的其他引擎,例如: MongoRocks等\n\n# 部署和资源占用\n\n单机部署的话其实MongoDB和Elasticsearch都十分的方便, 不过es相对来说资源占用更多一点, 性能也比MongoDB要弱一点\n\n集群化的部署, 我们一般都会选择分片+副本的部署方式, 这种方式下, es部署起来比MongoDB方便太多, MongoDB要部署一套完整的分片 + 副本模式还是比较麻烦的, 没有经验的人部署起来需要一定的学习成本    \n\n资源占用方面, MongoDB可以支持存储文件类型的数据, 作为数据库也有数据压缩能力, es则因为大量的索引存在需要占用大量的磁盘和内存空间\n\n# 可用性和容错\n\nMongoDB和ElasticSearch作为天生分布式的代表产品都支持数据分片和副本   \n\n两者都通过分片支持水平扩展, 同时都通过副本来支持高可用(HA) \n\n分片就是一个数据集的数据分为多份, 同时分布在多个节点上存储和管理, 主流分片方式有两种: hash分片和range分片, 两种分片方式各有优势, 适合不同的场景\n\n副本就是一份数据集同时有一个或者多个复制品(有些地方叫主从), 每份复制品都一模一样, 但是为了保证数据的一致性, 往往多个副本中只有一个作为Primary副本(通过选主算法从多个副本中选出Primary), 提供写服务, 其他副本只提供读, 或者只提供备份服务\n\n> ps:es和MongoDB都可以通过副本增强读能力, 这与kafka很不一样(kafka的副本只有备份功能)\n\n## 两者分布式方案的一些不同\n\nMongoDB和Elasticsearch虽然都是分布式服务, 但是还是有一些不同方案的选择的\n\n* 分片和副本单位的划分\n\nMongoDB是以节点为单位划分角色, 一旦一个节点被指定为副本, 其上面的数据都是副本\n\nElasticsearch是以分片为单位划分角色, 一个节点上即可以拥有某分片的主分片和可以同时拥有另一个分片的副本分片, 同时es还支持自动的副本负载均衡, 如果一个新节点上面什么数据都没有, 系统会自动分配分片数据过来 \n\n* 架构模式\n\nMongoDB的副本和分片是两种不同的模式, 虽然可以同时使用但是依然有各自的架构设计, 用户可以任意选择选型进行搭配, 每个节点的职责更加专一, 方便据此调整机器配置和进行优化\n\nElasticsearch中的分片 + 副本是一套统一的架构设计, 每个节点具有接近同等的地位, 配置使用起来更加简单, 但是如果要针对节点所负责的功能对机器进一步做定制就不如MongoDB灵活\n\n# 文档型数据库的特点和问题\n\n## 无schema\n\n文档型数据存储既能享受无schema限制带来的灵活, 又能享受索引查询的快速和类SQL查询的便捷\n\n使他们用起来不像传统的RDBMS那么麻烦, 又不像 Redis,Hbase这种数据库查询功能不够强大, 处在一个传统RDBMS和经典K-V存储之间的比较均衡的位置\n\n我个人很喜欢这个特性, 没有schema的限制, 存储数据更方便也更灵活了, 但是有得有失, 很多固定schema的好处就无法享受到了, 比如: 对数据的高效压缩\n\n## 鸡肋的Collection 和 Type\n\n早期为了跟传统rdbms数据库保持概念一致 ，mongodb和elasticsearch都设计了跟传统数据库里面的`库->表->记录行`对应的概念，具体如下\n\n|RDBMS|MongoDB|Elasticsearch|\n|-|-|-|\n|库|库|索引\n|表|集合|类型|\n|记录|文档|文档|\n\n其实对于nosql数据库来讲, 集合/类型的意义其实不大, Nosql数据库几乎都是k-v类型的存储结构，完全可以通过key进行业务隔离和区分，真的没有必要为了跟传统数据库对应强行搞出来一个中间概念 ^_^\n\nElasticsearch从`6.x`版本开始强制只允许一个索引使用一个type, 其实就是意识到这个这个设计的失误, 不想让你用这个type类型, 因为type和传统数据库里面的表概念其实是不一样的，这种概念类比给人造成了误解，到了es的7.x版本会默认取消type类型, 就说明这个type字段真的是鸡肋的不行\n\n## 弱事务\n\nMongoDB以前只是支持同一文档内的原子更新, 以此来实现伪事务功能, 不过Mongo4.0支持Replica Set事务, 大大加强了事务方面的能力 \n\nes在这方面倒没有什么进展，因为从应用场景上es对事务的需求不高，不过用户其实也可以使用同文档更新或者通过程序自己来实现事务机制\n\n## 无join支持\n\n文档型数据库大多数都不支持join(也有少量支持的), 但是我一般也用不上多表join的功能, 即便真的需要使用join也可以通过应用层或者通过耦合数据来实现（不过据说未来Mongo4.2版本会带来对join的支持）\n\n不支持join带来的问题就是我们需要自己对数据进行连接, 但是这在擅长使用分布式计算的大数据领域不算什么问题, 相应的缺少join功能可能对善于使用SQL的数据分析师就不大友好\n\n## Bully的选主算法的缺陷\n\nelasticsearch和MongoDB选择的选主算法实现很简单, 但是代价就是有几率出现脑裂的情况, 当然, 具体情况跟配置也有关系(比如:你有三个es节点但是设置的最小主节点数为1, 将最小主节点数设置为2可以避免脑裂情况)\n\n不过脑裂问题一方面发生概率较低，另一方面即使出现了脑裂的情况, 使用`重启大法`一般就能解决 ^_^\n\n总体来说, 这方面不如使用Paxos和Raft算法或者使用zk做协调器的其他分布式系统靠谱\n\n# 其他\n\n* 运维工具\n\n两者背后都有商业公司的支持\n\nMongoDB的很多客户端和运维工具更丰富, 但是MongoDB作为一个数据库产品, 相对应的对运维人员的要求也要更高一点\n\nElasticsearch则有整套的数据分析和收集工具提供, 配套的kibana就是一个很不错的管控es的工具\n\n* 操作接口\n\nes使用Restful来提供统一的操作接口, 屏蔽了各种语言之间的障碍, 但是同样带来了表达能力和性能的损失\n\nMongoDB则使用TCP, 降低了序列化和网络这一层的性能损耗, 并最大程度保留了接口的内容表达能力, 但是相对的使用起来就不如http那么的方便\n\n# 适用场景\n\n两者其实在很多使用场景上有重合之处, 是可以互相替代, 比如日志收集\n\n但是某些方面两者又各有特色，比如： 如果打算使用一个文档型的业务数据库， 那最好还是选mongodb, 如果你有要求复杂查询又并发性能要求高的场景，类似搜索服务，那最好的选择是elasticsearch\n\n除此之外：\n\nMongoDB有多个存储引擎可以选择, 而且MongoDB不仅看重数据的分析, 对数据的管理同样看重, 总的来说MongoDB更倾向于数据的存储和管理, 可以作为数据源对外提供， 未来说不定还会有支持join和支持倒排索引的mongo引擎出现\n\nElasticsearch则有很多插件可以使用, 相对来讲Elasticsearch更倾向于数据的查询, 一般情况下elasticsearch仅作为数据检索服务和数据分析平台, 不直接作为源数据管理者\n\n* MongoDB适合\n\n1. 对服务可用性和一致性有高要求\n2. 无schema的数据存储 + 需要索引数据\n3. 高读写性能要求, 数据使用场景简单的海量数据场景\n4. 有热点数据, 有数据分片需求的数据存储\n5. 日志, html, 爬虫数据等半结构化或图片，视频等非结构化数据的存储\n6. 有js使用经验的人员(MongoDB内置操作语言为js)\n\n* Elasticsearch适合\n\n1. 已经有其他系统负责数据管理\n2. 对复杂场景下的查询需求，对查询性能有要求, 对写入及时性要求不高的场景\n3. 监控信息/日志信息检索\n4. 小团队但是有多语言服务，es拥有restful接口，用起来最方便\n\n# 总结\n\nMongoDB和Elasticsearch都是我比较喜欢的存储产品\n\n两者的功能特性也存在很多重合的地方, 其实现在很多数据库产品都在互相借(chao)鉴(xi), 功能和特性都在逐渐变得相似, 这也是未来很多存储产品的发展趋势, 大家都希望自己能覆盖尽量多的场景和用户群体\n\n很多产品总是在不断的从`没有`->`有`->`功能丰富`,但是功能丰富一定是做了很多的妥协, 于是又有了 `功能众多的单体服务`->`多个功能单一的子服务` 方向的转变,就像三国里面说的 \"天下大势, 分久必合合久必分\". \n\n现在NoSQL数据库产品就在这个路上, NoSQL归根到底都是 RDBMS的某个方面的妥协, 现在各种NoSQL 也都在加入对经典SQL和传统RDBMS的 join, 事务的支持, 但是我相信等到两者区别足够小的时候, 一定会有放弃了大而全, 而专注于某一场景的新的存储产品出现，到时候搞不好又是一波新的Nosql潮流 ","tags":["NoSQL","MongoDB","Elasticsearch"]},{"title":"2019年记录","url":"/2019-01-01-summary-md/","content":"\n# 2019\n\n# 1月\n\n看书:\n\n- [ ] 神经网络与深度学习\n- [ ] 深入理解Java虚拟机\n\n# 2月\n\n看书:\n\n- [ ] 设计数据密集型应用\n\n# 3月\n\n看书:\n\n- [x] 富爸爸穷爸爸\n\n# 4月\n\n看书:\n\n- [ ] 一本书看懂经济学\n- [x] 从零开始学炒股\n- [ ] 设计数据密集型应用\n- [ ] 剑指offer\n\n# 5月\n\n看书:\n\n- [x] 设计数据密集型应用\n- [ ] 股市真规则\n- [x] hbase权威指南\n\n# 6月\n\n- [ ] 剑指offer\n- [ ] 深入理解Java虚拟机\n- [ ] 推荐系统三十六式(在线课程)\n- [x] 数据结构与算法之美(在线课程)\n- [x] 大规模数据处理实战(在线课程)\n- [ ] Mysql实战45讲(在线课程)\n- [ ] Java核心技术36讲(在线课程)\n\n# 7月\n\n- [x] 推荐系统三十六式(在线课程)\n- [ ] 从一到无穷大\n- [ ] 海龟交易法则\n\n# 8月\n\n- [x] Java核心技术36讲(在线课程)\n- [x] rust程序设计语言\n\n# 9月\n\n- [x] 数学之美\n- [ ] 剑指offer\n- [x] 深入理解Java虚拟机\n- [x] 从0开始学大数据(在线课程)\n\n# 10月\n\n- [ ] Mysql实战45讲(在线课程)\n- [ ] 从一到无穷大\n- [x] 阶层越迁\n- [x] kafka核心技术与实战(在线课程)\n- [x] 小岛经济学\n\n# 11月\n\n- [ ] 思考，快与慢\n\n# 12月\n","categories":["年度记录"]},{"title":"初步探索实时数据处理系统","url":"/2018-09-30-real-time-proccess/","content":"# 背景\n\n因为业务需要, 公司现在需要一个实时的计算平台来支撑上层的各种业务\n\n借这个机会, 对我们用到的相关技术部分进行了整理\n\n# 业务场景分析\n\n下面拿我自己经历的两个项目来探讨一下实时计算平台的构建和使用\n\n以及其中遇到的一些坑\n\n# 业务1. 统一的产品池服务\n\n## 需求\n\n* 统一产品数据池\n\n由于公司部门比较分散,公司的不同品类的产品(在线旅游公司)分属不同的BU(Business Unit),不同部门之间不仅数据不互通, 而且使用的数据库,产品数据结构和使用的存储技术也都不相同, 数据库存储主要使用Oracle和MySQL\n\n我们组的业务由于含有统一的列表页和内容服务, 所有分类产品的相关信息都需要进行聚合展示, 所以原来我们使用产品都需要根据产品品类调用不同部门提供的接口进行数据查询\n\n考虑到接口性能和未来业务的增长，我们需要一个统一的产品池功能来帮助汇总所有的产品信息，向上曾业务提供一个统一的最基本的产品信息查询, 之后所有组内的产品信息统统通过产品池进行获取, 这样把数据和业务进行充分解耦  \n\n上层业务不需要了解各种分类的产品信息的存储位置和处理逻辑,只需要从统一的产品池获取产品信息即可，同时作为基础的数据服务还需要保证服务的性能和高可用性，于是有了产品池这个项目   \n\n## 组件\n\n主要涉及的中间件和服务`redis`,`kafka`,`storm`,`elasticsearch`,`mysql`\n\n## 项目详情\n\n1. 对接各BU, 整合各BU的产品信息到统一的产品容器内(选择redis/es作为主要的对外存储容器)\n2. 提供统一的产品信息获取接口\n\n## 整体结构\n\n![产品池](productpool.jpg)\n\n其中各组件的主要功能:\n\n`Redis`: 存储k-v结构的产品信息, 提供前台api接口的产品基础信息查询数据\n\n`Elasticsearch`: 提供后台和部分前台对产品的搜索功能\n\n`kafka`: 数据总线, 后台数据流转的核心\n\n`mysql/oracle`: 提供最初始的数据源\n\n`storm`: 产品信息计算平台\n\n## 流程图\n\n### 前台api获取产品的流程\n\n![](flow1.png)\n\n### 后台构建产品的流程\n\n![](flow2.png)\n\n## 详细步骤描述\n\n* 定时的产品id添加: 定期进行全量的产品数据重建, 为了方便控制重建过程, 将要处理的产品id分批存入kafka中的`全量重建topic`, 也就是把批处理转化为流处理  \n\n* 失效的产品id: 当某个产品不存在于redis中时, 也会重新放入kafka的另外的`miss产品topic`中进行重建  \n\n* 当产品信息变更时候也会有对应的变更产品id入kafka的`变更产品topic`中进行重建  \n\n* 处理产品时会从以上三个产品源topic中读取需要重建的产品, 根据分类发放到`不同的分类topic`, 然后交给storm进行产品信息计算, 这部分信息只有简单的产品ID和更新类型标识  \n\n* storm中构建失败的产品(数据库中不存在等原因), 会在redis中进行标记暂时不可用(有效期1天), 不可用的产品不会继续进行重建  \n\n* kafka多个topic中的消息含有需要构建的 产品id和产品需要构建的内容, 也就是说可以通过消息内容格式控制构建产品的某个部分的信息(例如: 只更新产品的基本信息, 只更新价格信息, 只更新评论数,好评数等信息)\n\n* storm从kafka中获取消息, 进行产品的信息计算, 计算完成的信息会重新返回kafka, 同样根据产品分类发放到不同的`分类topic`, 这部分信息含有全量的产品信息数据\n\n* 整合各个分类topic的产品计算结果, 写入redis 和 es, 并回写部分mysql表\n\n\n## 产品数据更新\n\n通过`canal`监听mysql数据库的产品表数据变更, 将变更数据发给kafka中的`产品表日志topic`, 后续从kafka的`产品日志topic` ,根据数据内容解析出来产品更新事件, 封装对应的事件消息, 存入`产品事件topic`  \n\n通过读取`产品事件topic`中的数据, 根据品类和变更内容, 向产品池`变更产品topic中发送`发送产品池信息重构需求\n\n## 经验和总结\n\n* 为什么要分多个产品数据源topic\n\n1. 为了优先级考虑, 不同来源的产品对时效性要求是不同的, 但是kafka本身又做不了带有优先级的消息处理\n\n2. 不同的分类的产品的处理逻辑不同, 更新频率和数据量也不同, 提前进行分流\n\n* 为什么不同分类的产品要用不同的写入topic\n\n1. 如果有其他业务需要使用其中某个分类的产品数据只需订阅对应的产品topic流就可以了, 免去了从全量产品流中过滤的步骤 \n\n* 为什么最后还要把产品信息吐会回kafka\n\n1. 为了统一控制写入源并做优化, 使用统一的topic存储数据可以让整个程序只有一个数据写入的源, 所有写入操作统统使用写总线来处理, 解耦了功能, 提高了可靠性, 扩展性和可维护性\n\n2. 可以对数据写入做优化, 比如:幂等处理, 批压缩写入处理, ABA问题的重写\n\n3. 为了数据重用, 因为其他部分业务组也可能需要使用产品信息, 到时候直接订阅最终的产品信息表就可以了\n\n4. 为了方便扩展, 如果将来数据量大, 出现了写入瓶颈, 只要对这一部分承担写总线功能的写入程序进行扩展就可以了\n\n# 业务2. 用户画像之用户信息完善系统\n\n## 需求\n\n这个项目是用户画像的子项目, 目的是将用户分布在不同BU的信息进行整合, 提供一份统一最完整的用户信息出来\n\n同时进行一些数据清洗和数据统计\n\n* 对分散在各个表中的会员信息进行梳理, 整合一份相对比较完善的用户信息\n\n例如: 用户1在基本信息中填写了一份信息 \n```\n{ \n    \"username\":\"zhang\",\n    \"birthday\":\"1990-01-01\",\n    \"gender\":\"M\"\n}   \n```\n\n同时用户上传了一张个人身份证, 通过解析, 身份证含有的信息是\n```\n{\n    \"birthday\":\"1990-12-07\",\n    \"gender\":\"F\"\n}  \n```\n\n也就是说用户自己填写的信息和身份证中的信息不一致, 相同的情况可能出现在多个业务部门, 因为业务拆分各部门相互独立, 同一个用户在多个业务部门可能拥有多份不太一致的用户信息  \n\n* 对进行过清洗的用户数据进行完善度的计算\n\n根据不同用户信息字段占有的不同分值权重, 使用完善后的用户信息, 对用户的完善度进行实时统计\n\n* 定期统计用户的完善度报表\n\n根据用户会员等级/地区/性别 等基本属性和 对应的销售vip客服人员进行用户信息的报表统计\n\n## 组件\n\n主要相关的组件有 `mysql`,`kafka`,`storm`,`hbase`, `es`\n\n## 项目详情\n\n1. 对接各数据源, 根据用户身份表示整合统一的用户信息\n2. 统一存储用户信息\n\n> ps:由于部分原因, 项目的实际开发时间很短, 只有200左右的工时, 也就是一个人工作一个月, 而且大部分时间都花在内部数据问题的处理上面, 所以项目未能做到最终非常完善的程度\n\n## 流程\n\n1. 定期的全量用户信息补全\n2. 用户信息变更以后触发的补全\n3. 用户资料补全以后进行完善度的计算\n4. 定期根据用户属性对用户完善度进行报表统计\n\n具体的细节跟上面产品池相似, 都是利用`kafka`的数据流转, 将需要计算的消息流到`storm`, 经过计算以后再通过`kafka` 回馈给数据库和存储 \n\n# 总结\n\n其实回顾这两个项目\n\n在其中主要起作用的中间件主要是`kafka`和`storm`\n\n`kafka` 承担了系统几乎所有的数据流转需求, 做了一个数据总线的角色, 提供了`事件驱动`,`ETL`,`解耦`等功能   \n\n`storm` 则承担了主要的计算任务和部分数据转发功能  \n\n其他 `mysql`, `redis`,`elasticsearch`则一直充当数据提供方和数据使用方(业务)之间的网关作用   \n\n这一套消息处理流程目前来看还没遇到太大的问题, 但是因为我们部门业务相对比较单一, 尚不能完全发挥这套架构的潜力  \n\n希望以后可以多尝试, 并进行改进","tags":["数据处理"]},{"title":"平衡和度","url":"/2018-06-06-balance/","content":"# 什么是智慧\n\n一直以来我都很认同`大道至简`的看法\n\n所以我天真的认为处理世界上的所有事情肯定有一个通用的框架, 该框架应该适用于所有麻烦的事情    \n而我们庸庸众人只需要学习这一种处事方式就能轻松应付生活,即所谓的The One Truth    \n后来的我渐渐意识到,`世界本来就是混乱无序的`, 那个万能法则肯定是不存在的   \n\n>从物理学上来讲, 一个封闭的系统中, 熵(代表混乱程度)处在不断增加的状态,一味地想维持低熵状态往往需要额外的付出更多能量.同样的,如果我强行要求这个系统是有序的并且规则的,那对这个系统来说,必然需要极大的能量来维持这种状态\n\n**智慧的本质, 就是对空间和时间的理解**\n\n![度](wisdom_mindnode1.png)\n\n所谓智慧, 就是能很好地平衡时间和空间, 而怎么平衡, 就涉及到度的把握\n\n## 度\n\n**度**或者叫**分寸**, 一种抉择中的取舍   \n我们无时无刻不在面临许多的抉择    \n大部分的抉择都存在我们可以感知的正面和反面效果,即便看起来非常正面的行为背后也隐藏着隐忧    \n例如:    \n* 培养好的习惯是应该的, 但是好的习惯不可能一直增加. 我们的精力是有限的,我们所处的的环境也在不断改变, 根据环境调整自己习惯才是我们要做的,否则随着时间增加我们的习惯也越来越多,如果不及时调整, 你的所有时间会被积累下来的习惯完全占据\n\n一个人在待人接物方面能很好地把握分寸, 我们会说他情商高   \n一个人在自己和外界的联系方面能很好地把握分寸, 我们会说他有品位  \n一个人在处理冲突方面能很好地把握分寸, 我们会说他有智慧   \n","categories":["思考"]},{"title":"终于找到了魅族flow耳机的模特啦","url":"/2018-05-20-meizi-qingguya/","content":"\n前几天找到了我一直寻找的给魅族耳机代言的小姐姐, 微博: @青谷娅\n\n我从第一眼看到这个小姐姐就觉得气质好好啊\n\n从网上搜了好久都找不到个人信息\n\n后来偶然间从某个摄影师处了解到这个小姐姐的微博\n\n开心了好多天\n\n# 以下是美图欣赏\n\n魅族耳机照\n\n![青谷娅](WX20180528-200414.png)\n\n![青谷娅](WX20180529-095529.png)\n\n以下图片来自微博\n\n![青谷娅](IMG_1103.JPG)\n\n![青谷娅](IMG_1104.JPG)\n\n![青谷娅](IMG_1106.JPG)\n\n![青谷娅](IMG_1107.JPG)\n","tags":["青谷娅"]},{"title":"胡思乱想-有关当前社会的一些隐忧","url":"/2018-03-09-woolgather-social-problem/","content":"\n我想说说我自己对当前社会的一些担忧\n\n我总觉得未来的3年(2018-2020)会是我国社会的重大转折点\n\n# 人口结构的隐忧\n\n中国的人口老龄化加剧已经是一个无法避免的事情了\n\n即便国家最近几年放开了二胎政策, 但是从数据上面看效果并不是很好\n\n下面是一份部分年份的出生和死亡人数的图(单位:万人)\n\n![人口图](people-1.png)\n\n## 出生与死亡人口\n\n目前我国的人均寿命男性在74岁, 女性在77岁, 综合平均值大概在75.5岁上下\n\n也就是说去年2017年, 按照平均寿命来算, 去年的大量正常死亡人口都是出生于1941年的, 假设我们预计平均寿命每5年增长一岁的话, 1946年出生的人口正常死亡时间在2023年左右,再加上一些非正常因素, 也就是说2023年左右死亡人数至少在1200万+\n\n从上面的图推论, 我们有理由相信在未来10年, 中国每年的死亡人口将迅速由每年970万左右上升到每年1600万+( 深绿色曲线将沿着浅绿色曲线旧轨迹上升)\n\n到2020年,1955年出生的人将步入65岁, 人到了这个阶段, 已经进入疾病高发期, 也就是说未来几年我国将新增至少5200万65岁以上的老人,这批人对养老和医疗造成的压力会很大, 我非常担忧之后医疗资源和社会资源的消耗情况\n\n# 社会影响和政策\n\n* 对出生人口的预测\n\n回过头来看我们的出生人口, 最近几年国内出生人口持续下降, 2016-17年由于二胎政策有小幅回升, 17年1700万出生人口中,二胎占800万(这其实是一个很不好的信号)\n\n当前国内的生育主力,还是1980-90年这一批人, 等到他们这一代人的生育意愿消耗完毕, 国内出生人口必然大幅下降, 因为91-96年出生人口本来就少了许多, 适龄生育人数更是大减\n\n我国人口出生的第一个高峰在60年代,第二个高峰在1985-1990年,第二个人口高峰出生的人的父母就是第一次人口高峰中出生的人,理论上来说85-90这一代人的孩子将会形成第三次人口高峰,预计在2015-2022年, 但是, 我们看一下出生数据表:\n\n![出生人口](people-2.png)\n\n我们来看1985-1990年的出生人口分别为`2042,2319,2528,2457,2513,2621`,平均 2413万人/年\n\n这一代人到了最佳生育期(24-30岁)之后对应的实际出生人口为 `1615,1574,1604,1635,1640,1687`(2009-2014),平均每年1625万人\n\n**也就是说正常情况下, 每年2400万人的适龄生育人口对应的生育婴儿人数大概是1600万,比例大概是 3:2**\n\n过去5年提供生育力量的主力人口就是这一批人,我们根据他们这一代人的出生人口数和生育情况可以预估未来5年的出生人口情况\n\n未来5年提供生育力量的的主力人口也就是 1991-1996这几年的出生人口分别为 `2008,1875,1791,1647,1693,1522` 平均1756万人/年\n\n根据3:2的比例,我们可以预测未来5年的生育人数是平均 1200万人/年\n\n我们根据以上信息, 来做一个有关中国人口的预测:\n\n![人口预测](people-3.png)\n\n**预计最迟中国将在2022年迎来人口负增长!!!**\n\n**最迟中国将在2022年迎来人口负增长!!!**\n\n**2022年人口负增长!!!**\n\n中国人口一旦减少, 将是一个革命性的时刻, 到时候很有可能中国将会走上一条没有人能预想到的道路\n\n## 人口老龄化的影响\n\n**人是社会的基础** \n\n人口结构和数量的变化将会带来社会的巨大改变\n\n而目前我国逐步严重的人口老龄化将会为我们的社会带来难以想象的巨大的压力\n\n* 公众人物的离世\n\n在2018年有很多人感叹今年是怎么了\n\n一个接一个知名公众人物离世, 大家纷纷都说不喜欢2018年, 因为失去了太多喜爱的老前辈\n\n其实这个现象是正常的\n\n1. 80, 90后是新媒体的第一代受众, 这一代人开始认识比父辈更多的公众人物, 我们认识的公众人物更多  \n2. 电视, 广播时代的前几代先驱者到现在都逐步步入老年时代, 他们普遍比我们年纪大很多, 他们在变老  \n\n以后这个情况恐怕会越来越严重\n\n我算一笔账, 现代网络时代每个人听说过的的公众人物进入老年人行列的少说也有 1000人 \n\n假设他们都在30年内相继离世, 每年是30人, 平均下来, 差不多每10天就有一个你熟知的公众人物离世\n\n但是真实情况是我们每个人熟知的人远超 1000人, 他们也不一定都能长寿到100岁, 所以现实情况未来只会更糟糕\n\n* 未来还会有的影响\n\n1. 殡葬行业的需求量未来会爆增, 加上我国传统思想的影响, 行业将会迎来前所未有的机遇\n2. 医疗资源紧张, 成人纸尿裤一定会大卖 ^_^\n3. 健康保健行业的机遇, 以后大家会越来越重视健康生活, 保健品行业可能会迎来爆发期\n4. 旅游行业和保险行业未来也会进入一段时间的黄金时期\n5. 同时由于国内文化的特殊性, 老龄化还会造成教育行业的快速发展\n\n诸位注意投资\n\n## 平均寿命和养老金\n\n我国早期制定的养老金计划是依照平均寿命60岁制定的, 可当时的人们没有想到人类的平均寿命增长的如此之快\n\n以至于旧有的养老金制度无法满足当前社会的需要, 我国养老金亏空已经是人尽皆知的事情了\n\n现在年轻人生育欲望低, 未来的养老更是没有保障, 这样我估计将来怕是连这个养老金制度都会崩溃\n\n养老金问题已经成为了我国一个十分重大的社会问题, 不知道未来国家会采用怎么样的方式来解决\n\n## 房价\n\n在我们的邻国日本有研究表明, 日本的房价和年轻人的生育意愿呈负相关.\n\n国内现在房价如此之高,导致养孩子的成本极高, 没有一定的物质积累,年轻人怕是不敢妄谈生育\n\n高房价会进一步降低年轻人的生育意愿\n\n我上面对我国出生人口的预测还是太过乐观了\n\n不过我同时也觉得现在房价泡沫有点偏大了, 预计未来3年(2018-2020)就会破灭, 房价就会崩盘\n\n即便很多人说国家不会允许房价崩盘, 但是我想说, 房价不崩盘, 其他所有实体行业统统要崩盘, 两害相权取其轻, 相信国家会这么选择的\n\n所以打算买房的朋友可以稍微等上几年\n\n## 国家未来几年可能会采取鼓励生育政策\n\n由于人口压力,国家未来几年一定会出台各种鼓励生育的政策\n\n我在这里做一下预测, 未来几年可能会采取的政策\n\n1. 取消多胎生育限制\n\n现在仅仅是取消了二胎的限制, 多胎依然是违法的, 未来很有可能会彻底取消生育限制, 以刺激农村乡镇人民的生育意愿\n\n> ps: 据彭博社消息, 中国将来2018年年底取消多胎限制,消息未经官方证实\n\n2. 延长退休年龄\n\n国家已经在进行这方面的政策调整了, 未来说不定会跟新加坡一样, 彻底取消退休年龄, 永不退休\n\n3. 增加女性生产福利\n\n增加女性生产福利(比如: 强制半年产假,男方陪产3个月). 不过如此一来很可能会起到其他意想不到的效果\n\n比如:增加产假时长等于变相增加企业雇佣女性的成本, 没有企业愿意在同等条件下雇用女性, 导致女性工作难找, 不得不在家生孩子, 现在的欧洲已经在这么做了\n\n4. 利用媒体鼓动年轻人谈恋爱\n\n鼓励年轻人谈恋爱同事灌输多子多福的思想才是理论上的可持续发展战略\n\n其他的政策都只能治标不能治本\n\n\n# 教育和阶级固化\n\n## 教育周期的延长\n\n随着现在社会的发展, 人类掌握的知识总量呈指数发展\n\n同样, 一个人从出生到达科研领域最前沿的时间也在不断增长\n\n牛顿时代,一个25岁的数学系高材生就能接触到最前沿的数学理论研究, 此时的物理更是连基本的框架都没有, 这个时期人学习某种技术的周期相对较短, 一般能在25岁完成对所需基本知识的积累\n\n到了现代, 哪怕你专研一个领域并且博士毕业, 都未必能接触到最前沿的研究\n\n科研要突破必须先走到研究的最前沿, 但是要走到最前沿又必须有足够的知识积累, 这就导致现代人接触前沿科学的时间被大大拉长\n\n以前 25-30岁的科研人员就能接触到最前沿的技术, 现在得等到40-50岁才有可能完成早起必要的知识积累, 但是4,50岁的人了, 哪还有那么多精力来搞研究, 前沿研究的迟滞会导致整个科学学科的发展变慢\n\n人类的科技进步已经不可避免要出现瓶颈了\n\n这种矛盾产生的原因是因为人类社会的发展太过迅速, 人类的进化速度赶不上社会的发展速度, 彼此之间不能很好的匹配\n\n可能有效的解决方案\n1. 领域继续细分，降低研究人员积累必要知识的负担\n2. 借助电脑帮助加快研究速度\n\n## 阶级固化\n\n**社会阶层的固化是历史上每一段和平时期的主旋律**\n\n我只说一个现象,我当年上学时候, 同学里面还有县长的孩子,教育局长的孩子.公安局副局长的孩子   \n但是我弟弟上学的时候, 都已经很少遇到权贵子弟了, 是当任的权贵年龄偏大吗, 不是,是因为这些人的孩子早出国去了   \n\n大家自己富裕了, 自然就想给孩子更好地条件   \n富者愈富, 穷者愈穷    \n**而且这是个死循环,你还不能不给孩子投入**   \n我有朋友说,\"有多少钱,出多少资源, 不可能什么都给孩子准备好,只能靠他自己,我当年没钱也不过来了吗\"   \n其实这种看法我是很反对的     \n\n现在很多小孩子你不给他报什么钢琴班,美术班,英语班, 他会的技能就比其他孩子少,小孩子们之间攀比心很重,你孩子不懂这些,没有这些,人家别的小孩子不跟你玩...    \n别人有Switch,你没有, 别人报了绘画班,钢琴班,你没有,别人学了英语/美术,你没有, 那别人就不跟你玩...因为孩子也有圈子,圈子是由共同语言组形成的   \n\n你的孩子不应该拿来跟20多年前的你来比, 他的竞争对手是他的同龄人, 应该看看他们同龄人是怎么样的条件    \n而且现在很多老师会在入学时候收集家长信息,对孩子因家庭条件施教,甚至你不给老师送红包就不在意你孩子   \n**这都是中国特色的现象,逼着你的孩子不得不拼爹**     \n这几年这种现象尤为明显, 现在大家都希望把最大的投入放到孩子的教育上面, 由于教育的投入,孩子的差距也会越来越大  \n就像<<名侦探柯南>>里面有一集说的: 政治家的儿子依然是政治家, 企业家的孩子依然是企业家, 明星的孩子依旧是明星   \n日本已经经历过我过正在经历的阶段和遇到的诸多问题, 日本的现状我们能从中学到很多    \n> 秦人不暇自哀，而后人哀之；后人哀之而不鉴之，亦使后人而复哀后人也。","categories":["思考"]},{"title":"学习分布式计算框架-MapReduce","url":"/2018-02-08-distribute-map-reduce/","content":"\n最近在使用Google搜索的时候发现搜索结果显示的速度非常的快(一般在0.1s-0.4s内)\n\n我们之前也做过一部分搜索引擎相关的工作(基于Sphinx和Elasticsearch), 但是发现Google搜索引擎的性能和准确度要比我们做的快上许多\n\n这个事情让我很好奇Google的搜索引擎为什么速度这么快\n\n搜索引擎一般来说都会随着数据量的增加而变慢,即便使用了索引也有很多的问题要处理\n\n后来从网上搜索了一下,发现google现有的搜索引擎是基于Caffeine的增量索引系统构建的\n\nGoogle背后的索引计算工作是搜索引擎的核心之一, 经过搜索发现, Google后续的一些列大数据计算引擎都是基于MapReduce的思想构建出来的\n\n# MapReduce\n\n在2004年google发布了一篇论文, 描述了google内部针对大数据处理的一种通用模式:MapReduce\n\nMapReduce是一种编程模型,主要用来对大量的数据进行分布式处理和计算,很多常见的数据处理任务都可以被拆分为符合mapreduce模型的编程过程,MapReduce主要过程分为Map和Reduce两个过程\n\n论文地址:[MapReduce论文](https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf)\n\n## Map\n\nMap是一个将问题分解成多个小问题为后续的分发提供基础的技术\n\nMap的过程用函数来表示就是:\n\n    map(k,v) = (k1,v1<list>)\n    \n    map函数接收一对k,v键值对,返回一个(k1,v1<list>)\n    \nmap函数的目的是为了将任务分割方便后续的任务合成\n\n## Reduce\n\nReduce是将多个k-v pair按照相同的k进行合并的过程\n\n    reduce(k,v2<list>) = (v3<list>)\n    \n    reduce函数接收一个k,v1<list>, 返回一个v2<list>\n    \n>ps:大多数情况下map的返回结果不能直接用于reduce函数,需要特殊处理一下\n\n## 过程图\n\n以下是一个很详细的对MongoDB中的MapReduce过程的解读图\n\n![mr](map-reduce.bakedsvg.svg)\n\n我们可以看到map函数的输入是多个被查询过滤过的文档集合,返回值是一个map对应的值列表,我们可以认为map函数式对所有符合条件的数据进行一次简单的处理\n\nreduce则是将这个值列表按照key进行处理,即对map的结果进行最终结果操作\n\n# 实例\n\n我们用一个实际的问题来描述MapReduce的思想\n\n假设我们有一个文件集合(C),里面包含M个文档,我们要对文件集合中的文档进行单词次数统计,统计在所有文档中的每个单词出现的次数\n\n可以用以下过程描述:\n\n```c\nmap(String key, String value): // key: document name\n    // value: document contents for each word w in value:\n    EmitIntermediate(w, \"1\");// 该函数返回一个[(\"to\",1),(\"yours\",12)]这样的列表数据\n\nreduce(String key, Iterator values): // key: a word eg: \"t1\"\n    // values: a list of counts 示例: [1,2,3]\n    int result = 0;\n    for each v in values:\n      result += ParseInt(v);\n    Emit(AsString(result)); // 该函数同样返回一个[(\"to\",1),(\"yours\",12)]的数据\n```\n\n## 代码(单机版)\n\n以下是使用mapreduce进行文档词频统计的示例代码\n\n其中的主要代码简单解释一下\n\n### MapReduce类\n\n`MapReduce`类是一个通用的MapReduce框架,理论上任意MapReduce任务都可以套用这个框架\n\n要处理不同的问题我们只需要修改对应的map和reduce函数即可\n\nMapReduce类接收3个参数\n\n```\n    i:       要处理的数据源,格式是一个普通的字典; \n    mapper:  映射函数,该函接收一个kv键值对,根据需要对每个v值进行处理,返回一个(k,v<list>),此处的k值并不一定是传入的k值; \n    reducer: 压缩函数,接收一个(k,v<list>),根据需求对数据进行压缩合并;\n```\n\n### map函数\n\n其中`get_most_common_from_text`使用了结巴分词插件\n\n参数:\n\n        k:\"a\"\n        v:\"The quick brown fox jumped over the lazy grey dogs.\"\n\n返回:\n\n        eg: [(\"the\",1),(\"quick\",1),(\"fox\",1)...] \n\n### reduce函数\n\n参数:\n\n        k:\"the\"\n        v<list>:[1,1,1]\n\n返回: \n        \n        [(\"the\",3),(\"quick\":1)...]\n\n```python\nimport itertools\nimport jieba\nfrom collections import Counter\n\nclass MapReduce:\n    __doc__ = '''提供map_reduce功能'''\n\n    @staticmethod\n    def map_reduce(i, mapper, reducer):\n        \"\"\"\n        map_reduce方法\n        :param i: 需要MapReduce的集合\n        :param mapper: 自定义mapper方法\n        :param reducer: 自定义reducer方法\n        :return: 以自定义reducer方法的返回值为元素的一个列表\n        \"\"\"\n        intermediate = []  # 存放所有的(intermediate_key, intermediate_value)\n        for (key, value) in i.items():\n            intermediate.extend(mapper(key,value))\n\n        # sorted返回一个排序好的list，因为list中的元素是一个个的tuple，key设定按照tuple中第几个元素排序\n        # groupby把迭代器中相邻的重复元素挑出来放在一起,key设定按照tuple中第几个元素为关键字来挑选重复元素\n        # 下面的循环中groupby返回的key是intermediate_key，而group是个list，是1个或多个\n        # 有着相同intermediate_key的(intermediate_key, intermediate_value)\n        groups = {}\n        for key, group in itertools.groupby(sorted(intermediate, key=lambda im: im[0]), key=lambda x: x[0]):\n            groups[key] = [y for x, y in group]\n        # groups是一个字典，其key为上面说到的intermediate_key，value为所有对应intermediate_key的intermediate_value\n        # 组成的一个列表\n        # print(groups)\n        return [reducer(intermediate_key, groups[intermediate_key]) for intermediate_key in groups]\n\n\nclass test:\n\n    def get_most_common_from_text(self,text,n = 100):\n        word_list = [x for x in jieba.cut(text) if len(x) >= 2]\n        return Counter(word_list).most_common(n)\n\n    def map(self,k,v): # k:文档名, v:文档内容\n        return self.get_most_common_from_text(v,10000)\n\n    def reducer(self,k,v): # k:词  v:词出现的次数\n         return k, sum(v)\n    \n    def run(self):\n        \n        i = {\n            \"a\":\"The quick brown fox jumped over the lazy grey dogs.\",\n            \"b\":\"That's one small step for a man, one giant leap for mankind.\",\n            \"c\":\"　　Mary had a little lamb,Its fleece was white as snow;And everywhere that Mary went,The lamb was sure to go\",\n            \"d\":\"I pledge to honor and defend you and yours above all others\",\n            \"e\":\"To share in blessings and burdens, to be your advocate, your champion\"\n        }\n        \n        t = MapReduce.map_reduce(i,self.map,self.reducer)\n        print(t)\n\n\nm = test()\nm.run()\n\n```\n\n\n# 总结\n\nMapReduce其实就是我们常说的分而治之的思想\n\n不过这个过程中借助了中间存储\n\n统一了数据模型规范, 使之能适用于更广泛的数据计算","categories":["编程学习"],"tags":["MapReduce"]},{"title":"分布式文件系统-GFS学习总结","url":"/2018-02-02-distribute-storage-gfs/","content":"GFS是谷歌的底层文件系统\n\n# GFS简介\n\nGFS(Google File System)是谷歌开发的一个分布式文件系统, 目的是提供一个基于众多廉价服务器工作的基础层分布式的文件存储服务\n\nGFS服务的是上层的`Bigtable`, `Megastore`等上层数据库应用，所以GFS的读写基本都是其他应用的大文件批量数据读写\n\nGoogle于2003年放出了GFS的设计论文\n\n论文地址 [The Google File System](https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf)\n\n# GFS的特点\n\n1. 仅支持文件追加操作 (适用于谷歌的爬虫数据存储需求)\n2. 文件块大小为64M (优点很多, 减少元数据量, 减低master服务器压力, 缺点也有)\n3. 采用中心化的master节点管理元数据 (可能造成单点故障和性能存储瓶颈)\n4. 基于廉价服务器实现高容错高可用\n\n# 核心组件\n\nGFS的核心服务分为三个部分\n\n![GFS核心](1334712344_6225.jpg)\n\nGFS采用中心化的管理方式,Client作为应用使用方,Master作为ChunkServer的管理者,ChunkServer来负责数据的存储,client与master进行交互获取控制信息,然后与对应的ChunkServer交互获取具体的数据\n\n1. Client\n    \n    Client就是各种应用中使用GFS的客户端,以库文件的形式提供\n\n2. MasterServer\n\n    MasterServer相当于对ChunkServer数据进行管理的管理者,存储整个文件传统的目录结构和文件元信息(包括Chunk分片信息和分片位置),Client从Master获取到具体的文件所在的ChunkServer的地址,然后直接与ChunkServer通信进行数据操作\n    \n3. ChunkServer\n\n    存储具体文件数据的服务器\n    \n# 内部数据管理机制\n\n## Master数据存储\n\nMasterServer中存储3类信息:\n\n1. 文件系统的命名空间,整个文件系统的目录结构和Chunk基本信息\n2. 文件与Chunk的映射关系\n3. Chunk副本的位置信息,默认每个Chunk使用3个副本\n\n由于MasterServer采用中心化的单节点管理,所以MasterServer的内存使用和性能都是我们要关注的点:\n\n        假设要存储1Pb的数据 MasterServer的内存使用为 \n        \n        (1P * 64b * 3) / 64Mb = 3Gb\n        \n        1P  : 是总数据大小\n        64Mb: 是每个Chunk的容量\n        3   : 是Chunk备份数量,默认为3\n        64b : 是每个Chunk的元属性所占的空间\n\n## ChunkServer存储的数据\n\nChunkServer中存储Chunk的具体文件内容\n\nGFS将每个Chunk限制为64M, Chunk内部又分为众多的Block\n\n同时ChunkServer还负责进行具体每个Chunk文件的读写操作, 接受并执行每个主Chunk(租约Chunk)的指令\n\nChunkServer还需要定时与master进行心跳同步，上报自己持有的运行状态和维护的chunk信息\n\n## 负载均衡\n\n由于GFS是由众多的廉价服务器组成的系统,所以系统的负载问题就是十分重要\n\nGFS会根据每个服务器的负载和最近操作数来决定新数据的分布,以保证数据分布的均匀\n\n一般有三个基本原则\n\n1. 同一个Chunk的多个副本不会放在同一个机架\n2. ChunkServer最近操作数有一定的限制\n3. 优先选择磁盘负载较低的服务器\n\n第二点十分重要但时常被忽略,如果没有第二条规则限制, 很容易出现新加的机器由于负载过低导致短时间内大量数据都往这个机器上操作, 导致新添加的机器被压垮\n \nChunkServer启动时会向MasterServer上报存储的文件信息,也会周期性的向MasterServer上报自己的服务器状态, 以此来保证master上的ChunServer信息保持更新, 并及时发现ChunkServer的故障\n\n## 垃圾回收\n\nGFS采用标记回收的方式处理,删除一个文件之后,GFS并不会立即要求归还可用的物理空间,而是在元数据中将文件表示为一个不可用的隐藏名字,标记一个删除的时间戳\n\nMaster定时检查,文件被删除超过一定时间,Master会删除文件的元数据信息,之后在与ChunkServer交互时通知ChunkServer删除对应的Chunk信息,ChunkServer来处理后续的存储释放\n\n过期的Chunk也是通过垃圾回收机制来进行删除\n\n## 快照\n\n一但对一个文件采取快照, GFS会通过租约机制先停止所有Chunk的写操作, 更新所有Chunk副本的引用计数\n\n然后之后的写请求在执行时会copy一个Chunk副本,后续的修改都会落到新的Chunk上面\n\n例如:\n\n对文件 f 执行快照生成 f_back , f在GFS中有三个Chunk: C1,C2,C3 \n\nMaster首先会回收C1,C2,C3的写租约,从而保证此时的f状态一致,然后Master复制 f的元数据生成一个新的文件 f_back\n\n此时f_back的 Chunk仍然指向 C1,C2,C3. 快照之前, C1,C2,C3只被一个文件引用,引用计数为1, 快照之后引用技术更新为2\n\n当客户端向C3增加数据时,Master发现c3引用计数超过1,会通知ChunkServer生成新的C3', 新的操作也会在C3'上面进行\n\nf的Chunk映射也会更新为 C1,C2,C3'\n\n> ps: 这个机制叫写时复制(Copy On Write)\n\n# 读写数据的流程\n\n## 读取流程\n\nGFS中的文件读取流程大致如下:\n\n    1. client发送给master需要获取的文件名和偏移量(告诉服务器我要读某文件的某段数据)\n    2. master根据文件名查找命名空间中的文件对应的文件块id,返回对应的ChunkServer和副本的位置\n    3. client根据返回的ChunkServer的位置信息去对应的Chunk上面取对应的数据\n    \n>ps: client会缓存一部分的ChunkServer元信息(某个ChunkServer在某个机器上面,副本分布情况等),但并不会缓存具体的文件内容, 以此降低Master服务器的负载, ChunkServer会对服务器的请求进行校验, 当ChunkServer信息有变动时, 客户端如果使用过期的Chunk信息, 能从ChunkServer得到反馈, 重新去Master获取最新的Chunk信息\n\n## 数据的写\n\nGFS中写入数据的流程如下:\n\n![GFS写](1334931385_9113.jpg)\n\nmaster使用租约授权一个chunk副本为primary副本,执行client的写操作\n\n1. client需要更新一个数据块，询问master谁拥有该数据块的租约（谁是primary）；\n2. master将持有租约的primary和其它副本的位置告知client，client缓存之；\n3. client向所有副本传输数据，这里副本没有先后顺序，根据网络拓扑情况找出最短路径，数据从client出发沿着路径流向各个chunkserver，这个过程采用流水线（网络和存储并行）。chunkserver将数据放到LRU缓存；\n4. 一旦所有的副本都确定接受数据，client向primary发送写请求，primary为这个前面接受到的数据分配序列号（primary为所有的写操作分配连续的序列号表示先后顺序），并且按照顺序执行数据更新；\n5. primary将写请求发送给其它副本，每个副本都按照primary确定的顺序执行更新；\n6. 其它副本向primary汇报操作情况；\n7. primary回复client操作情况，任何副本错误都导致此次请求失败，并且此时副本处于不一致状态（写操作完成情况不一样）。client会尝试几次3到7的步骤，实在不行就只能重头来过了\n\n也就是说GFS也是使用持有租约的primary副本来进行一致性保证， 其他所有副本均按照primary确定的写入顺序执行\n\n# 故障恢复和容错机制\n\n## 快速恢复\n\nGFS能使用checkpoint 文件和日志文件快速进行故障的恢复\n\n## 副本复制\n\nGFS通过副本进行数据备份， 只要一个chunk有一个副本所在的机器存活，数据就可以恢复\n\n## Matser的容错\n\nMaster会进行远程备份，Master存储文件的信息有\n\n1. 文件的命名空间信息(整个文件系统的目录)\n2. Chunk服务器和文件名的映射关系\n3. Chunk服务器的地址和副本信息\n\n对于前两种操作GFS通过操作日志提供容错,日志会被被分到远程服务器   \n最后一种保存在ChunkServer上, 当ChunkServer跟master注册时,或者Master启动时,使用轮询的方式去ChunkServer获取元数据\n\n## ChunkServer的容错\n\n1. 每个Chunk默认拥有3个副本, 分布在不同的ChunkServer上面\n2. ChunkServer在发送数据之前会检查block的32的校验和,如果不一致就会上报Master,Master会从其他副本进行复制,并删除出错的副本数据\n\n> ps：为什么是默认3个副本呢，是因为副本的分布要同时满足性能和安全性需求，也就是同一机架放两个副本，另一副本放到另一机架，平衡安全性和速度。\n同时三个副本正好能覆盖chunk所有的可能存在的状态，1. 正常获得租约状态 2. 租约到期，进行转换  3. 作为其他chunk的副本 \n\n# 其他优化的点\n\n* 文件树存储\n\n由于master需要存储所有的文件树和块的对应关系，采用了前缀树进行数据压缩，大大提高了可存储数据的容量\n\n* 高并发热点文件的读写\n\nGFS采用副本机制和错峰控制来处理热点文件的高并发读写，同时提出了一种长效解决方案：允许客户端读取客户端数据，形成客户端链\n\n* 为什么要采用中心化的服务\n\n为了简化系统设计，保持灵活性\n\n* 读数据时候的数据流\n\nGFS写入数据的时候客户端并不是采用星型或者树形结构，同时持有多个副本的链接并向副本发送数据，而是经过了一定的拓扑优化  \n客户端会将数据发送给离自己最近的节点s1，同时该节点会继续将数据发送给离自己最近的节点s2，没一个节点都发送给离自己最近同时又没有接受数据的节点，以其充分利用机器的带宽\n\n> ps: 这个问题有点像旅行商问题\n\n# 总结\n\n1. GFS是一个中心化的分布式文件系统, 文件的具体信息分块存储, 同一文件可能被分为多个Chunk块, 每个Chunk块有多个副本\n2. Master负责文件的元数据的管理, ChunkServer负责文件具体数据的管理\n3. Client读数据需要先从Matser处获取到文件的Chunk分布信息, 然后去对应的ChunkServer上取得真正的文件数据\n4. Client写数据会先跟Master交互获取Chunk文件的信息, 然后向所有Chunk副本发送文件数据流, 最后向PrimaryChunk发送写入控制流, 由PrimaryChunk通知其他Chunk副本执行真正的写操作\n5. GFS可以以Chunk为单位在不同机器之间调度数据分布, 还有 CheckPoint和Redo日志来处理容错性","categories":["编程学习"],"tags":["GFS"]},{"title":"2018-追番-看书记录","url":"/2018-01-01-comic-book-2018/","content":"## 2018\n\n年度目标: *20本书以上*\n\n### January\n\nDone:\n\n* Book\n\n- [x] HTML5游戏开发实战\n- [x] 刻意练习\n- [ ] PRINCIPLES(原则)\n\n* Bangumi\n\n- [ ] 鬼途奇行录\n- [ ] 紫罗兰的永恒花园\n- [x] 少年锦衣卫第二季\n- [x] 画江湖之换世门生\n- [ ] 狐妖小狐娘\n\nPlan:\n\n- [ ] 机器学习相关基础知识的学习\n\n### February\n\n* Book\n\n- [x] 计算机组成与操作系统\n- [ ] 分布式服务架构\n- [ ] 神经网络与深度学习\n- [x] 东方快车谋杀案\n\n* Bangumi\n\n- [x] 冰菓\n- [ ] 狐妖小红娘\n- [ ] 紫罗兰的永恒花园\n- [x] Angel Beats\n- [ ] 龙王的工作\n\n### March\n\n* Book\n\n- [ ] 原则\n- [ ] 月亮与六便士\n\n* Bangumi\n\n- [ ] 紫罗兰的永恒花园\n- [ ] 鬼途奇行录\n- [x] 龙王的工作\n\n### April\n\n* Book\n\n- [x] 原则\n- [ ] 神经网络与深度学习\n- [ ] 大规模分布式存储系统\n\n* Bangumi\n\n- [x] 紫罗兰永恒花园\n- [ ] 鬼途奇行录\n- [ ] 一人之下\n- [ ] 狐妖小红娘\n\n### May\n\n* Book\n\n- [ ] 大规模分布式存储系统\n- [ ] 分布式实时处理系统\n- [x] 神经网络与深度学习\n- [x] 月亮与六便士\n\n* Bangumi\n\n- [ ] 鬼途奇行录\n- [ ] 一人之下\n- [ ] 没关系, 是爱情啊\n\n### June\n\n* Book\n\n- [x] 大规模分布式存储系统\n- [ ] 大规模分布式系统架构与设计实战\n\n* Bangumi\n\n- [x] 鬼途奇行录\n\n### July\n\n* Books\n\n- [ ] 国富论\n\n* Bangumi\n- [ ] 海贼王\n\n### August\n\n*  Books\n\n- [ ] 国富论\n\n* Bangumi\n\n- [ ] 工作细胞\n- [ ] 魔道祖师\n\n### Sep\n\n* Books\n\n- [x] 编码\n\n### Oct\n\n* Books\n\n- [ ] 深入理解Java虚拟机\n\n### Nov\n\n* Books\n\n- [ ] 深入理解Java虚拟机\n- [x] 大数据技术体系详解\n- [ ] Designing Data-Intensive Application\n- [x] 走向分布式(Scalability)\n- [ ] Spark大数据处理\n- [x] Spark编程指南\n\n### Dec\n\n* Book\n\n- [ ] 深入理解Java虚拟机\n- [ ] Designing Data-Intensive Application\n- [x] kafka权威指南\n- [ ] Scala编程实战\n\n## 统计\n\n图书: \n\n读完: 11本(技术类7本, 其他4本)\n未完: 6本","categories":["年度总结"]},{"title":"使用Bitmap来实现用户标签系统","url":"/2017-12-29-user-tag-sys-on-bitmap/","content":"\n# 用户标签的存储方案\n\n## 背景\n\n我们在日常的工作中经常遇到这种场景\n\n对一个用户添加许多的标签信息方便对用户身份进行搜索和精细化运营\n\n>ps:本文我们不考虑用户身上的标签是怎么来的,只讨论用户已经拥有标签的情况下怎么进行存储\n\n## 需求分析\n\n我们给用户做标签的目的是为了支持更加精细化的运营,算是用户画像的一部分,用户的标签来源可能跟消费,登录,浏览等记录都有关系,我们不具体去解释怎么得到用户标签\n\n我们要做的是可以根据用户身上已经存在的标签,筛选出来符合我们需求的用户\n\n我们可以在大量的标签中查找具有某一些标签的用户,或者获取某用户身上的所有标签\n\n我们如果要满足以上的需求, 需要提供以下几个基本接口来方便进行数据查找\n\n1. 查找某标签的所有用户以及非该标签的用户\n2. 查找某个用户身上的所有标签\n3. 判断某个用户是否有某个标签\n\n一般来说对以上需求,对于用户和用户身上的标签数据,如果我们采用数据库来进行存储\n\n可能会采用以下方式(为了方便我们模拟了7个用户,7个标签,以下测试都基于该假数据),例如:\n\n1. 使用字段标识标签信息\n\n|id|name|vip|mobile|email|male|mac|supervip|lost|\n|:-|:-|:-|:-|:-|:-|:-|:-|:-|\n|1|小明|1|1|0|1|0|1|0|\n|2|小花|0|1|0|0|0|0|1|\n|3|小江|0|0|0|1|1|0|1|\n|4|小红|1|1|0|0|0|0|1|\n|5|小九|0|0|1|0|1|1|0|\n|6|小七|0|1|0|1|1|1|0|\n|7|小四|1|0|1|1|0|0|1|\n\n或者是这样\n\n2. 使用记录标识标签信息\n\n|tag|uid|result|\n|:-|:-|:-|\n|vip|1|1|\n|mobile|1|1|\n|email|1|0|\n|male|1|1|\n|mac|1|0|\n|supervip|1|1|\n|lost|1|0|\n|vip|2|0|\n|mobile|2|1|\n|email|2|0|\n|male|2|0|\n\n以上两种方式功能上都可以达到我们想要的效果,但第一种方式在标签数量非常多的时候明显是不合适的,我们不可能给每个标签都添加一个字段,那样性能和扩展性都损失非常大\n\n在上面的两个表中第二个表相当于对第一个表进行了拆分,增强了标签的扩展性.如果我们采用第二种方式存储,对于上面的需求 1,2,3 都能很好的满足\n\n但是方式2依然有两个可能遇到的问题\n\n1. 我们要查找在某一些标签的用户需要使用如下sql\n\n```sql\nselect \n    uid \nfrom \n    tag_table \nwhere \n    result = 1 \nand tag in ('vip','mobile','email','male','supervip','lost')\n```\n\n这样的语句在标签数万甚至数十万的时候对性能影响会非常大\n\n2. 存储: 因为每个行记录同时标明了用户,标签,和结果, 所以其中的重复数据非常的多,对数据库存储是个极大地浪费\n\n## Bitmap\n\n### Bitmap的概念\n\nBitmap 翻译做中文称为\"位图\", 其核心里面是充分利用一部分数据本身就存在的元属性(空间/位置/容量)信息,我们这李主要是使用其中的每一位的位置信息,达到使用一个信息表达两种含义的作用\n\n其实就也是一种特殊的编码(coding)过程(或者叫多工(multiplex))\n\n### 解决的问题\n\nbitmap可以用来有效解决两类问题\n\n1. 存储大量值可以用布尔值标识的数据\n2. 部分有用到交,并,差等集合运算的数据\n\n第一个特性主要是利用位存储的节省空间的特性,第二个是利用计算机位运算比较快速的特性\n\neg: \n\n1. 以前的搜索引擎爬虫在处理网页爬取的时候需要给已经爬取过的网页做标记,避免陷入死循环的重复爬取,当时的搜索网站的爬虫就有一些采用过bitmap来给爬取过的网页做标记,大致就是取页面的url取hash,然后处理成数字,把对应的数字位置为1\n\n2. 微博里面你关注的A也关注了B, 使用B的粉丝列表和你的关注列表进行交集运算就可以了,同样 购买这件商品的人也购买了M,也可以用 购买这件商品的用户列表里面取某个用户购买过的某个商品即可\n\n以上应用确实能有效的减少数据的存储容量和提高集合计算速度, 如果我们用这种方法来存储用户标签信息也能大量减少存储容量\n\n但是怎么把用户标签的表信息数据转换成bitmap形式的数据呢?\n\n### 数据处理\n\n我们如果要记录一个用户对应的一个标签的信息,假如我们知道5号用户是小九,而她是一位超级会员用户(我们可以在上面的表中查到该信息)\n\n我们要如何使用bitmap来表示这条信息呢\n\n#### 存储用户和标签的关系\n\n我们可以这样:\n\n1. 使用一个键`user:supervip`来记录所有用户是否是超级会员的信息,这个值最初是空的字符串值,表明没有超级会员用户\n2. 我们为了标明 5 号用户是超级会员 可以使用这个键中对应位置的二进制位来表明会员的身份,将这个键的第 5 位置为1, 这样这个`user:supervip`值现在是'000001'(从第0位开始计算)\n3. 同样,如果`user:supervip`的值现在是'01001010' 我们就可以知道 1,4,6号用户都是超级会员用户\n\n我们根据这个数据可以做到2点:\n\n* 我们可以根据该标签数据键的对应位置的二进制位的值来判断以该位置为id的用户的标签结果\n\n* 也可以查询某个标签下的所有用户\n\n这样我们存储上万个标签也只需要上万个键\n\n##### 存储所有用户\n\n但是我们如果需要查找不属于某个标签的用户怎么办啊,如果直接对上一个例子取反肯定是不行的\n\n为了解决这个问题我们需要一个存储所有用户的键\n\n我们知道了所有用户,知道了拥有某标签的用户\n\n        不含某标签的用户 = 总用户 - 含有某标签的用户\n\n用二进制的操作方法就是使用`异或`, 举例:\n\n我们有7个用户(编号1-7),5号用户是超级vip,我们要查找所有不是vip的用户可以使用下面的运算\n\n```php\n01111111 ^ 00001000 = 01110111 // 127 ^ 8 = 119\n// 01111111:所有用户的二进制键  00001000:5号用户是超级会员的键 01110111:所有不是超级会员的用户\n```\n以上操作我们就能得到所有不是超级会员的用户\n\n##### 存储某用户的所有标签\n\n我们如果要获得用户的所有标签,也可以将用户拥有的标签id在用户标签键中所对应的位置置为1,这样每一个用户的表示所有标签的键的最大位长度就是固定的,比如:\n\n我们可以用如下方式存储用户的所有标签\n\n```php\nusertag:all:1 => 01101010  // 1号用户的所有标签\nusertag:all:5 => 00010110  // 5号用户的所有标签\n```\n\n这样我们就能使用bitmap来满足以上基本查询需求\n\n同样我们也可以将所有标签存储成一个`usertag:alltag`键, 再使用异或运算计算某用户不含有的标签\n\n### 实现方案\n\n我们如果自己来对位运算做管理就有点麻烦了,我们可以借助`redis`\n\n`redis`原生提供了可以对字符串进行位操作的命令,具体如下\n\n```shell\n    SETBIT key pos value  // 将 key 的第 pos 位设为 value(只能取1/0)\n    GETBIT key pos        // 获取 key 的第 pos 位的值\n    BITOP cmd key1 key2 key3 ... // 对 key2,key3 等执行 \n    BITOP AND destkey srckey1 srckey2 srckey3 ... srckeyN\n    BITOP OR destkey srckey1 srckey2 srckey3 ... srckeyN\n    BITOP XOR destkey srckey1 srckey2 srckey3 ... srckeyN\n    BITOP NOT destkey srckey\n    BITPOS key bit start end  // 将 key 的 strat 到 end 位全部设为 bit(0/1)\n    BITCOUNT mykey 1 1\n    BITFIELD mystring SET i8 #0 100 i8 #1 200\n```\n\n我们就直接使用`redis`来存储数据了,这样方便点\n\n### 预处理\n\n我们这边为了方便直接使用redis提供的`setbit`,`getbit`和`bitop`来进行字符串的位操作\n\n因为我们要存储用户标签,所以我们首先需要对用户和标签进行编号,这样我们需要两个表\n\n用户表:\n\n|uid|name|\n|:-|:-|\n|1|小明|\n|2|小花|\n|3|小江|\n|4|小红|\n|5|小九|\n|6|小七|\n|7|小四|\n\n标签表:\n\n|tid|name|备注|\n|:-|:-|:-|\n|1|vip|是否vip|\n|2|mobile|是否绑定手机|\n|3|email|是否绑定邮箱|\n|4|male|是否男性|\n|5|mac|是否使用Mac|\n|6|supervip|是否年费会员|\n|7|lost|是否易流失用户|\n\n### 存储\n\n我们这里为了性能考虑使用redis来进行存储\n\n我们将最上面的表格数据转换成以下键值对\n\n```json\n\n{\n    // 所有用户\n    \"user:all\":{\n        \"01111111\"\n    },\n    // 所有vip用户\n    \"user:vip\":{\n        \"01001001\"\n    },\n    // 所有绑定了手机的用户\n    \"user:mobile\":{\n        \"01101010\"\n    },\n    // 所有绑定了邮箱的用户\n    \"user:email\":{\n        \"00001010\"\n    },\n    // 所有男性用户\n    \"user:male\":{\n        \"01010011\"\n    },\n    // 用户1的所有标签\n    \"usertag:all:1\":{\n        \"01101010\"\n    },\n    //用户2的所有标签\n    \"usertag:all:2\":{\n        \"00100001\"\n    }\n}\n\n```\n\n### 查询操作\n\n我们可以使用redis的命令`getbit`来查询某个键的某个位置的值   \n比如,我们要查询5号用户是否具有vip标签,可以使用以下命令   \n```php\n$ getbit user:vip 5 // 返回 0\n```\n要查询某用户身上的所有标签可以使用如下   \n\n```php\n$ get usertag:all:1 // 获取用户1的所有标签 返回'01101010'\n```\n我们如果要获取某标签下的所有用户可以使用如下命令   \n```php\n$ get user:vip // 返回一个二进制字符串 类似 '01001001'\n```\n查询不具有某个标签的用户   \n```php\n$ bitop xor user:not_vip user:all user:vip // 根据所有用户和具有标签的用户进行异或运算,得到不含有某标签的用户\n$ get user:not_vip // 返回二进制字符串\n```\n\n我们现在知道如何快速的获取我们想要的数据了,但是我们发现有时候我们获取到的都是二进制的数据例如 `00001000` 这种,而群殴们想从这样的数据中获取的是 `[5]` 这样的比较易读的信息\n\n我们需要有一个将二进制字符串 转化为对应位置为1的位置数组的形式\n\n如: function(`01001010`) => `[1,4,6]` \n\n### 结果解析\n\n这里我们提供两个函数来进行这样的操作\n\n1. 遍历法\n\n我们遍历二进制字符串中的每一位, 每遇到一个为1的位置就将该位置放入数组\n\n这种方法比较慢,不建议使用,这里贴一个示例代码\n\n```python\n    def key2array(self, key):  # 将二进制('\\x05'->'0b00000101')变为数组[5,7], 表示第五位和第七位为1\n        tmpstr = ''.join([bin(i).replace('0b', '').zfill(8) for i in key])\n        arr = []\n        str_len = len(tmpstr)\n        for i in range(0, str_len):\n            if int(tmpstr[i]) == 1:\n                arr.append(i)\n        return (arr)\n```\n2. 查表\n\n我们可以观察一下redis返回的二进制数据的特点, 每8个二进制位属于一个字节,每个字节都可以表示成具体的数字(如:0,23,127)这个数字最大也只能到255,而且同一个数字有可能出现非常多次,而每个数字所对应的转换过后的位置数组都是固定的,比如: 100(二进制:1100100) => [1,2,5]\n\n我们可以利用这一点,提前制作一个 `0-255`的所对应的位置表,然后每次处理8位,处理完把当前处理的位数加上新表中对应的值就可以快速的得到这个值了\n\n> ps: 我们也可以扩大这个表的容量以提高速度\n\n贴下示例代码:\n\n```python\n    def build_bit_table(self):  # 生成0-255的表\n        arr = []\n        for i in range(0, 256):\n            tmp_arr = []\n            tstr = bin(i).replace('0b', '').zfill(8)\n            n = 0\n            for k in tstr:\n                n = n + 1\n                if int(k) == 1:\n                    tmp_arr.append(n)\n            arr.append(tmp_arr)\n        self.bit_table = arr\n\n    def key2array(self, key):  # 查表法\n        arr = []\n        n = 0\n        for i in key:\n            pos = self.bit_table[i]\n            for k in pos:\n                arr.append(n + k - 1)\n            n = n + 8\n        return (arr)\n```\n\n> ps:jdk中的BitSet就是对bitmap的一种简单实现\n\n## 如果标签过于稀疏会不会浪费空间?\n\n如果我们在一个很长的bitmap中只存除了极少量的数据是不是会对空间造成浪费呢?\n\n例如: 在bitmap的第40000位置为1,那存储的数据大概就类似: 00000000000...0000000001\n\n这样的数据前面的39999位都是0,不会浪费空间吗\n\n### Google的EWAHCompressedBitmap\n\nGoogle的EWAHCompressedBitmap就对这种情况做了优化\n\nEWAHCompressedBitmap 将整个的二进制数据分成每64位一个的word\n\n一个空的Bitmap默认拥有 4 个word 也就是 `4*64` 位\n\n其中 word0 存储bitmap的头信息\n\n当我们改变对应位置的比特位的值时 word 会跟着变化\n\n当我们插入的值非常大的时候(例如:40000), 算法会根据当前的值 创建两个新的word \n\n一个用于存储第40000个数据所在的word的信息(LW), 还有一个存储跨度信息(称为:跨度word /RLW )\n\n假如说我们给一个空的bitmap,我们插入40000的话正常情况下会有6个word,前4个是头信息word+3个空word,第6个中保存40000这个数字所在的位置信息,第5个word中保存从第 4-625 word的跨度信息,第626word中存储有 40000 这个数据 \n\n>ps: 第一个word存储头信息, 625 = floor( (40000 + 1) / 64 ) \n\n存储跨度信息的word和普通的存储数据的word虽然空间一样但是存储的内容不一样\n\n存储跨度信息的word大概内容这样\n\n        前32位存储 `当前跨度word(RLW)横跨了多少空word`\n\n        后32位存储 `当前跨度word(RLW)后方有多少个连续的LW`\n\n当我们存储 位置在跨度word(RLW)之中的数据(例如:20000), RLW会进行分裂\n\n变成3个word,中间一个存储20000所在的LW信息,前后各有一个RLW保存新的跨度信息\n\nEWAHCompressedBitmap对应的maven依赖如下：\n\n        <dependency>\n          <groupId>com.googlecode.javaewah</groupId>\n          <artifactId>JavaEWAH</artifactId>\n          <version>1.1.0</version>\n        </dependency>\n\n","categories":["系统设计"],"tags":["bitmap","标签系统"]},{"title":"程序语言不是工具","url":"/2017-12-29-programming-languages-are-not-tools/","content":"\n原作者： 王垠\n原文： http://www.yinwang.org/blog-cn/2013/04/21/programming-languages-are-not-tools\n\n# 程序语言不是工具\n\n在谈论到程序语言的好坏的时候，总是有人说：程序语言只是一种工具。只要你的算法好，不管用什么语言都能写出一样好的程序。在本科第一堂编程课上，我的教授就这么对我们说。可是现在我却发现，这是一个根本错误的说法。\n\n我不知道这种说法确切的来源，然而昨天在浏览网页的时候，偶然发现了 C++ 的设计者 Bjarne Stroustrup 的一些类似的说法。这些说法来自于 2007 年 MIT Technology Review 对 Stroustrup 的采访。\n\n>问：一个好的语言是什么样的？\n>Stroustrup：所有能帮助人们表达他们的想法的东西都会让语言更好。一个语言在一个好的工匠手里应该能胜任每天的任务。语言是否优美是次要的问题。被认为是丑陋的语言开发出来的有用的系统，比优美的语言开发出来的系统要多得多。\n\n>问：优雅难道不重要吗？\n>Stroustrup：优雅很重要，可是你如何衡量\"优雅\"？可以表达问题答案的最少字数？我觉得我们应该看构造出来的应用程序的优雅程度，而不是语言自身的优雅程度。就像你不能把木工的一套复杂的工具（很多是危险的工具）叫做\"优雅\"一样。但是我的餐桌和椅子却真的很优雅，很美。当然，如果一个语言本身也很美，那当然最好。\n\n## 一些基本的错误\n\n对这两个回答，我都不满意，我觉得这只是他对于 C++ 的恶劣设计的借口而已。下面我对其中几个说法进行质疑：\n\n所有能帮助人们表达他们的想法的东西都会让语言更好。\n\n作为一个程序语言，并不是好心想”帮助人”就可以说是好的。如果是这样的话，那么我就可以把所有国家的脏话都加到你的语言里面，因为它们可以帮助我们骂人。\n\n被认为是丑陋的语言开发出来的有用的系统，比优美的语言开发出来的系统要多得多。\n\n系统的数量再多也不能说明这个语言好。正好相反，众多的系统由于语言的一些设计失误，把人们的生命置于危险之中，这说明了这个语言的危害性之大。一种像炸药一样的语言，用的人越多越是危险。\n\n## 语言不是工具，而是材料\n\n我这篇文章想说的最关键的部分，其实是他所支持的”语言工具论”的错误。\n\nStroustrup 说：\n\n我觉得我们应该看构造出来的应用程序的优雅程度，而不是语言自身的优雅程度。就像你不能把木工的一套复杂的工具（很多是危险的工具）叫做”优雅”一样。但是我的餐桌和椅子却很优雅，很美。\n\n他的言下之意就是把程序语言比作木工的工具，而餐桌也椅子就是这些工具做出来的产品。比方的威力是很大的，很多人一见到大牛给出这么形象的比方，想都不用想就接受了。如果你不仔细分析的话，这貌似一个恰当的比方，然而经过仔细推敲，这却是错误的比方。这是因为程序语言其实不是一种”工具”，而是一种”材料”。\n\n木工不会把自己的锯子，墨线等东西放进餐桌和椅子里面，而程序员却需要把语言的代码放到应用程序里面。虽然这些程序经过了编译器的转化，但是程序本身却仍然带有语言的特征。这就像一种木材经过墨线和锯子的加工，仍然是同样的木材。一个 C++ 的程序在编译之后有可能产生内存泄漏和下标越界等低级错误，而更加安全的语言却不会出现这个问题。\n\n所以在这个比方里面，程序语言所对应的应该是木工所用的木料，钉子和粘胶等”材料”，而不是锯子和墨线等”工具”。这些材料其实随着应用程序一起，到了用户的手里。那么对应木工工具的是什么呢？是 Emacs, vi, Eclipse, Visual Studio 等编程环境，以及各种编译器，调试器，make，界面设计工具，等等。这些真正的”工具”丑一点，真的暂时无所谓。\n\n现在你还觉得程序语言的优雅程度是次要的问题吗？一个复杂而不安全的语言就像劣质的木料和粘胶。它不但会让餐桌和椅子的美观程度大打折扣，而且会造成它们结构的不牢靠，以至于威胁到用户的生命安全。同时它还可能会造成木工的工作效率低下以及工伤的产生。\n\n这也许就是为什么我的一个同事说，他看 C++ 代码的时候都会带上 OSHA（美国职业安全与健康管理局）批准的护目镜。\n","categories":["编程学习"],"tags":["编程语言"]},{"title":"分布式服务组内分享","url":"/2017-11-02-distribute-database-share-in-group/","content":"\n这个是写给组内成员的分布式知识简单分享\n\n# 什么是分布式\n\n什么是集群? 什么是分布式?    \n集群:   一个任务多个人可以做(实际是一个人做), 集群的主要目的是高可用, 通过冗余解决单点故障问题   \n分布式: 一个任务拆分成多个部分由多个机器来做, 解决业务解耦, 水平扩展和性能问题   \n\n几个典型的分布式系统:\n\n|名称|类型|数据分布方式|故障转移|底层存储|节点类型\n|-|-|-|-|-|-|\n|kafka|消息系统|broker->partition|partition选举|file|对等节点|\n|redis|缓存|instance->shard|sentinal选举|memeory|对等节点|\n|es|搜索服务|node->shard|master选举和partition选举|file|对等节点|\n|Tidb|数据库|TiDB+TiKV+PD|node选举|file|非对等节点|\n|hdfs|文件系统|namenode+datanode|主从|file|非对等节点|\n\n节点类型：对等节点是说节点之间功能相似，非对等节点是说节点之间功能不同，无法互相取代\n\n# 分布式要解决的常见问题\n\n分布式要满足三个特性之二 CAP(C:一致性, P:分区容忍性, A:可用性)\n\n- 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本），换句话就是说，任何时刻，所用的应用程序都能访问得到相同的数据。\n- 可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性），换句话就是说，任何时候，任何应用程序都可以读写数据。\n- 分区容错性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择，换句话说，系统可以跨网络分区线性的伸缩和扩展。\n\nCAP三个特性不可能同时满足, 只能同时满足两个特性    \n对大多数的分布式应用来说 CAP中的 P 是必不可少的    \n所以我们一般都会从CA中选取一个, 一般会选择CP 或者 AP   \n\n具体处理cap协议的方法如下图\n\n![cap](cap.jpg)\n\n# 如何解决分区容忍性\n\n解决分区容忍性问题首先就是对数据进行分区或者叫分片\n\n分区手段有很多, 但大多分两种, hash分区和线性分区    \n系统将数据分为逻辑上的几个区块, 每个区块可以在多个机器上进行自由的部署和移动    \n这样就做到了将数据和机器进行隔离, 可以以分片为单位在不同机器上进行数据的移动和备份   \n但是这样在使用数据的时候就需要从多个分片同时获取数据进行合并 \n如果因为某些原因， 导致某些分片所在的节点出现故障， 此时我们就认为出现了网络分区， \n分区容忍性要求在此种状况下，系统依然能对外提供有效服务 \n\n## Gossip\n\n使用者: Redis\nGossip协议是节点将自己的数据通知给集群内所有节点的协议, 但是不能做到数据一致性\nGossip只能保证可用性和分区容忍性\n\n如果对数据的分片进行备份, 同时将备份分布到多个不同的网络节点上, 这样即便部分数据分区不可用, 在可容忍的范围内只要不是该分区的所有数据分片都出问题, 还是能提供正常的数据服务  \n\n数据分片是分布式存储的基础, 数据分片好处很多    \n\n1. 对数据分片可以使数据不受单机存储制约\n2. 对数据分片可以通过多分区共同协作并行处理提高性能\n3. 对分区数据进行冗余可以提高系统可用性\n\n但是数据分片和副本会带来一致性问题\n\n# 如何保证数据一致性\n\n## 单节点的数据一致性\n\n单节点如何保证数据一致性和完整性\n\n比如: 数据库索引的更新, B树在分裂过程中出现问题怎么办, \n\n一般处理单节点的一致性可以用 WAL(预写日志,或者叫redo日志) 或者 写时复制(copy on write)\n\nWAL就是先把操作追加到一个日志文件, 然后再对内存进行操作, lsm树中的memtable就是典型的使用这种方案\n\n写时复制就是先在其他地方把数据处理完毕, 最后直接修改数据引用, gfs的快照技术有使用类似的方案\n\n典型的例子是 修改B+树时预先生成一个小的B+树, 然后直接替换B+树上的节点指针\n\n## 分布式的一致性\n\n\n### 主从一致性\n\n目前业界的普遍做法是将分区的多个副本形成一个小组, 组内选举一个primary副本来执行写操作或确定写入顺序, 其他副本仅提供读操作或根本只提供备份功能, 这样对外部系统只有一个主副本做写入操作, 就可以保证数据写入的一致性\n\n如何从多个副本集合中选举主副本就涉及到共识算法（选主算法），常见的共识算法有 `Paxos`,`Raft`,`Zab协议`,`Bully` 等\n\n### NRW算法\n \nNRW是一种特殊的保障一致性的算法, 通过饱和读取策略充分保证数据读取的一致性，具体详情如下:   \n\n    R(读取分片数) + W(写入分片数) > N(节点总分片数)\n\n只要满足以上公式, 我们必然可以拿到一个正确分片的数据\n举例: 我们对某个数据有5个分片, 我们只要保证 写入分片为3,读取分片为3,这样,我们必然可以保证读取的分片其中有一个含有最新的数据 \n\n# 如何处理可用性\n\n实现高可用一般都是通过节点或数据备份来实现, 采用主从或主备节点, 主节点或主分片不可用, 就采用副本分片或备份节点替代原有的服务\n\n# 分布式事务\n\n解决分布式事物要处理ACID 四个问题，常用如下方式\n\n1. 2PC, 使用者: mysql, 两阶段提交协议\n2. 3PC, 三阶段提交协议, 二阶段提交协议的优化\n3. TCC  事务补偿\n\n# 使用经验\n\n### 如何设置合理的分区和副本数量\n\n1. 其实对于副本数量的设置一般取决于副本的用途\n\n如果你副本只做备份，不对外提供读取服务，那设置3个是比较理想的情况，因为3个副本足以覆盖副本所有的可能状态（可用，不可用，升级中），也就是说只要有3个副本， 就一定有一个副本处于可用状态\n\n如果副本同时提供读功能， 那可以酌情增加副本数量\n\n2. 分片的设置\n\n其实针对不同的系统，不通的分片方式，分片设置有各自的考虑，不过一般受以下因素影响\n\n* 数据量\n* 分布节点数量\n* 使用者数量\n* 数据同步和网络开销\n","categories":["编程学习"],"tags":["分布式"]},{"title":"浅谈Kafka消息系统","url":"/2017-11-01-kafka-share-in-group/","content":"# kafka分享\n\n听闻kafka已经是很早之前的事情了\n\n在2016年的时候, 就在一次我们公司的数据团队的内部分享中听过他们基于kafka做的一套数据处理系统\n\n不过当时我对他的认知还仅仅知道是一个能处理海量数据的消息队列服务\n\n后来随着深入使用才发现kafka其实不仅仅是纯粹的消息队列, 而是一种分布式消息系统甚至于流处理平台(基于scala开发)\n\n## 消息传递在现代业务中的地位\n\n**面向对象的程序 = 对象 + 消息传递**\n\n消息系统在我们业务中的重要性由此可见, 消息系统可以作为系统与系统进行交互,或者对业务进行解耦的一个利器\n\n我们通常会把许多实时性要求不那么高的任务处理通过消息系统进行解耦,以平衡数据处理的性能和功能\n\n例如: 用户下了一个订单,我们需要马上告诉用户下单成功, 但是之后的物流发货, 订单入账和商品信息更新等消息都可以通过一个消息系统进行拆分,这样不仅不会影响用户体验,也可以对之后触发的多个属于不同系统的业务进行并行处理,提升系统处理的性能\n\n# Kafka基础介绍\n\nkafka作为一个消息平台, 其中有一些基础概念跟传统的消息队列服务对应\n\n```\nbroker(instance)    承载服务的实例\ntopic (queue)  \t\t逻辑上的消息通道\npaitition(sharding) 一个消息通道进行存储的区域(物理上的,本质是对应着一个文件序列)\nconsumer       \t\t消费者 (通常指客户端的使用者)\nproducer       \t\t生产者 (也是客户端的使用者)\nconsumer group   \t消费者组 (虚拟概念, 消费者的逻辑分组)\n```\n\n**broker**\n\nbroker就相当于我们的kafka实例, 每个集群由多个broker组成, 每个broker具有完整的存储消息的功能, 多个broker可以组成broker集群, 但是这些实例不一定要分布在不同的机器上(虽然我们建议不要在同一个机器上部署多个broker)\n\nbroker是链接`producer`和`consumer`的中间桥梁, 是消息真正的存储者, producer将消息发送给broker, broker对消息进行存储, 等待consumer消费和使用消息，kafka的性能, 很大程度上取决于broker参数配置\n\n**topic**\n\ntopic就相当于其他消息队列中的queue, 我们发送消息需要指定topic, 读取消息也需要指定topic, 同一个topic可以有多个生产者和多个消费者\n\ntopic是一个逻辑上的概念, 每个topic由至少一个或多个partition组成, 每个partition保存topic内的`一部分`消息。topic内的消息无法保证有序, 除非只有一个partition\n\n**partition**\n\npartition相当于是topic内部的一个分片 \n\n假如说我们有个topic其中有5个patition, 一个消息在每个topic中只会存储在一个patition中, 整个topic的消息等于该topic下所有partition的总和 \n\n每个partition至多只能有一个消费者, topic下的总消费者数量也受限于partition, 比如你topic有10个分片, 如果使用12个消费者就会有两个消费者永远获取不到数据  \n\n每个partition是一个文件集合, 集合内同一时刻只有一个文件可写入数据，单个partition里面的数据因为这个关系可以保持有序  \n\npartition还可以有自己的replication，replication只有一个功能, 就是提供数据冗余, 防止partition出问题时造成数据丢失 。不过同一个partition的多个replication中同一时间只能有一个primary replication(通过选举得出)，由这个primary  replication来执行整个partition的数据操作\n\n**consumer**\n\n每个消费者可以消费一个topic的一个partition, 可以同时消费多个topic\n\nconsumer数量如果超过一个topic的分片数量, 会造成某些consumer永远消费不到数据\n\n消费者消费数据需要提交offset告诉broker自己已经消费过某条数据\n\n当topic新增一个consumer的时候会触发其他消费此topic的consumer group内consumer的`Rebalance`, 重新在consumer之间重新进行分区分配\n\n**consumer group**\n\n消费者组也是一个逻辑上的概念, 每个消费者组内的消费者只能消费同一个topic内的某一条消息一次, 除非进行手动offset调整重新消费\n\n如果某个topic中的数据希望同时给多个业务方使用, 每个业务方应该使用一个单独的consumer group\n\n**producer**\n\n每个生产者可以为一个或多个topic生产数据, producer只负责将数据发送给broker, 后续操作通通由broker来负责\n\n# kafka的主要应用何特点\n\n**常见应用场景**\n1. 消息队列：kafka通常被用作消息队列, 这也是kafka的主要用途之一, 因为他可以一定程度上保证消息的可靠和有序\n2. 日志/消息存储：kafka由于基于文件存储, 所以很适合用来存储日志信息, 通知消息等有序且数据巨大的信息\n3. 数据总线：kafka还适合在不同的存储系统和业务之间做数据总线, 这样可以方便的把一份数据传递给多方公用\n**优点**\n\n\t1. 增加了partition层, 高度解耦, 支持分布式, 支持副本, 扩展方便\n\t2. 基于文件存储消息, 采用文件指针的读方式, 速度快, 且可重复读\n\t3. 保证多消费者情况下消息的有序性\n\t4. 在producer, broker, consumer三者做了大量性能优化,例如:`cache buff`和`sendfile()`等\n\nkafka的大部分分布式特性都得益于partition的设计,由于采用了文件集合来存储每一个partition,使得kafka在性能和有序性方面获得了巨大的优势\n\n**kafka作为消息队列的缺点**\n\n\t1. 只有topic一个逻辑隔离级别\n\t2. 高并发依赖于partition数量限制, 扩展不是特别的方便\n\t3. 没有消息优先级机制\n\t4. 数据中心级别的数据同步不成熟\n\t5. 功能和数据存储系统没有隔离开\n\n同时也由于kafka的部分设计不可避免的有一些缺点\n\n由于partition的限制, 应对高并发场景, 如果需要加快一个topic的处理速度只能通过增加消费者的方式, 这个增加过程又不像其他内存式的消息队列来的方便\n\n相比于很多传统消息队列服务, kafka也没有消息优先级的机制\n\nkafka的竞争对手Apache Pulsar在后两点比kafka要更加优秀, 且在很多基础功能上提供了更多的选择性\n\n# kafka大概工作流程示意图\n\n![大概示意图](kafka1.png)\n\nkafka中的一个完整的消息流程如上图所示\n\nProducer将消息发给broker中的topic,存储到topic下的某一个partition\n\nConsumer从partition中消费数据,将该消费者在该topic中的数据偏移标记为最新\n\n# kafka为什么这么快\n\n1. 吞吐量和延迟\n\n吞吐量和延迟是一个kafka的平衡选择\n\n吞吐量大, 延迟就高, 延迟高, 吞吐量就小\n\n这个需要自己做抉择, kafka一定程度上选择了用牺牲延迟换吞吐量\n\nkafka在producer和broker中都使用了`cache buff`的方式来增加吞吐量\n\n2. 零拷贝\n\nkafka的broker发送数据时采用零拷贝技术, 减少了一次内部的从用户态到内核态的状态切换过程, 使用`sendfile`将文件直接通过内存地址发送给网卡\n\n3. 基于文件的追加方式\n\nkafka采用追加文件记录的形式来处理数据, 这种方式要比随机读写快上很多  \n\n4. buff发送\n\n对发送的文件进行了了缓冲区处理, 缓冲区满了以后或者到了一定时间才会发送数据\n\n相当于对发送信息做了批处理\n\n## kafka和ZooKeeper\n\nkafka 使用zk存储一些关键配置信息\n\n如: 某个topic的消息总量, 每个partition的消费数据等信息,消费者消费的记录offset等都存储于zk\n\n许多的kafka监控应用也都是通过读取zk中的kafka数据来进行监控的\n\n> ps: kafka新版本中已经允许客户端提交offset到kafka的topic中\n\n具体保存消息的节点路径如下图: \n\n![kafka信息在zk中的保存方式1](kafka_zk.jpeg)\n\n![kafka信息在zk中的保存方式2](kafka_zk2.jpeg)\n\n# kafka数据存储\n\nkafka的数据存储大致分为三层, broker, partition, segment\n\nkafka配置文件中的 server.properties中的以下属性指明了kafka的数据存储位置\n\n`log.dirs=/usr/local/var/lib/kafka-logs`\n\n具体如下图:\n\n![kafka存储](kafka_store.jpeg)\n\n一个broker中虽然可以随处多个topic数据, 但是真正的存储还是要落实到 segment上   \ntopic和partition只能决定存放segment的上层文件夹的名字\n\n## segment内的存储细节\n\n![kafka文件](kafka_segment.jpeg)\n\n一个topic的一个partition拥有多个segment file, 每个segment file拥有多个部分 \n\n一般由以下四个类型文件组成\n\n```\nxxx.index  \t\t\t\t\t\t//segment的索引文件\nxxx.log    \t\t\t\t\t\t//segment的数据文件\nxxx.timeindex            \t\t//segment的时间索引\nleader-epoch-checkpoint   \t\t//检查点文件\n```\n\n# 使用kafka遇到的问题\n\n**1.kafka的topic不消费**\n原因：\ntopic中的消息容量是有限制的,假如短时间内某topic中进入了大量的消息\n消费者来不及消费可能导致消费者的消费offset小于当前topic的最小消息偏移\n\n举例: \n假如我们topic最大可以存储200万消息,消费者每分钟消费30万的消息\n现在有个入消息的接口每分钟入100万的消息,那topic, consumer就会产生如下问题\n\n```java\n\t\t{\n\t\t\t\"topic\":{\n\t\t\t\t\"start\": 211450, // 当前topic消息最小值\n\t\t\t\t\"end\": 2211450, // 当前topic的消息最大值\n\t\t\t},\n\t\t\t\"consumer\":{\n\t\t\t\t\"topic1\": 311450, // 消费者在topic中的消费位置\n\t\t\t}\n\t\t}\n\t\t// 然后等了一分钟\n\t\t{\n\t\t\t\"topic\":{\n\t\t\t\t\"start\":2211450,// 当前最小的消息值\n\t\t\t\t\"end\":4211450,// 当前最大的消息值\n\t\t\t},\n\t\t\t\"consumer\":{\n\t\t\t\t\"topic1\": 461450, // 消费者当前的消费消息位置\n\t\t\t}\n\t\t}\n```\n\n也就是说消费者的消费值在内存中的topic中找不到了.因为消息入得太快,消费者跟不上,当前消费消息,被\"顶\"出去了\n\n解决方案:\n\n1. 可以手动设置消费者的消费位置,将其置为 当前topic中可以找到的消息偏移位置\n2. 可以重新设置消费方式,这种方式也是变相将该消费者在该topic的消费位置重置\n\n**2.kafka的topic不能直接删除**\n\n原因: 因为要删除一个topic必须符合两个条件\n1. 无消费者消费  \n2. 文件中无消息记录,普通的删除只能删除文件中的消息记录,无法删除消费者得消费信息\n\n方案: 将该topic的所有消费者消费偏移置为0 ,然后执行删除，或者使用kafka tool工具可以直接删除\n\n**3.kafka的分片数据分布不均匀**\n\n原因: kafka早期的算法会根据key的hash值来对消息进行分配\n如果没有key可能会被分配至随机的一个固定的partition中\n这样会导致topic中的消息分布不均匀,\n\n方案: 1. 可以更改分配算法 2. 使用时间戳作为key的结尾 \n\n**4.kafka的消费者分组的使用**\n\n描述: 由于每个消费者分组中的topic只能被消费一次\nkafka可以通过消费者分组来对某一topic中的数据进行重复消费\n我们可以通过给不同部门设置消费者分组来实现类似订阅的机制\n\n举例: 我们有一个订单消息队列, topic为 `order-topic`\n我们可以通过给 订单部门和 物流部门 分配不同的消费者分组\n来对同一个topic中的消息进行重复消费\n\n# Kafka的高级特性和流处理\n\n* kafka事务\n\nkafka现在已经支持事务, 这个是kafka一致性保证的重大进步\n\nkafka的事务目前还有一定的限制, 实现方式是使用 事务ID和客户端id做幂等处理\n\nkafka事务流程：\n\n1. 生产者发起事务请求\n\n2. 发送消息\n\n3. 服务器接受数据,进行追加写入\n\n4. 生产者结束事务\n\n如果客户端没有结束事务, kafka虽然将数据写入到了broker,但是不会让其他消费者客户端读到这部分数据\n\n这部分数据在kafka上会被标记为abort掉的数据\n\n* kafka多版本混布\n\nkafka现在支持多个kafka版本混合部署, 可以同时使用1.0 和2.0 版本组建一个kafka集群\n\n* 流处理\n\n什么是流? 流一个无限持续的数据集，比如 用户的行为数据\n\n流处理的目的是尽可能的保证业务处理的实时性，就是事件一旦发生我们就希望立刻处理\n\n目前常见的流处理框架有 spark, storm, flink等，kafka streaming与他们相比显得更为轻量和易用\n\n流处理更像业务逻辑的一部分, 而不是业务的分拆, 是一个独立的微服务, 而不是MapReduce任务\n\n* 流处理的常用方法\n\n流处理常用的方法有 `filter /map /join /aggregate`\n\n其中 `map/filter` 属于对单个数据进行的无状态操作\n\n`join/aggregate` 属于数据统计需求, 有一定的状态要求\n\n此外还有`window函数`等\n\nkafka stream作为一个库的形式像我们提供了以上各种方法, 使得我们使用起来非常容易\n\n* 使用kafka streaming的一个场景\n\n例如在产品池项目中, 我们用 kafka stream 从canal的事件消息topic中接收数据  \n\n从中根据不同的消息内容将事件按照`库和表`发送给不同的后续topic, 达到了消息路由的功能  \n\nkafka stream将三个不同来源的topic中的待更新产品信息融合到同一个 待更新的产品信息Topic中  \n\n* Kstream和Ktable\n\nkafka向我们提供了以下两个概念方便我们进行流处理\n\n1. KStream\n\n一个纯粹的流就是所有的更新都被解释成INSERT语句(因为没有记录会替换已有的记录)的表。\n\n在一个流中(KStream)，每个key-value是一个独立的信息片断，比如，用户购买流是：alice->黄油，bob->面包，alice->奶酪面包，我们知道alice既买了黄油，又买了奶酪面包。\n\n>ps: 表中每条记录的变动就是一个流\n\n2. KTable(changelog流)\n\nKTable 一张表就是一个所有的改变都被解释成UPDATE的流(因为所有使用同样的key的已存在的行都会被覆盖)。\n\n对于一个表table( KTable)，是代表一个变化日志，如果表包含两对同样key的key-value值，后者会覆盖前面的记录，因为key值一样的，比如用户地址表：alice -> 纽约, bob -> 旧金山, alice -> 芝加哥，意味着Alice从纽约迁移到芝加哥，而不是同时居住在两个地方。\n\n>ps: 对某一时刻的流数据进行切面,按时间对数据进行覆盖,那个切面数据就是表\n\n这两个概念之间有一个二元性，一个流能被看成表，而一个表也可以看成流。\n\n我们一般用KStream来支持流式处理功能，同时使用KTable支持批处理功能作为补充，两者互相结合可以满足大部分的业务处理场景\n\n同时KTable 还提供了通过key查找数据值的功能，该查找功能可以用在Join等功能上。\n\n总的来说kafka streaming做为流式处理系统跟老牌的spark streaming/flink还有一定的差距，但是很适合轻量级的数据处理场景\n\n还是拥有一定的市场空间","categories":["工具使用"],"tags":["Kafka"]},{"title":"给团队成员的Redis分享总结","url":"/2017-10-29-redis-share-in-group/","content":"# redis分享\n\nAuthor:   leriou lee       2017.10.12\n本篇内容主要是针对团队成员的redis中间件分享\n\n目的是帮助不熟悉redis的团队成员快速的了解redis，对redis大概有一个了解  \n已经使用过redis的能对其有进一步的了解，以及总结了一些遇到的业务问题和解决方案\n\n# redis基础\n\n1. redis是什么\n\n`redis`是一个使用c语言开发的k-v存储系统,其实不仅仅作为缓存,由于`redis`内部的底层数据结构设计的非常完善\n\n我们也可以把`redis`作为一个现成的数据结构实现集合,只要了解`redis`内部的基础数据结构和实现,我们就能利用它做很多事情\n\n比如我们想利用某种数据结构的特性(例如:跳跃表),又不想自己实现,就可以在`redis`的基础之上构建业务\n\nredis目前支持5种数据对象, 基本可以满足大多数的业务场景\n\n>ps: 现在5.0发布已经有6种了\n\n2. redis的大致工作流程\n\n\t1. 启用redis-server,使用socket服务监听端口(redis服务端)\n\t2. 客户端启用socket连接到服务器,通过认证,服务器维护client的信息(使用链表持有)\n\t3. 客户端发送命令, 服务器接收到命令根据命令表进行执行和查找等,返回结果(将结果保存到client的输出缓冲区)\n\t4. 客户端解析服务器返回的结果\n\n3. redis能做什么\n\nredis作为一个缓存中间件, 可以帮助我们解决很多业务中遇到的问题,由于redis内部功能机制比较丰富,其实不仅仅可以作为简单的缓存中间件使用\n\nredis可以作为高速的k-v存储，非常适合存储一些直接针对用户的应用数据，或者进行用户行为统计。 比如：对用户进行限流，统计用户访问量\n\n4. 基于redis可以解决的一些常见问题\n\nredis可以帮助我们解决很多业务中的问题,下面简单列举一下\n\n* 作为服务间的共享空间或临时存储，解决数据共享问题 例如: 计数器,注册器/协调器,在分布式应用中做桥接\n\n\t由于redis是一个独立的服务,不依赖任何其他的服务,同时又具有高效的存储功能\n\t我们可以用redis在不同的应用和系统服务之间进行简单的数据传递,或者存放部分中间数据\n\t相当于多个服务之间的共享内存,我们可以\"使用共享内存来通信\"\n\n*为高读写要求的场景提供数据存储，解决性能问题  例如: 热点数据缓存/流量控制(漏桶和令牌桶)\n\n\tredis由于是一个内存数据库,读写速度执行非常的快\n\t在一个最低配的的阿里云机器上可以达到8w/s的ops,非常适合用来处理一些对读写性能要求极高的场景\n\t比如:部分热点商品数据,秒杀活动,流量控制等\n\n*其他可以利用redis特性的场景，解决业务问题    例如: 搜索/bitmap/数据匹配/消息队列/发布订阅\n\n\tredis内部还有很多的特殊机制实现了比较丰富的功能, 如:发布订阅.\n\t我们也可以利用redis的一写数据结构特性来构建倒排索引,以实现简单的搜索功能 \n\t也可以利用list的数据结构的特性实现简单的消息队列\n\n# Redis的读写流程\n\n* 通信协议RESP\n\nRESP协议在Redis 1.2中引入，但它成为与Redis 2.0中的Redis服务器通信的标准方式。 这是每一个Redis客户端中应该实现的协议。\n\nRESP实际上是一个支持以下数据类型的序列化协议：单行字符串，错误信息，整型，多行字符串和数组。\nRESP在Redis中用作请求 - 响应协议的方式如下：\n\n客户端将命令作为字符串数组发送到Redis服务器。\n服务器根据命令实现回复一种RESP类型数据。\n在 RESP 中, 一些数据的类型通过它的第一个字节进行判断：\n\n单行回复：回复的第一个字节是 “+”\n\n错误信息：回复的第一个字节是 “-“\n\n整形数字：回复的第一个字节是 “:”\n\n多行字符串：回复的第一个字节是 “$”\n\n数组：回复的第一个字节是 “*”\n\n此外，RESP能够使用稍后指定的Bulk Strings或Array的特殊变体来表示Null值。\n在RESP中，协议的不同部分始终以“\\ r \\ n”（CRLF）结束。\n\n* 读写过程\n\nRedis的读过程可以简化为:\n\n1. client客户端通过socket发请求\n2. server端监听服务端口, 收到请求, 解析协议, 查找命令表\n3. server端进行数据操作, 更新数据状态\n4. server端返回数据或信息, client端接受并解析\n\n其中细节颇多, 值得注意的就是 server端内部会进行很多检查工作\n\n比如: 检查键的订阅者, 是否有监听者(monitor), hash负载因子如何, 是否需要rehash, 主从同步等信息 \n\nRedis在集群模式下, 会把`key`根据hash映射到 `16384`个槽其中的一个, 再根据槽所在的节点对客户端操作进行应答\n\n如果该`key`所在槽不归本节点维护, 服务器会返回`moved`错误\n\n而且cluster模式下不能使用Redis的pipeline功能, 除非你能保证pipeline操作的所有key都在同一节点上\n\n# Redis的特色功能\n\n1. Redis的持久化\n\nredis有别于memcache的一个区别就是redis支持数据持久化,redis可以通过采用一定的策略将内存中的数据持久化到本地磁盘上面\n\n这么做不仅有利于数据的完整性和可用性, 同时也可以在服务器重启或者迁移过程中实现方便的数据恢复,一般来说如果设置了合理的持久化策略,就算是服务进程出了问题只要重启服务,并不会丢失太多的数据\n\nredis的持久化相关的主要有以下几点:\n\n1. RDB: 基于内存状态的持久化操作\n2. AOF: 基于命令操作的持久化操作\n3. AOF重写: 基于内存的持久化(命令格式)\n\n**RDB**\n\nRDB:持久化相当于对当前的数据库状态进行一次快照备份, 是将当前的内存数据库中的数据进行序列化保存到本地的操作, 如果数据库使用量比较大,在持久化的时候可能会对性能造成比较大的影响,可以使用命令 `save`(在主进程执行持久化,会造成主进程阻塞) 或 `bgsave`(创建一个子进程来执行持久化,不会阻塞主进程,但是执行时会消耗大量的内存)来执行RDB持久化\n\n**AOF**\n\nAOF(append only file): AOF持久化是对redis的命令进行记录,恢复时按照命令重新执行一遍,以恢复数据库状态的持久化形式,有点类似于GFS里面的基于日志的恢复机制. AOF持久化对性能影响没有RDB那么大,每当redis执行一个命令,redis会根据AOF持久化的设置规则判断是否进行持久化,AOF可以根据命令执行时间和频率来执行持久化策略,比如: 3s执行100个命令则进行持久化,每个命令都持久化等\n\n**Rewrite AOF**\n\nAOF重写: 但是AOF也有一些缺点,有可能造成AOF文件非常的大,举个例子: 我先设置键a为10(set a 10),然后设置键a为5(set a 5),重新设置键a为10(set a 10), 这三条命令执行以后最终的数据状态中的表现结果是a=10,但是在AOF文件中会有3条命令.如果某个键的变动频率非常的高,就会消耗还多的数据命令来记录数据的变化,比如计数器. \n\nredis提供了AOF重写功能来解决这种情况, AOF重写是对当前的内存数据库状态进行命令反向解析,比如,上面的例子,在进行AOF重写的时候,redis看到数据库中的键a的值是10 ,会反向生成一条命令 set a 10,将该命令写到重写文件中,这样就能有效的减小AOF文件的体积\n\n1. 事务\n\n\t\tredis中的事务基于链表实现,跟普通的数据库事务不同的是,redis的事务不支持回滚数据,执行失败了也不会进行通知\n\t\tredis在的事务其实相当于使用一个pipeline 将一系列的操作一起打包发给redisServer来执行\n\n2. 发布订阅\n\n\t\tredis的发布订阅也是基于链表实现,redis的订阅相当于将某个客户端加入到订阅该模式的链表中,redis在执行发布消息的时候会沿着链表去检查所有订阅了符合该模式的所有客户端,将消息发送给他们.\n\n3. 监控(monitor)\n\n\t\t监控功能也是基于链表实现,redis的监视器是一种特殊的redis客户端,服务器会在执行命令时候,将命令同时发送给所有监视器列表上面的客户端\n\n4. 哨兵(sentinal)\n\n\t\tredis哨兵是官方的集群方案出来之前的一种分布式解决方案,哨兵可以监控服务器,并在服务器出问题时候采用选举策略将从服务器省纪委主服务器保证服务稳定\n\n5. 排序(内部实现)\n\n\t\tredis的内部排序主要对set,sort set,list这三个数据结构起作用,旨在让用户可以用过自定义的方式对内部数据进行排序\n\n# redis Representation\n\n这里做了一个简单的redis的脑图, 着重描述了一下内部的基本数据结构的关系\n\n![redis](redis.png)\n\n百度脑图地址: \n[http://naotu.baidu.com/file/ee2d1316a2eb6b2d4fc5b0c876c50685?token=cb284164f0989037](http://naotu.baidu.com/file/ee2d1316a2eb6b2d4fc5b0c876c50685?token=cb284164f0989037)\n\n# Redis集群\n\nredis的常见高可用部署方案\n\n- keepalived(基于VRRP协议)\n- 哨兵(sentinal)\n- 集群(cluster): redis3.0之后提供\n- 其他第三方方案\n\n其中各种方案各有优点, 我们使用的是redis的官方cluster方案\n\n**集群使用中的一些坑**\n\n1. 主从切换,故障转移\n\nredis的主服务器出问题以后,从服务器会顶替主服务器对外提供副服务,但是如果客户端没有对集群中的主节点配置进行更新, 会导致客户端和服务器主节点配置对应不上,从而导致redis操作失败,部分redis客户端支持集群模式,可以自动判断当前集群的主节点,从而自动进行配置调整\n\n2. 分片导致的数据分布问题\n\nredis内部采用16384个槽来对存储的数据进行分配,数据分配到槽上面,槽分配到节点机器上面.但是这样也而导致在进行部分数据操作的时候会出现问题\n\n**故障转移**\n\n主节点挂掉之后,怎么自动修改配置,使服务正常?\n\n3个思路:\n\n1. 后台定时检查,修改配置或将配置放入zk等,实例化客户端的时候从zk中实时获取配置信息\n2. 客户端程序执行redis命令失败时,进行消息通知,检查当前的节点配置,修改配置 \n3. 每次redis对象实例化之后检查集群状态,程序中动态修改配置 \n\n以上思路都需要使用`cluster node`命令从集群中获取当前节点信息,解析出来当前的集群主节点,区别就是修改配置的方式和时间点不同\n\n```js\n\n\tcluster info // 检查集群状态\n\tcluster info返回信息如下(redis3.2):\n\n\tcluster_state:ok\n\tcluster_slots_assigned:16384\n\tcluster_slots_ok:16384\n\tcluster_slots_pfail:0\n\tcluster_slots_fail:0\n\tcluster_known_nodes:6\n\tcluster_size:3\n\tcluster_current_epoch:9\n\tcluster_my_epoch:8\n\tcluster_stats_messages_sent:8625814\n\tcluster_stats_messages_received:8601220\n\n\tcluster nodes // 检查集群节点的状态\n\tcluster nodes返回信息如下:\n\n\t634f54bcec482a1a048f2604793c06acd47c93c6 10.113.1.231:7001 slave c1eecd493eee0644a76bb9e691b6d13a31b25628 0 1510321448626 6 connected\n\t1ed54647073d60118a35df253e9b04459cc30e49 10.113.2.82:7001 slave c464639a33800da984875866391a549647af4a5a 0 1510321447623 3 connected\n\t01334b7a5802032461966cc382b2f97f004ab027 10.113.2.82:7000 myself,master - 0 0 1 connected 0-5460\n\tc1eecd493eee0644a76bb9e691b6d13a31b25628 10.113.1.231:7000 master - 0 1510321446623 5 connected 10923-16383\n\tc464639a33800da984875866391a549647af4a5a 10.113.1.42:7000 master - 0 1510321445622 3 connected 5461-10922\n\t98b58ef327f872dec466761cabae23bad74622db 10.113.1.42:7001 slave 01334b7a5802032461966cc382b2f97f004ab027 0 1510321450631 4 connected\n\n```\n\n其他问题:\n\n\t1. 多主节点的槽分配导致的无法对复杂数据结构(例如hash)进行重命名操作\n\t2. pipeline的使用受节点限制\n\n# 数据对象和底层数据结构\n\n**redis基本数据对象在我们自己项目中的使用**\n\nredis提供了多种基本的数据对象,已经能满足我们的大部分业务需求\n\n以下是各种数据结构在我们业务中的使用示例\n\n```js\nstr:  适用于简单存储(临时标记,计数器等)          \nlist: 适用于线性存储和类似场景(简单线性容器,vector,简单的消息队列)\nhash: 适用于对象存储(产品池,产品信息)\nset:  适用于需要进行集合运算的场景(行政区服务,A和B都喜欢的产品,倒排索引等)\nzset: 适用于有排序需求的场景(360凤舞系统,消息系统中的优先级实现)\nstream:  流式对象, 类似于kafka中的topic  (5.0新增)\n```\n\n其他一些不建议的数据对象使用方法:\n\n```js\n\n1. 使用str存储json对象\n\n\t如: a:{\"name\":\"xiaohua\",\"age\":8},像这种可以使用hash来存储\n\n2. 过度使用有序集合\n\n\t集合和有序集合和list在部分特性上面比较类似,很多人时候问题都可以使用list替代而不必要使用集合,因为有序集合底层使用的跳跃表,性能方面比简单的列表稍微差点,但是集合和有序集合都可以方便的使用集合操作,交/并/差集等\n\n```\n**redis中的数据库键空间**\n\n![数据库](IMG_0255.jpeg)\n\n**数据对象和底层实现的数据结构对应关系**\n\n数据对象的实现之所以有这种情况,其实是适应2个不同场景, 省内存和常规使用\n\n|对象|省内存|常规|\n|:-|:-|:-|\n|str|int/embstr| row |\n|list|ziplist(quicklist)|linkedlist(quicklist)|\n|hash|ziplist|hashtable|\n|set|intset|hashtable|\n|zset|ziplist|skiplist|\n\nredis在3.2之后使用quicklist替代了linkedlist作为列表对象的底层实现\n\n>ps: 我还另外写过两篇稍微详细点的关于redis数据结构([https://leriou.github.io/post-redis-data-structure/](https://leriou.github.io/post-redis-data-structure/))和数据对象的文章([https://leriou.github.io/post-redis-object/](https://leriou.github.io/post-redis-object/))\n\n# 生产问题实例\n\n1. 使用redis注册器起到类似分布式锁的作用\n\n一个曾经的小问题,一段伪代码\n\n```c\n\nflag = get(redis_key)?redis_key:0\n\nres = DB.op(select * from table where id > flag)\n\nwhile(res) {\n\tforeach(a in res) {\n\t\tdo(a)\n\t}\n\twrite(redis_key,flag)\n}\n\n```\n\n潜在的问题: 不支持多线程并发, 任务不能多线程同时进行\n\n解决方案:   借用redis作为注册器,实现类似乐观锁的机制\n\n具体方案:  \n\n```js\n\nredis中存储正在进行的处理进程:\n[2000:1505290677,3000:1505287997,5000:1505287993,6000:1505287892,8000:1505287844]\n流程:\n1. 从注册器根据过期时间和处理范围获取当前应该处理的flag的值\n2. 将自己的当前处理进度存入注册器列表,处理数据\n3. 处理结束移除注册器中自己注册的进度和范围\n\n```\n以上这个程序的核心思想可以用以下流程来描述:\n\n1.  第一步: 正常的数据处理流程   \n\n\t第一个进程来到向注册器索要自己处理的数据起始值,注册器发现当前没有进程在进行,\n\t并且没有flag标记(程序处理到哪里了),给出起始值0,\n\t并在注册器记录里面记录0:1505287993,意思是有程序正在执行从0开始的数据,\n\t进程取1000条数据,将待处理的最大的数据的id设为flag = 1006,\n\t处理完毕将删除注册器中的0:1505287993记录;\n\n2.  第二步: 有其他进程在执行时候的情况   \n\n\t然后第二个程序来执行的时候向注册器索要可以执行的起始值,\n\t注册器查看记录发现0:1505287997并且时间没有过期,\n\t说明0其实的数据已经有人在处理,并且没有过期的注册信息,\n\t于是发放当前的flag给第二个程序,并想注册期记录1006:1505287997,\n\t第二个程序取数据1000条,假设ID范围为1006-2390,将处理标记标记为flag = 2390,\n\t处理完毕删除注册其中的自己的处理进度记录1006:1505287997;\n\n3. 第三步: 针对有部分进程断掉的情况   \n\n\t如果第一个程序中间断掉,\n\t则不能删除自己的处理进度记录0:1505287993,\n\t此时新的程序向注册器索要起始值时,\n\t注册器会发送当前过期的(过期表示处理该记录的程序处理中断了)的程序起始值0,\n\t并标记当前处理的程序是二次处理,\n\t二次处理的程序不会更新flag,\n\t处理完毕删除自己的处理记录\n\n> ps: 整个流程有点类似于常见的\"锁\"的概念\n\n**缺点**\n\n这个处理方案有个缺点, 要求数据的处理操作是`幂等`的,也就是无论操作多少次,操作结果都是一样的,或者不具有累加效应\n\n查询操作就是最常见的`幂等操作`\n\n**流程图**\n\n具体流程图:\n\n![flow](flow1.png)\n\n2. 使用redis解决超高并发\n\n**使用redis的bitmap，hyperloglog等数据结构**\n\nredis的Bitmap非常适合用来做一些数据量大，id分布紧凑，且值类型为bool型的数据的存储， 比如用户标签\n\nhyperloglog也适合用来进行用户访问量统计，视频播放统计等大数据量的统计工作\n\n**其他应用**\n\n我们也可以使用redis的集合来构建倒排索引以实现搜索功能\n\n也能使用redis的发布订阅来实现简单的消息通知系统(不过redis的发布订阅缺点很明显，不建议使用)\n\n或者使用redis的有序集合统计同时在线用户数\n","categories":["工具原理"],"tags":["redis","NoSQL"]},{"title":"Redis集群遇到的一些问题","url":"/2017-10-03-redis-slot-prolem/","content":"\n我们在使用Redis集群的使用过程中发现了很多问题\n\n这些问题产生的原因归根到底都是因为redis将数据映射到槽(slot)上面, 而不同的键分布在不同的Node节点上面导致的\n\n# 键分布导致的问题\n\n当在集群模式下进行多键操作, 同时操作的键中有部分不在该节点时,会报如下错误\n\n`CROSSSLOT Keys in request don't hash to the same slot`\n\n例如:\n\n`hmget key1 key2`\n\n`rename key1 key2`\n\n## 错误类型\n\n- moved错误\n\n该错误表明当前键的落点槽不属于当前Node, 一般之后会跟着一个槽落点和节点地址\n\n例如:\n\n`MOVED 1584 10.200.6.185:7001`\n\n1. 基于该错误可以调整客户端, 让不支持集群模式的客户端也能支持集群功能\n\n2. 也可以提前计算好key, 直接去负责该key所在槽的服务器上取数据\n\n- ASK错误\n\n该错误表明该key对应的数据正在做数据迁移, 槽迁移会引起该槽上的数据返回该错误\n\n\n# 集群模式下不支持select db\n\n单机模式我们可以使用 `select 1` 来选择使用的数据库(redis默认提供16个数据库)\n\n但是集群模式下redis不支持该功能\n\n如果不同的业务组之间需要做业务隔离最好采用不同redis集群的形式进行\n\n可以把多个redis集群组成redis组，多个redis组组成redis池进行资源的统一管理\n\n# cluster模式不支持使用Pipeline\n\nRedis的`pipeline`是一种效果很明显的加快获取数据速度的手段\n\n但是有一个缺点, 我们一旦使用了Redis的Cluster集群, 就没有办法对整个集群使用Pipeline功能\n\n**原因**\n\n因为Redis的Pipeline的原理是在一个连接中持续的进行命令发送, 需要持有一个稳定的连接\n\n但是一旦使用了集群, 我们每个连接只能连接一个Node节点, 可是Pipeline中发送的数据键的数据落点未必会落到我们当前连接的集群节点上去\n\n那经过Pipeline发送过去的key就很明显不能正确的拿到内容\n\n## 解决方案1\n\n- 我们先计算出来每个key的数据落点, 然后将key进行分组, 分组取数据\n\n步骤:\n\n1. 实现集群节点选择方法, 给每个节点起一个名字, 例如 节点1, 节点2, 节点3\n\n2. 查找每个节点上面的数据槽(slot)的范围\n\n3. 对Pipeline中的每个key进行`crc16(key)&16383`, 计算出来每个key的槽, 并找到槽对应的节点\n\n4. 将落到相同节点的key进行分组\n\n5. 对每一组key再进行Pipeline操作\n\n### 优点\n\n充分利用集群特性, 普适性好, 不会造成数据倾斜\n\n### 缺点\n\n按照节点计算key, 最大请求次数等于节点数, 节点太多的情况下不太合适, 适合小规模集群\n\n## 解决方案2\n\n- 存储时候就把key存到一起\n\n使用`{}`来对key进行标记\n\n例如: `{user}:name:3`, `{user}:name`,`{user}:age` \n\n这三个key因为{}部分都相同所以会落到同一个slot上面, 数据自然就落到同一台redis机器上面了\n\n### 优点\n\n不受集群规模和节点数量的影响\n\n### 缺点\n\n但是这种方法限制很大, 没办法充分利用Redis的集群特性, 仅仅适合使用比较频繁的小数据量\n\n数据量太大会导致大量数据存储在同一个槽内, 造成数据倾斜\n\n","categories":["工具使用"],"tags":["redis"]},{"title":"读红楼","url":"/2017-09-10-reading-hongloumeng/","content":"# 前言\n\n说起来惭愧,最近才有幸拜读中国古代小说的巅峰之作<红楼梦>\n\n从很早之前打算好好看一下了, 遗憾的是一直以来都没有时间\n\n最近才抽出一部分时间将曹雪芹所写的前八十回看完\n\n之所以只看前八十回\n\n是因为我个人并不认同后四十回的高鹗/程伟元续写的版本\n\n所以只说前八十回的内容\n\n# 关于全书\n\n<红楼梦>原著全本因为各种原因,现在已经寻不见了 \n\n现在流传的大多是经过后人补全或者修改的,不过版本太多了\n\n但是大多数版本都已被后人篡改太多内容,目前看来脂砚斋重批版本的应该是最符合原书原意的\n\n脂砚斋在批注中剧透了大量后面的故事情节对于解读红楼原意非常有帮助,也是解读红楼最重要的依据之一\n\n虽然我也很希望看到全书, 但是又有点犹豫\n\n毕竟从脂砚斋的批注中我们可以知道大部分人物的结局都是悲剧的\n\n我不想亲眼看到这种悲剧. 现在的高鹗和程伟元的续书虽然也有悲剧\n\n但是我还能骗自己说这不是原书,不可作信\n\n如果真的原本红楼被挖出来了,且不说我能不能接受得了,便是那些依靠红楼吃饭的红学家,可能也会有部分人因此丢掉饭碗\n\n> ps: 清朝的富察明义看过全本的红楼梦, 这在他的诗集<绿烟琐窗集>里面有记载\n\n# 关于87版电视剧\n\n如果是没看过红楼梦的书的人, 非常不建议直接去看电视剧\n\n因为电视剧里面其实是演的一个一个的书中的片段,而且后面几集被删减的内容太多,连续性不强\n\n还是建议先把书读一遍,然后再去看电视剧\n\n## 电视剧中的一些非常好的点\n\n1. 服饰\n\n剧中的服饰非常讲究,林黛玉的各种服饰造型既符合传统,又完全没有传统汉朝服饰那种笨,糙的感觉\n\n据说为了拍87版的电视剧剧组设计了2700多套衣服, 按照三年的时间来计算平均每天设计三套...\n\n\n2. 建筑\n\n剧中的荣国府是专门为此建造的影视基地,建筑用料,建制,建筑上面的一砖一瓦都极为讲究,之前看过一部与此相关的纪录片\n\n3. 音乐\n\n剧中的词曲甚多, 也有人专门对此进行研究,剧中的<枉凝眉>简直好听到爆\n\n## 其他相关\n\n87版的红楼梦毫无疑问是最经典的版本, 而其中的林黛玉毫无疑问是表演非常非常好的一个角色\n\n我其实看书的时候并没有那么喜欢林黛玉, 但是后来看了陈晓旭的林黛玉, 越看越喜欢\n\n其实我个人觉得87版的陈晓旭老师的林黛玉演得好绝非是因为长得好看\n\n就纯粹的长相而言,剧中的林黛玉绝对算不上顶尖的美女,但是架不住里面各种俏皮的小动作, 实在是太可爱了\n\n我现在依然记得几个经典的片段\n\n> part1: 贾宝玉用老鼠偷香芋的故事编排黛玉的时候\n> part2: 史湘云第一次出场,黛玉笑湘云说话咬字,被湘云反过来调戏的时候,生气追湘云被宝玉拦下来的时候\n> part3: 凤姐调笑黛玉吃了我家的茶怎么还不给我们家做媳妇的时候,黛玉生气的样子\n> part4: 宝玉被魇好了以后,黛玉向菩萨祈愿,被宝钗调笑\n> part5: 探宝钗黛玉半含酸\n> part6: 蘅芜君兰言解疑癖\n> part7: 以及湘云刚出场, 黛玉问宝玉去处\n> part8: 宝玉跟黛玉一块哭, 黛玉把手帕递给他\n> part9: 惊呆雁片段\n\n以上几个片段我也读过书, 分明就有好多小动作是陈晓旭自己加上去的\n\n而且看之后的而采访时候也听扮演贾宝玉的欧阳奋强说,片场的陈晓旭十分鬼灵\n\n陈晓旭老师真的是把林黛玉身上那种俏皮可爱,表现的淋漓尽致\n\n陈晓旭老师自己都说她就是林黛玉,我觉得此言非虚\n\n## 跟10版的对比\n\n我之前老是听人说红楼梦是一部伟大的现实主义作品, 但是我个人其实并不是很同意这个说法\n\n10版就是认为应该写实, 结果拍出来跟那啥一样\n\n<红楼梦>中浪漫主义的体现非常之多\n\n贾宝玉的玉的来历,贾宝玉性格,薛宝钗吃的药,很多地方都说明红楼梦不是完完全全的写实主义, 反而是浪漫主义偏多\n\n书中人物性格之所以那么明显, 不就是因为各种戏剧化事件的推动吗\n\n所以我很喜欢87版偏浪漫主义的拍摄\n\n# 关于人物\n\n## 薛宝钗\n\n在我还没有看过红楼梦的时候我就听过好多人说喜欢薛宝钗而不喜欢林黛玉, 因为宝钗明显更符合传统的封建礼教的那一套大家闺秀的形象,通古博今,待人友善,同时又很少干涉他人私事,王熙凤说她\"不关己事不开口,一问摇头三不知\"\n\n书中的宝钗是个脾气极好的人,好像除了清虚观那一段发过脾气外就再也没有发过脾气了,刘心武说宝钗那一段时间心情不好是因为选秀失败了,结合宝玉把她比作杨妃,宝钗生气说出的话来看,确实有一定的道理\n\n而且宝钗在元春省亲时候的态度和所说的话,明显看得出宝钗是很崇拜元春的,可能因为她也想当娘娘\n\n宝钗一出场,气场就与众不同,日常吃的冷香丸的配方看似普通,实则需要极强的机缘与运气.\n\n宝钗自来到贾府与贾府众人都关系融洽(我个人觉得王熙凤不喜欢薛宝钗,按理说,王熙凤和薛宝钗因为王夫人的关系还算亲人呢,结果前八十回,王熙凤和薛宝钗正面交流的描写极少)\n\n宝钗在书中几件比较重要的出场无一不是以控制场面的形象出现的,少数几个宝钗受挫的场面大概也只有清虚观生气,宝玉睡梦中说木石前盟,宝琴出现等几个\n\n宝钗到底才情到什么地步,书中并没有直接描写,不过能跟黛玉并列金陵十二钗之首,才情可想而知\n\n黛玉跟宝玉一起看过牡丹亭和西厢记, 然而宝钗早就看过, 惜春会画画, 然而宝钗给她列画画需要的物品列表时候如数家珍, 你猜宝钗会不会画画?后来还给湘云出主意办螃蟹宴,细想以上几件事情,件件执行者都不是宝钗,但宝钗却都在以上几件事情上扮演了极为重要的角色\n\n总体而言,宝钗给人的感觉是比黛玉和宝玉高一个level的,宝钗完全明白宝玉在想什么但是宝玉却猜不透宝钗所想,两人在感情地位上实际上是有点不平等的\n\n## 林黛玉\n\n相比宝钗,黛玉和宝玉才是真正的互为知己,宝玉懂黛玉,理解黛玉\n\n> \"林妹妹有说过那混账话吗,林妹妹压根就不说那混账话\"\n\n一句话就表明了宝玉和黛玉互为知己到什么地步\n\n两人互相理解互相关心\n\n宝玉偷偷吊祭金钏儿,黛玉不问而知\n\n宝玉有什么好东西第一个想到的一定是林妹妹,\"西厢记妙词通戏语\"基本上已经是明写两人的感情了\n\n> \"你我既为知己,又何必来一宝钗\"\n\n可惜宝玉身在花丛中,为此,林黛玉还吃醋, 开始吃宝钗的醋, 湘云来了吃湘云的醋, 后来宝琴来了倒没见有什么大的反应\n\n从书中看,黛玉是极为关心宝玉的, 宝玉被魇和挨打那两次,黛玉都十分的担心\n\n\"慧紫鹃情辞试莽玉\"一回, 听说宝玉的状况, 说出了\"你倒是找个绳子勒死我才是正经\"\n\n>\"仙杖香桃芍药花\"\n\n可惜因为寄人篱下,只能把自己的希望寄予贾母身上,仙杖是不是就是指贾母啊\n\n## 贾探春\n\n探春其实是个十分有才气的人, \"才自精明志自高\", 从探春兴利除弊就能看出来,她对家族的一些问题早就看在眼里,并早就在思考解决方案. 据说也是曹雪芹寄托自己精神的一个人物, 可惜为家族和身份所累\n\n书中的探春毫无疑问是三春之冠,在十二钗排名中排第四,据说书中的四春分别对应 琴棋书画, 探春也确实工于书法,屋里陈设也有很明显的体现\n\n书中`抄检大观园`一段,探春的表现使的这个人物形象无比的丰满,一个片段就有如此的威力\n\n## 史湘云\n\n湘云是十分可爱的一个角色,说话咬字,天天爱哥哥的, 黛玉打趣她,她也不生气, 书中的史湘云十分可爱, 然而也免不了成为封建制度的牺牲品.\n\n湘云才情不下于宝黛, 擅长对联, 在书中有一段把黛钗都给比下去了, 也就宝琴能跟她比比,还和黛玉对出了\"寒塘渡鹤影,冷月葬花魂\"这样的句子.\n\n黛玉其实是懂世故而不世故, 但是湘云是真的没心机,所以叫\"憨湘云\"\n","categories":["收藏记录"],"tags":["红楼梦"]},{"title":"Life Style","url":"/2017-08-12-daily-life-style/","content":"\n以后啊, 要向极简的生活方式靠拢\n\n之前看过一个日本的书籍就是有关极简生活的\n\n当时还有点不以为然, 感觉都是在讲废话, 现在慢慢的感觉. 如果不把生活简单化, 精力是不够用的\n\n# 有关审美观\n\n我不知道怎么去形容我自己的审美观\n\n可能有一个英文单词比较贴切`clear`\n\n其中包含的意思就有: 清晰, 干净.\n\n我就非常喜欢那种清晰, 干净的事物\n\n比如: 不管对视频还是图片,我都会选择清晰度比较高的那种\n\n挑选软件我也会选择界面比较干净,使用比较流畅的那种,哪怕功能稍微弱一点\n\n我有一段时间特别痴迷微距拍照,特别喜欢那种把这个世界看得清晰的感觉\n\n仔细想想其实也是一种对于品质的追求,因为微距照片的拍摄对象都是比较小的东西\n\n这与极简其实是有相通之处的, 我所崇尚的就是这种干净, 简单的生活方式\n\n某种意义上来说\n\n佛教所说的 \"禅\" 也是这样一种类似的思想\n\n## 日式审美观\n\n日本有一种审美观称为\"侘寂\"\n\n**侘寂: 侘 ,简谱 寂,古旧**\n\n大意是: 随着时间事物的很多部分会被消磨掉,剩下的不完整的事物更有意义, 去掉事物表面的浮华假象, 剩下的才是本质\n\n`简而不陋,古而不旧` 其实也就是常说的简约而不简单\n\n这也是我比较欣赏的一种审美观\n\n但是我自己对此并不是很热衷, 因为我总觉得侘寂会给我一种因为没有更好的选择所以才将就,有一种自欺欺人的感觉\n\n日本还有两种比较有特色的审美概念 `幽玄`和`物哀`\n\n至于这三者的区别,我曾听过一个比较形象的描述:\n\n>试想你站在一池平静无波的湖水面前, 突然有一滴水从湖边的树梢滴落,正好落到湖边的一块长满青苔的石头上,溅起的水滴落入湖水中,引起一道波纹\n\n`幽玄` 就是你望着那浅浅波纹渐渐散开渐渐消逝时的感觉\n\n`物哀` 则是那一滴水落入石头上的那一声轻响,转瞬即逝\n\n`侘寂` 就是那常年被水滴浸润的长满青苔的石头\n\n## 与北欧的对比\n\n拿常见的家具行业的`MUJI(无印良品)`和`IKEA(宜家)`分别代表了典型的北欧和日式两种设计风格\n\n虽然两者都推崇极简和简约的设计, 但是无印良品的风格更着重表现物质本身, 而宜家则大多着重设计方面的极简\n\n比如: 同样是木材家具,无印良品可能更着重表现的是木头的质地和纹理,而宜家则更多的是通过线条设计和材质来传达自己的设计理念\n\n# 音乐\n\n通过我多年的生活和工作经验,我现在发现了一个问题\n\n**好多人其实都不具备真正欣赏音乐的条件**\n\n## 欣赏好音乐的前提\n\n要真正的欣赏音乐需要有一定的客观条件和主观条件\n\n1. 客观条件\n\n客观条件包括前端,耳机/音响,音源文件,线材等\n\n在我看来虽然以上东西比较复杂,但是我还是整理了一个表格\n\n|耳机|音源文件|前端|\n:-:|:-:|:-:|\n不可|价位: 百元以下耳机不推荐使用|mp3 320k以下|-\n入门|价位: 100-500;   例如: AKG K420| mp3(320kbs)等普通格式即可 |无需播放器\n中端|价位: 1000-3000   推荐: IE80|flac(900kbs+)/ape等无损格式|专业播放器\n高端|价位: 3000+ 推荐:   推荐: AKG K3003|数字无损/原声碟|专业播放器\n\n对一般人而言,耳机选取2000以下的耳机,前端用手机或电脑,音乐文件普通的wav/aac/mp3即可,再往上的话就需要配备其他配件才能比较好的发挥效果,相对来说便携性会大大降低\n\n>ps: 使用低端耳机听歌有极大地永久性损伤听力的风险,另外不推荐 beats等耳机\n\n2. 主观条件\n\n主观条件包括环境和心态,以及听者的音乐涵养等\n\n尽量不要在嘈杂的环境,如火车,地铁,大街上欣赏音乐,在那种地方最多也就听个响\n\n想欣赏音乐还是需要找个安静的所在,静静地听\n\n# 手机\n\n以前上大学的时候, 花了大量的时间在挑手机上面\n\n新出一个手机, 总是比比比,看看看, 挑挑挑\n\n总是跟人安利这个手机哪哪哪好\n\n现在手机也好, 电脑也好, 已经没兴趣在折腾了\n\n随便买一个用用得了\n\n时间那么宝贵, 现在不愿意在这种事情上浪费时间了","tags":["生活方式"]},{"title":"如何事半功倍的学习编程","url":"/2017-05-20-how-to-make-a-decision/","content":"我一直认为学习东西有四重境界\"道\",\"法\",\"器\",\"术\"\n\n编程也不例外,对于编程我是这么认为的\n\n由浅入深依次是: `道`->`法`->`器`->`术`\n\n## 解决问题的道\n\n道: 规则\n我把它理解为解决特定问题方法规则, 是一种切入口和方向类的,思想性的东西,\n比较抽象,而且不针对具体的问题,而是针对某一类型的问题提出解决的思想    \n特点是没有针对具体的问题,甚至没有实际的可操作方案 \n在编程领域通常指的是从数学中提取总结出来的解决问题的思想, 纯理论层面的东西\n例如: \"分而治之\"\n\n要达到这个层次, 通常需要能了解需要解决的问题本质, 多年的实际经验外加时常总结解决问题的方法\n\n计算机行业可能遇到的问题很多, 但是归根到底, 其实并没有太多种, 很多相似的问题可以用同类的方法来解决\n\n比如: \n\n数据一致性问题, 解决数据一致性问题的方法有很多, 但是根本思想都是希望参与决策的个数据节点尽可能的了解彼此的数据状态\n\n## 法\n\n法: 方法\n\n基于思想实现的解决某一类问题的方法,某一种思想可以有很多种不同的实现方法   \n特点是针对特定问题,有实际的演示例子\n\n编程领域中的各种基于数学理论出现的各种算法就属于这个层次\n\n例如:\n\n具体的某种算法\"哈希算法\",某种中间件中MapReduce的具体实现方案等 \n\n一致性问题中的某种算法: paxos, raft, zab等实际的算法\n\n## 器\n\n大量解决方案的集合, 解决一系列问题及其衍生问题的工具,一般包含了大量的设计模式和解决各种问题的具体的算法\n\n特点:解决某种或者某一系列问题的工具\n\n例如:\nRedis,GFS,MongoDB,各种编程语言(c/c++,java,Python)\n\n我们使用的基于zab的zookeeper, 基于paxos的chubby等\n\n## 术\n\n使用\"器\"的技术  \n\n特点:使用工具解决具体问题的方法\n\n例如:\nredis的命令和用法, 某种具体编程语言的语法等\n\nzookeeper的各种api的使用","categories":["编程学习"],"tags":["编程"]},{"title":"多git账号配置","url":"/2017-06-01-multi-git-user-config/","content":"\n# 背景\n\n我们有时候可能会遇到这样的情况\n\n公司部署了一个gitlab服务器\n\n我们自己也有在github上面使用仓库\n\n但是这两个服务器上面的账号是不一样的\n\n我们需要在公司的项目中使用公司的git账号,私人项目使用私人的git账号\n\n这时候就需要在同一台电脑上面使用多个git账号\n\n## 生成两个ssh-key\n\n现在大家普遍使用ssh-key来作为授权验证的工具.\n\n大多数的git服务器也使用这样的方式\n\n那我们就需要生成两个对应的ssh-key, 一个用于私人项目,一个用于公司项目\n\n## 获取服务器项目权限\n\n首先我们要拥有对应服务器(github/gitlab/coding等)的权限\n\n一般去的权限的方法是\n\n1. 注册github/gitlab/coding账号\n\n2. 生成ssh-key\n\n`ssh-keygen -t rsa -C \"youremail@example.com\"` 生成ssh-key\n\n3. 将生成的ssh-key中的xxx.pub公钥添加到github或者gitlab的ssh-key授权中\n\n此时我们的电脑实际上已经获得了往对应的平台中的账户下面的仓库中推送代码的权利, git推送代码是只认机器不认人\n\n此时机器已经可以推送代码了,但是服务器还无法针对不同的服务使用不同的ssh-key设置\n\n## 在ssh中增加config文件\n\n可以通过配置.ssh文件夹下的config文件,通知ssh对不同的服务器使用不同的ssh-key\n\n例如,config内容:\n\n```bash\n\n# github\nHost github.com    # 指定主机地址\n    HostName github.com   # 主机名, 选填\n    User 111@qq.com      # 用户名\n    PreferredAuthentications publickey  # 授权方式\n    IdentityFile ~/.ssh/id1_rsa     # 该服务器上使用的ssh-key\n\n# gitlab\nHost gitlab.com\n    HostName gitlab.com\n    User 222@qq.com\n    PreferredAuthentications publickey\n    IdentityFile ~/.ssh/id2_rsa\n\n```\n\n以上内容就是 对github.com 使用 id1_rsa这份公钥,对gitlab.com使用 id2_rsa公钥,配置好了以后ssh就可以的对不同的服务器使用不同的公钥了\n\n>ps: 没有域名host可以直接设置为服务器ip\n\n但是此时我们可能推送代码的用户标识可能不正确\n\n例如:  你的私人用户名叫A ,公司账号叫B, 此时你推送代码到公司账户但是却显示推送者是A\n\n## 在目标项目中使用git config设置用户\n\ngit中的配置分为全局配置和项目配置,默认使用全局配置,如果要在特定项目中使用特定的用户名,需要在项目的git配置中进行指定\n\n可以在项目目录中执行以下命令,指定需要使用的用户名和邮箱\n\n`git config user.email \"aaa@qq.com\"`: 设置项目用户邮箱\n\n`git config user.name \"aaa\"`: 设置项目用户名\n\n也可以手动修改`项目名/.git/config`文件中的user标签下的内容\n\n## ssh-T 测试\n\n使用如下命令可以测试配置结果,需要测试@ 后面的服务器地址可以自己修改\n\n`ssh -T git@github.com`\n","categories":["工具使用"],"tags":["git"]},{"title":"关于员工工作态度的思考","url":"/2017-03-15-thking-for-attitude/","content":"# 工作态度\n\n影响一个人态度的因素\n\n我把影响员工工作态度的主要分为4个方面\n\n1. 理想\n2. 责任 \n3. 奖惩机制\n4. 个人能力\n\n我们拿西天四人组举例子\n\n1. 个人能力和团队其他成员的能力\n\n这个是客观因素, 对团队成员工作态度的影响也不能一概而论, 有可能是正面影响, 也有可能是负面影响\n\n个人能力是影响员工态度的很重要的一方面\n\n有人喜欢展现个人能力, 如果自己在团队中能力偏弱会发愤图强, 努力提升\n\n也有人会因为自己能力不行, 但是懂得根据现实情况选择合适的人做合适的事情, 不会强行要求自己来做\n\n还有人会因为自己能力普通, 就变得很不积极, 没有展现自己的意愿\n\n2. 奖励和惩罚机制\n\n这两个机制使用得当可以增强员工的工作态度\n\n\n3. 理想\n\n这个决定了第1点里面的到底是正面影响还是负面影响\n\n有理想的人工作态度必然是十分积极的\n\n4. 责任\n\n这个是人本身的性格, 对员工的工作态度当然也有影响\n\n# 西天四人组\n\n### 唐僧\n\n主要因素: 理想, 责任\n\n唐僧当然是要去西天取经的, 应该本人也是喜欢做这件事情的吧, 他肯定觉得自己有责任拯救黎民于水火\n\n他估计不会太看重取经成功的奖励和取经失败的惩罚\n\n个人能力当然也影响他一路上的态度\n\n### 孙悟空\n\n主要因素: 个人能力, 奖励和惩罚机制\n\n孙悟空个人能力极强, 属于团队里面的攻坚分子\n\n这种人的态度怎么保证呢, 悟空当然是不喜欢西天取经的\n\n孙悟空估计本身也没啥责任心\n\n决定孙悟空态度的我认为主要还是奖惩机制和个人能力\n\n就是 放出花果山 + 紧箍咒 + 愿意展示个人能力\n\n### 猪八戒\n\n主要因素: 奖励和惩罚机制\n\n猪八戒这种人毫无疑问, 没有理想, 没有责任心, 不想展示个人能力\n\n能影响到猪八戒的纯粹就是 奖惩机制\n\n### 沙和尚\n\n主要因素: 奖励机制, 责任心\n\n沙和尚虽然个人能力不行, 也没有啥理想, 但是有责任心啊, 个人能力一般\n\n### 小白龙\n\n主要因素: 奖励机制, 责任心\n\n小白龙和沙和尚类似, 没有理想, 有责任心, 个人能力一般\n\n\n# 启发\n\n我们工作中进行工作分配的时候, 也可以参考西游记中四人组的工作职能\n\n1. 孙悟空这种, 就做为困难攻坚分子\n\n2. 猪八戒这种拿来背锅\n\n3. 沙和尚和小白龙做日常一般业务","categories":["思考"],"tags":["思考"]},{"title":"两种网站限流方案","url":"/2017-03-03-rate-limit-method/","content":"\n# 网站限流\n\n随着网站用户规模的增加,业务的扩张, 我们网站所承受的流量规模和并发数也会不断增加\n\n到了一定时候我们就会希望可以对网站的流量进行一定程度的控制,因为我们的业务处理能力是有限的,我们需要优先保证关键业务的正常运转\n\n技术人员一直以来都在致力于可以彻底的解决高并发问题,但是到目前为止也没有一种可以彻底解决的方案\n\n我们只能尽量的提升业务处理的性能,做业务拆分,分布式,进行错峰处理等手段\n\n其实我们可以从一整个用户请求的过程中的每个阶段进行分析, 在不同的阶段采用不同的方案\n\n在用户请求刚刚进入的时候进行限流处理就是一种十分有效的手段\n\n## 限流\n\n限流就是从用户访问出限制用户的请求,常用于秒杀等并发量极高的场景之下\n\n限流的核心思想就是人为的丢弃一部分用户请求, 不作处理, 这样相当于从最根源处就避免的用户后续的操作,虽然对用户体验来说影响非常大, 但是只要采用合适的丢弃策略,就能在有效保护系统的同时,尽量减少对用户体验的影响\n\n## 漏桶算法\n\n漏桶算法就是一种有效的限流算法,顾名思义,就是像漏桶一样以固定的速率将用户请求控制在一个确定的范围之内\n\n漏桶有两个关键属性,一个是漏桶的大小(最大存储的请求容量),另一个是漏桶的开口(处理请求的速率)\n\n用户的请求过来之后可以认为会被放到一个漏桶内,然后桶本身以一定的速率处理请求,当用户的请求速率过快,桶内的请求数量过多就会造成请求溢出,这部分请求就会被视为无效的请求\n\n特点: 根据时间以固定速率允许请求通过\n\n缺点: 针对部分由突发场景的效率有点低\n\n流程图: \n\n![](flow1.png)\n\n## 令牌桶算法\n\n另一种常用的限流算法叫令牌桶算法,令牌桶的思想跟漏桶有点不大一样,令牌桶是先假设了一个桶, 桶内装有令牌(token),系统以一定的时间往桶里添加令牌.请求过来以后需要使用桶里面的令牌才能执行,也就是说我们可以通过控制桶内令牌的数量来控制最大请求数,也能通过改变添加令牌的速率来调整请求的处理速率\n\n令牌桶也有关键参数,一个是桶的大小,一个是令牌的发放速率\n\n特点: 使用请求+令牌来进行请求处理,没有令牌的请求不予处理\n\n缺点: 实现起来比漏桶算法复杂一点\n\n流程图:\n\n![](flow2.png)\n\n>ps: 往令牌桶内添加令牌并不需要一个单独的程序来执行,只要在请求过来时候根据时间自动计算可用的令牌就行了\n\n虽然两种算法都能控制请求的处理速率, 但是这两者其实都受到之后请求处理速率的影响, 也就是说就算我们限流部分允许每秒2万的请求,但是后台业务的处理速度只有每秒1千,依然会造成严重的业务阻塞\n\n## RateLimiter\n\nGoogle开源工具包Guava提供了限流工具类RateLimiter,该类基于令牌桶算法(Token Bucket)来完成限流","tags":["漏桶算法","令牌桶算法"]},{"title":"消息通知系统的设计","url":"/2017-03-01-message-system/","content":"# 站内信通知系统的设计\n\n站内信系统是一个成熟的系统所应该具有的基本系统组件\n\n## 需求分析\n\n站内信通知系统的核心目标是为系统提供一个 用户与用户,系统与用户交互的手段,属于网站信息传播的一个重要途径,如果详细考虑,该系统实在是一个非常庞大的系统设计,可以做的事情非常的多\n\n这里只是简单梳理一下普通消息系统需要做到的部分和功能设计,并提供一个可用的实际消息系统框架\n\n一个完成的消息通知系统大概可以分为两部分, 消息系统和通知系统\n\n消息系统主要负责消息的产生,接收等,通知系统则要实现事件机制,通知机制,对接各种消息通知平台(短信,微信,邮件等)\n\n消息通知系统的核心处理大概可以分为以下3个部分:\n\n1. 消息产生\n\n        消息的产生:消息如何产生,来源和消息对象的结构\n\n2. 推送消息\n\n        消息的分发:消息如何到达用户,用户如何获取消息\n\n3. 处理消息\n\n        消息的处理:用户可以对消息所做的操作\n\n\n同时还要在整个过程中随时持有消息的状态,这样才能最大化消息通知系统的功能\n\n一个成熟消息处理的流程大概如下图:\n\n![](flow1.png)\n\n## 消息产生\n\n消息系统的消息按类型大致可以分为私信类和通知类,其中私信类就是上文提到的消息部分,又可以分为管理员发送的和用户个人发送的\n\n私信类的消息大概情况如下:\n\n1. A给B发送了S内容,B给A回复了私信S2\n2. 管理员(admin)给A/B发送了S内容(这一种也可以看做是公告)\n\n通知类,消息是由用户某些动作产生的提醒类的信息,具体情况大概如下(拿知乎举例子):\n\n1. A回答了问题W\n2. A在专栏Z中发布了文章P\n3. B评论了A在问题W下的回答H\n4. B赞了A在问题W下的回答H\n5. B赞了A在问题W中的回答H下的评论C\n\n>ps:用户: A,B,C 专栏: Z 回答: H 问题: W 文章: P 消息: S 评论: C\n\n私信形式的实现起来比较容易,这里不多做表述,现在主要针对消息通知类型的进行方案分析\n\n### 基于订阅模式的消息产生\n\n消息类的通知总结一下就是A对B的某操作进行了某操作,具体模式是:  \n\n        用户X 收到了 用户B 对 对象O 的 事件E 操作的通知\n\n这种模式很符合订阅模型,以下几种消息都可以用订阅关系表示\n\n1. B订阅了问题W的回答事件ER\n2. B订阅了专栏Z的发表事件EP\n3. B订阅了回答H的评论\n4. B订阅了回答H的点赞事件\n5. B订阅了评论C的点赞事件\n\n只要根据触发改消息的那条记录生成对应的消息即可\n\n### 表结构设计\n\n具体设计如下:\n\n>ps:(这里模拟了几条记录,方便用来做演示)\n\n#### 订阅关系表\n\n用于记录用户的订阅信息\n\n|id|用户|订阅对象id|订阅对象类型|订阅事件|时间|\n|-|-|-|-|-|-|\n|1|B|30|post|answer|2017-01-01|\n|2|B|1|zhuanlan|publish|2016-01-01|\n|3|B|112|answer|common|2016-01-01|\n|4|B|113|answer|up|2018-01-01|\n|5|B|12|comment|up|2018-01-01|\n\n当某对象产生某动作的时候,根据订阅关系表的订阅关系生成消息\n\n#### 订阅配置\n\n用于为用户生成默认的订阅配置\n\n|id|动作|订阅事件|\n|-|-|-|\n|1|关注问题| 问题更新/问题回答 |\n|2|回答| 回答被评论/被点赞|\n\n这个表格记录了用户的某些操作会订阅怎样的对象动作,用于生成用户默认的订阅事件,后期如果开放权限,用户就可以对自己收到的提醒类型进行定制\n\n#### 消息内容表\n\n消息内容表用来存储消息的具体内容,用户将来收到的信息就是该表中的信息\n\n|id|type|content|\n|:-:|:-:|:-:|\n|1|notice|用户C回答了问题W(id=30) |\n|2|announce|知乎形象刘看山发布了|\n|3|notice|B赞了你在问题W下面的R|\n\n#### 消息记录表\n\n消息记录表用来存储消息和用户的分发关系\n\n|id|remindid(消息ID)|senderid(发送方)|reciverid(接收方)|isread|type|\n|-|-|-|-|-|-|\n|1|1|1|1|0|message|\n\n### 私信类消息\n\n对于第一类私信类的消息,原则上即便用户不上线也需要对用户进行推送,也即是直接写入消息表\n\n现在从消息的产生开始分析消息的数据流程\n\n用户A->发消息(\"你吃饭了吗\")->消息内容表->消息记录表\n用户B上线->查询消息记录表中的未读->阅读消息->回复内容\n\n私信类型的比较简单,如果是管理员的话,把id设置为特殊值或者将消息类型标记为announce,在前台就可以进行相应的展示限制\n\n### 提醒类消息\n\n重点是第二类提醒类的消息,提醒类消息也不允许用户漏接\n\n提醒类消息的产生流程就比较麻烦\n\n1. 某用户在某专栏发布某文章->生成消息存入消息表->检查订阅该专栏文章发布的用户和关注了该用户动态的其他用户->把消息表中的记录分发给这些用户->这些用户上线收到消息\n\n2. 你回答了一个问题->增加订阅该回答的点赞和评论动作->有人评论你的回答->生成消息内容表的内容->检查订阅该回答评论的用户->分发消息\n\n例如以上记录会产生消息:\n\n1. 用户C在专栏Z(id=1)中发布了文章P\n2. 用户C评论了某用户在问题W下的回答H\n3. B赞了你在问题W下的回答(该消息推送给回答者)\n\n消息表用于存储消息信息,当某事件被触发时,会生成对应的消息提醒内容,然后查询订阅该事件的所有用户,将消息和用户关系写入消息记录表\n\n### 通知合并\n\n有时候,当某用户收到大量用户对某对象进行相似的操作的时候为了性能和用户体验,我们需要对用户的同志进行合并\n\n比如: 用户A 发布了一篇文章, 有5万人在1小时内都点赞了该文章, 我们就可以生成一条\"张三,李四等5万个用户点赞了你的文章XXX\".\n\n消息合并的规则:\n\n1. 按时间合并消息\n2. 按发送方合并消息\n3. 按种类合并消息\n\n合并的周期:\n\n1. 固定时间的周期性的消息进行汇总\n2. 无固定时间,产生未读消息即汇总\n\n合并的具体方法:\n\n1. C点赞了你的回答之后，这条消息会被标记为可聚合，聚合keyword为操作ID/对象类型/对象ID\n\n例如: 在某段时间之类有两个用户赞了你的评论,这个时候可以使用 C,V等两个用户赞了你的评论C,当产生第一条通知的时候,消息表中有一条消息: C赞了你的回答,这个时候V赞了你的回答之后,两条记录可以合并成一条\"c,v等两个人赞了你的回答\", 这个例子中的两条记录的操作类型(都是点赞)和操作对象(都是你的回答)相同\n\n## 消息分发\n\n通知消息产生以后我们只是有个要推送给用户的消息体,怎么把消息推送给用户也是一个很重要的部分\n\n#### 通知的分发\n\n消息分发一半常用的有两种方式,一种是消息推送(push)一种是消息拉取(pull),不过现在大多采用两者结合的方式,针对不同的场景使用不同的方式\n\n1. push方式: 推送你有XX条消息未读(针对在线的用户)\n2. pull方式: 用户点击未读消息时对内容进行拉取\n\n消息分发的话可以采用redis来作为中间桥梁,将未读消息的数量存入redis, uid:unread:10 用户有10条未读消息\n\n当用户点击未读消息的标志的时候,从消息记录+消息内容表获取该用户的具体未读信息内容\n\n这里可以做一些优化:\n\n1. 未读消息太多的话会每次取前20条\n2. 某些公用的消息比如公告和某文章发布的消息可以存入redis,使用类似messageid:content:xxxx.这样的内容存储消息内容,当所有订阅该类消息的用户获取消息的时候会先从redis中获取数据,取不到的才从数据库中查询\n\n分发频率\n\n1. 实时分发\n2. 按小时分发\n3. 按周和天分发\n\n分发管道 Web,微信,邮件,短信\n\n#### 用户对消息的处理\n\n##### 通知已读\n\n每条消息都应该带有一个是否已读的状态,以防止对用户造成重复的打扰\n\n一旦用户点击获取消息,打开消息详情或点击消息体的任意连接,就算作已读该消息,已读消息不做重复提醒\n\n已读消息的排序: 用户有30条未读消息,点击列表已读20条,剩余10条未读消息怎么处理\n解决方案: 获取消息未读消息列表时按时间顺序取前20条\n\n##### 通知内容的处理\n\n        点击链接: 点击链接之后进入到与该消息有关的详情页面  \n        回复: 用户可以对私信进行回复\n        删除: 用户可以删除消息\n\n>ps: 不同终端消息状态应保持统一\n\n#### redis中消息的存储\n\nredis中不存储普通的用户消息,但是会存储系统公告和文章更新之类容易被复用的消息\n\n消息:\n\n        msgid:xx:content:你订阅的XXX专栏更新了\n\n        uid:xx:unread:10\n\n### 消息回收\n\n消息处理还有其他一些需要系统处理的地方\n\n1. 用户对话消息的显示范围(可以根据时间),是否允许用户删除\n2. 用户拉黑名单是否自动删除会话消息\n3. 用户长时间未读取的系统消息自动回收的时间\n4. 长时间的未读消息的处理, 永久保留,二次推送(通过其他渠道)\n\n## 其他\n\n一个消息系统还涉及到其他的一些关键的地方\n\n### 消息的离线计算和处理\n\n消息系统数据量有可能非常大,如果一个用户有50万粉丝,该用户发一篇文章,理论上就要为50万用户产生消息.想要实时计算消息基本是不可行的, 所以应该有一套成熟的数据处理系统来支持消息系统\n\n### 新消息到达时候的交互\n\n用户获取消息以后的UI交互也是消息系统的一部分功能,也是需要考虑的一部分\n\n1. 声音提示\n2. 标题闪烁\n3. 未读信息浮动层\n4. 弹窗\n\n### 防骚扰\n\n1. 增加屏蔽功能\n2. 设定接受消息的权限(例如:仅我关注的人可以给我发消息)\n3. 黑名单\n\n### 用户拉回\n\n1. 长时间未处理消息的用户进行二次推送(通过短信和邮件等)\n","categories":["系统设计"],"tags":["系统设计","消息通知系统"]},{"title":"redis的持久化","url":"/2017-01-29-redis-persistence/","content":"# redis的AOF和RDB持久化\n\nRedis支持两种持久化方式, 一种是快照形式, 一种是重放命令日志的形式\n\n## RDB持久化\n\n特点: RDB持久化是对当前数据库的状态进行备份,备份的对象是当前数据库的数据状态\n\n例如:\n\n```json\n{\n\t\"age\":1,\n\t\"name\":\"zhangsan\"\n}\n\n```\n这样的数据会被被分为某种格式的信息,进行数据恢复的时候是直接读入RDB文件解析数据\n\n拥有持久化的能力使得redis在服务重启时能保留大部分的内存数据\n\nRDB文件在redis主从同步时候会被发送给从节点,从节点使用RDB进行全量的数据恢复\n\n### 主动触发保存\n\n1. 使用 `save` 命令可以手动对redis进行保存, 该命令会阻塞redis主进程\n\n2. 使用`bgsave`会在后台创建子线程来进行存储, 此时要求redis节点有1倍以上的空闲内存 \n\n比如:  机器内存有32G, 此时Redis里面数据20G, 使用 `bgsave` 就不可以,必须保证空闲内存大于20G才能使用\n\n## AOF持久化\n\n特点: 对写命令进行备份,一般是再有写命令的时候吧命令追加到AOF文件中,客户端每进行一次操作,服务器吧命令写入AOF文件,数据恢复就是从AOF文件中读取命令并执行\n\n但是会出现这么一种情况(ABA):\n\n对某个命令的写命令太多的话,有可能会出现这种情况\n\n```shell\n\n$ set a 10\n\n$ set a 18 \n\n$ set a 10\n\n$ set a 20\n\n$ set a 10\n\n```\n\n这种情况下a的值实际最终还是10,不过因为aof对所有操作的命令都会记录,导致大量的命令对数据最终的状态来说其实都是\"无效\"的\n\n这种情况还会引起效率问题,为了减小AOF文件的大小,这个时候需要对AOF进行重写\n\n### AOF重写\n\n为了应对命令有冗余,提高数据备份效率,会对数据库进行AOF重写,重写是通过对当前的数据库数据进行读取并进行反向的命令解析来进行的\n\n某种意义上来讲AOF重写和RDB有部分类似,都是针对当前数据库状态进行的备份\n\n只不过aof会把所有数据反向解析成操作命令保存起来\n\nAOF重写可以使用命令 `BGREWRITEAOF`\n\n### AOF保存的格式\n\nredis的命令会被以RESP(redis的客户端通信协议)的格式保存到 *.aof的文件中\n","categories":["工具原理"],"tags":["RDB","AOF"]},{"title":"软件分享(Mac OS)","url":"/2017-01-24-my-software/","content":"# 常用软件分享\n\n仅仅列举了常用的完整APP程序,终端服务应用不在此列\n\n<!-- more -->\n\n## 日常\n\n|软件名|功能描述|备注|\n|:-:|:-:|:-|\n|QQ|聊天,交流||\n|微信|聊天||\n|Chrome|浏览器||\n|Firefox|浏览器|启用新的引擎之后也还不错|\n|有道云笔记|云笔记|配合本地md使用|\n|网易云音乐|音乐客户端||\n|虾米音乐|音乐||\n|QQ音乐|音乐|版权比较多|\n|爱奇艺|视频||\n|优酷|视频||\n|腾讯视频|视频客户端||\n|Maipo|微博客户端||\n|欧陆词典|词典||\n|有道词典|另一个英文词典工具||\n|Grammarly|英文语法检测工具||\n|Spark|邮件客户端|在我的电脑上退出时候老有bug所以暂时不用了|\n|IINA|基于MPV的视频播放器,但是更加好用||\n|vox| 本地音乐播放||\n|lastPass|密码管理||\n|企业微信|通信工具|工作沟通利器|\n\n>ps: firefox现在感觉有些不如chrome了\n\n## 苹果家\n\n|mail|邮件客户端||\n|:--:|:--:|:-|\n|ibooks|pdf阅读器||\n|QuickTime|视频播放,视频音频录制||\n|GarageBand|谱曲,作曲||\n|iMovie|视频制作||\n|Grapher|函数绘图||\n|page/number/keynote|apple办公三件套||\n|automator|自动化工具,可以做工作流||\n|iturns|不得不用的管理工具,但是并不好用|现在不怎么用了|\n\n>ps:mail有时会出现高CPU占用的情况,所以不经常用了\n\n## 工具类\n\n|SmartCoverter|视频,音频格式转换||\n|:--:|:--:|:-|\n|迅雷|下载工具||\n|motrix|下载工具| 替代迅雷比较好|\n|百度网盘|文件中转||\n|MPV|全能视频播放器||\n|lantern|科学上网||\n|shadowsocksx-ng|科学上网||\n|Github Desktop|github官方GUI|感觉官方的很好用,之前用过sourcetree|\n|Cornerstone|SVN管理工具||\n|SwitchHosts!|Host管理||\n|DaisyDisk|磁盘清理和管理||\n|CleanMyMac|软件管理,垃圾清理||\n|Sip|屏幕取色||\n|Cerebro|效率工具||\n|Alfred|效率工具|\n|MindNode|思维导图工具||\n|xmind-zen|轻量级的思维导图|\n|iStat Menus 6|系统监控工具||\n|马克飞象|MarkDown工具||\n|Typora|Markdown工具||\n|iMazing|比iTunes好用的iOS设备管理工具||\n|iTerm2|强大的终端工具||\n|Spectacle|窗口管理工具||\n|Transmit|FTP服务器管理||\n|zeplin|看产品设计图||\n|sketch|设计产品||\n|numi|超级好用的编程计算器,实际上就是个编程工具||\n|rightfont|字体管理||\n|Polarr Photo|图片处理||\n|Photolemur|智能的图片处理|自动处理的效果很不错|\n|Paste|多剪贴板管理|非常好用|\n|keka|压缩/解压缩工具||\n\n## 开发专用\n\n|sublime text3|轻便的编辑器||\n|:--:|:--:|:-|\n|Atom|备胎编辑器,性能有点问题,其他不错||\n|Visual Studio Code|微软出品的编辑器,感觉比atom要好点|性能很好,但是权限好像有问题|\n|Xcode|ios,mac os开发IDE||\n|unity|游戏开发引擎||\n|robo-3t|mongodb数据库管理||\n|MongoDB compass|mongodb官方的GUI管理工具||\n|Sequel Pro|MySQL数据库管理||\n|Charles|抓包工具||\n|Surge|调试工具||\n|Dash|开发文档集合||\n|Medis|GUI的redis查看工具|简直第一好用的redis的GUI客户端|\n|Postman|API测试||\n|Kafka Tool|kafka管理客户端|能查看的信息比较详细,应该是通过读zk里面的节点信息|\n\n## 游戏\n\n|Civilization VI|(文明6)一款策略游戏||\n|:--:|:--:|:-|\n|Beholder|经营策略游戏,剧情黑暗||\n|MiniMetro|益智小游戏||\n|Battle.net|暴雪全家桶||\n|机械迷城|益智解谜游戏|额,老游戏了|","tags":["软件分享"]},{"title":"几种分布式唯一ID的生成方式","url":"/2017-01-17-distribute-unique-id/","content":"# 分布式唯一ID\n\n我们在工作中经常需要用到唯一id 来对信息和记录进行唯一性标识\n\n因为许多数据库的特性, 我们对唯一id还有一个趋势增长的要求\n\n所以核心要点就两个\n\n1. 全局唯一\n2. 趋势有序\n\n下面介绍几种常用的方法\n\n# 数据库\n\n最常见的方式。利用数据库创建一张表，全数据库唯一。\n\n优点：\n\n1. 简单，代码方便，性能可以接受。\n2. 数字ID天然排序，对分页或者需要排序的结果很有帮助。\n\n缺点：\n\n1. 不同数据库语法和实现不同，数据库迁移的时候或多数据库版本支持的时候需要处理。\n2. 在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。\n3. 在性能达不到要求的情况下，比较难于扩展。\n4. 如果遇见多个系统需要合并或者涉及到数据迁移会相当痛苦。\n5. 分表分库的时候会有麻烦。\n\n优化方案：\n\n针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。\n\n比如：\n\nMaster1生成的是  1,4,7,10\nMaster2生成的是  2,5,8,11\nMaster3生成的是  3,6,9,12\n\n这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。\n\n\n# 使用redis\n\n当使用数据库来生成ID性能不够要求的时候，我们可以尝试使用redis来生成ID。\n\n这主要依赖于redis是单线程的，所以也可以用生成全局唯一的ID。可以用redis的原子操作 INCR和INCRBY来实现。\n\n可以使用redis集群来获取更高的吞吐量。假如一个集群中有5台redis。可以初始化每台redis的值分别是1,2,3,4,5，然后步长都是5。各个redis生成的ID为：\n\nA：1,6,11,16,21\n\nB：2,7,12,17,22\n\nC：3,8,13,18,23\n\nD：4,9,14,19,24\n\nE：5,10,15,20,25\n\n\n重点: 负载到哪个机器确定好，未来很难做修改。\n\n但是3-5台服务器基本能够满足器上，都可以获得不同的ID。但是步长和初始值一定需要事先需要了。使用redis集群也可以防止单点故障的问题。\n\n另外，比较适合使用redis来生成每天从0开始的流水号。\n\n比如订单号=日期+当日自增长号。可以每天在redis中生成一个Key，使用INCR进行累加。\n\n优点：\n\n1. 不依赖于数据库，灵活方便，且性能优于数据库。\n2. 数字ID天然排序，对分页或者需要排序的结果很有帮助。\n\n缺点：\n\n1. 如果系统中没有redis，还需要引入新的组件，增加系统复杂度。\n2. 需要编码和配置的工作量比较大。\n\n# twitter\n\ntwitter在把存储系统从MySQL迁移到Cassandra的过程中由于Cassandra没有顺序ID生成机制，于是自己开发了一套全局唯一ID生成服务:`Snowflake`。\n\nSnowflake使用二进制计数,讲一个完整的UUID分为不同部分,依据不同的规则生成\n\n1. 41位的时间序列（精确到毫秒，41位的长度可以使用69年）\n2. 10位的机器标识（10位的长度最多支持部署1024个节点）\n3. 12位的计数顺序号（12位的计数顺序号支持每个节点每毫秒产生4096个ID序号） 最高位是符号位，始终为0。\n\n\n![](640.webp)\n\n优点：\n\n1. 高性能，低延迟；独立的应用;\n2. 按时间有序。 \n\n缺点:\n\n1. 需要独立的开发和部署。\n2. 强依赖时钟,如果主机时间回拨,则会造成重复ID,会产生\n3. ID虽然有序,但是不连续\n\n# mongodb\n\nMongoDB的ObjectId和snowflake算法类似。\n\n它设计成轻量型的，不同的机器都能用全局唯一的同种方法方便地生成它。\n\nMongoDB 从一开始就设计用来作为分布式数据库，处理多个节点是一个核心要求。\n\n使其在分片环境中要容易生成得多\n\n如果观察过mongodb的数据会发现,在短期内插入大量数据的话只有后面几位不一致\n\n但是如果你等几秒再插入数据,中间部分地方也会不一致\n\nObjectId使用12字节的存储空间，其生成方式如下：\n\n|0-1-2-3|4-5-6|7-8|9-10-11|\n|:-|:-|:-|:-|\n|时间戳 |机器ID|PID|计数器 |\n\n前四个字节时间戳是从标准纪元开始的时间戳，单位为秒，有如下特性：\n\n 1 时间戳与后边5个字节一块，保证秒级别的唯一性；\n 2 保证插入顺序大致按时间排序；\n 3 隐含了文档创建时间；\n 4 时间戳的实际值并不重要，不需要对服务器之间的时间进行同步（因为加上机器ID和进程ID已保证此值唯一，唯一性是ObjectId的最终诉求）。\n\n机器ID是服务器主机标识，通常是机器主机名的散列值。\n\n同一台机器上可以运行多个mongod实例，因此也需要加入进程标识符PID。\n\n前9个字节保证了同一秒钟不同机器不同进程产生的ObjectId的唯一性。后三个字节是一个自动增加的计数器（一个mongod进程需要一个全局的计数器），保证同一秒的ObjectId是唯一的。同一秒钟最多允许每个进程拥有（256^3 = 16777216）个不同的ObjectId。\n\n\n如: \"5a3fa45b421aa93195b92d67\"\n\n优点: \n\n1. 时间戳保证秒级唯一\n2. 机器ID保证设计时考虑分布式\n3. 避免时钟同步\n4. PID保证同一台服务器运行多个mongod实例时的唯一性\n5. 最后的计数器保证同一秒内的唯一性（选用几个字节既要考虑存储的经济性，也要考虑并发性能的上限）。\n6. 既可以在服务器端生成也可以在客户端生成，在客户端生成可以降低服务器端的压力。\n\n缺点:\n\n1. 需要独立实现和部署\n\n# 携程的方案\n\n携程采用了另一种解决方案\n\n也是基于数据库\n\n先在数据库中创建一个表\n\nid| server \n---|---\n 1 | 192.168.8.1\n 2 | 192.168.8.2\n\n要获取id的时候先使用 replace into 更新自己服务器的记录, 然后在查询自己服务器的当前值\n\n> ps: replace into 会先尝试insert into 如果已经存在会进行对当前记录删除,然后重新插入\n\n这样就能获取到每个服务器的最大的值了\n\n但是这样性能会损耗比较大\n\n所以携程做了id段缓存\n\n一次性生成 1000(这个数字可配置) 个id\n\n要获取当前id的时候会先去请求缓存检查当前要获取的数字是否在缓存段中,如果在就直接获取,不存在就重新触发id段的生成,然后获取id\n\n举例:\n\n192.168.8.1 第一次拿到的id是1,那他就会把号段 (1 * 1000,(1+1)*1000)(左闭右开区间)存入缓存, 该机器上面的客户获取id的时候就检查是否在这个范围之内, 如果刚好等于2000\n\n则去触发号段更新,此时号段id为3, 生成的对应号段为 (3*1000, (3+1) *1000)\n\n再执行号码分发的处理\n\n优点:\n\n1. 数字类型, 使用方便\n2. 生成简单\n\n缺点:\n\n1. 需要单独实现\n2. 当缓存服务器数据丢失的话,会造成id段浪费\n\n# 总结\n\n总体而言，分布式唯一ID需要满足以下条件：\n\n高可用性：不能有单点故障。\n\n全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。\n\n趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。\n\n时间有序：以时间为序，或者ID里包含时间。这样一是可以少一个索引，二是冷热数据容易分离。\n\n分片支持：可以控制ShardingId。比如某一个用户的文章要放在同一个分片内，这样查询效率高，修改也容易。\n\n单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。\n\n长度适中：不要太长，最好64bit。使用long比较好操作，如果是96bit，那就要各种移位相当的不方便，还有可能有些组件不能支持这么大的ID。\n\n信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞争对手可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。","categories":["系统设计"],"tags":["UUID"]},{"title":"redis中的数据对象","url":"/2017-01-11-redis-object/","content":"# redis对象\n\nredis中有五种常用对象\n\n我们所说的对象的类型大多是值的类型,键的类型大多是字符串对象,值得类型大概有以下几种,但是无论哪种都是基于redisObject实现的\n\n<!--more-->\nredisObject的结构如下\n\n```c\ntypedef struct redisObject {\n    unsigned type:4; //类型 有五种,分别对应五种常见的值类型\n    unsigned encoding:4; // 编码,标明底层数据结构的类型\n    unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or\n                            * LFU data (least significant 8 bits frequency\n                            * and most significant 16 bits decreas time). */\n    int refcount; //  引用计数\n    void *ptr;    //  存储结构指针\n} robj;\n\n```\n\ntype的可选值有五种.分别是\n\n```c\n    REDIS_STRING,\n    REDIS_LIST,\n    REDIS_SET,\n    REDIS_ZSET ,\n    REDIS_HASH\n\n```\n\nencoding的可选值有八种(redis3.2版本新加入了quicklist)\n\n|REDIS_ENCODING_INT|long型的整数|\n|:-|:-|\n|REDIS_ENCODING_EMBSTR|embstr编码的简单动态字符串|\n|REDIS_ENCODING_ROW|简单动态字符串|\n|REDIS_ENCODING_LINKEDLIST|双端链表|\n|OBJ_ENCODING_QUICKLIST|快速链表|\n|REDIS_ENCODING_HH|字典|\n|REDIS_ENCODING_ZIPLIST|压缩列表|\n|REDIS_ENCODING_INTSET|整数集合|\n|REDIS_ENCODING_SKIPLIST|跳跃表|\n\n\n新的redis3.2以后的源码中更改了底层的数据结构,新的的定义如下,在`server.h`文件中有定义\n\n其中linkedlist是旧的list的底层实现,现已被quicklist代替\n\n```c\n\n/* Objects encoding. Some kind of objects like Strings and Hashes can be\n * internally represented in multiple ways. The 'encoding' field of the object\n * is set to one of this fields for this object. */\n#define OBJ_ENCODING_RAW 0     /* Raw representation */\n#define OBJ_ENCODING_INT 1     /* Encoded as integer */\n#define OBJ_ENCODING_HT 2      /* Encoded as hash table */\n#define OBJ_ENCODING_ZIPMAP 3  /* Encoded as zipmap */\n#define OBJ_ENCODING_LINKEDLIST 4 /* No longer used: old list encoding. */\n#define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */\n#define OBJ_ENCODING_INTSET 6  /* Encoded as intset */\n#define OBJ_ENCODING_SKIPLIST 7  /* Encoded as skiplist */\n#define OBJ_ENCODING_EMBSTR 8  /* Embedded sds string encoding */\n#define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */\n\n```\n\ntype和encoding共同决定了数值对象的底层结构和存储\n\n## 字符串对象\n\n字符串对象的编码可以是int,embstr和row\n\nredis中的字符串对象是最常用的数据对象之一,redis中的许多键都是采用的字符串对象\n\n字符串类型在redis中根据情况不同有3中情况\n\n1. 对于元素都是纯数字类型的, 例如,'1','2'这种会使用int类型存储,redis默认初始化了10000个数字对象\n2. 对于长度小于32的字符串类型,例如'hello',redis会使用embstr类型存储数据\n3. 对于长度超过32的使用row存储原字符\n\n>ps: embstr类型的字符串在修改后总会变成row编码类型(redis3.2之后该机制已失效)\n\n## 列表\n\n### redis3.2之前\n\n在redis3.2之前, 列表的编码可以是linkedlist或者ziplist\n\n1. 当列表对象保存的所有字符串长度小于64字节\n2. 当列表对象保存的元素数量小于512个的时候\n\n这个时候会使用,ziplist来作为列表对象的编码, 当不满足这两个条件的时候使用linkedlist\n\n>ps:这两个值是更改的,list-max-ziplist-value 和 list-max-ziplist-entries\n\n### redis3.2之后\n\n列表的实现在3.2之后改为quicklist实现\n\nquicklist可以看做一个类似链表的结构, 但是每个节点都是一个ziplist,所以每个ziplist内部可以包含多个数据\n\n>ps: 理念上有点类似于Java中的concurrenthashmap\n\n## 哈希对象\n\n哈希对象的编码可以是ziplist或者hashtable\n\n字典的每一个键和值都是一个字符串对象\n\n1. 哈希对象保存的所有键和值的长度都小于64字节\n2. 哈希对象保存的键值对数量小于512个的时候\n\n满足以上两个条件,使用ziplist存储,否则采用hashtable存储\n\n>ps:这两个值是更改的,hash-max-ziplist-value 和 hash-max-ziplist-entries\n\n## 集合\n\n集合对象的编码可以是intset或者hashtable\n\n当集合对象满足以下两个条件的时候采用intset\n\n1. 集合对象保存的元素都是整数\n2. 集合对象保存的元素数量不超过512个\n\n不满足以上两个条件都是用hashtable存储\n\n>ps: 该数值可以使用set-max-intset-entries设置\n\n## 有序集合\n\n有序集合对象的编码可以是ziplist或者skiplist\n\n有序集合对象跟前面的几个对象不大一样\n\n```c\ntypedef struct zset{\n    zskiplist *zsl;\n    dict *dict;\n} zset;\n```\nzsl中保存一个跳跃表,表节点的对象即是键,score即是分值,该结构主要为 zrange,zrank等函数服务\n\n同时还保存一个dict,dict中也保存有键和对应的分值,获取某键的函数zscore使用这个结构,\n\n同时持有字典和跳跃表是为了性能考虑\n\n当有序集合满足一下两个条件时候,使用ziplist编码\n1. 有序集合元素数量小于128\n2. 有序集合元素长度小于64\n\n不能满足以上两个条件的使用skiplist\n\n\n## 总结\n\n数据对象的实现之所以有这种情况,其实是适应2个不同场景, 节省内存和常规场景,具体表格如下\n\n|对象|省内存|常规|\n|:-|:-|:-|\n|str|int/embstr| row |\n|list|ziplist|linkedlist(quicklist)|\n|hash|ziplist|hashtable|\n|set|intset|hashtable|\n|zset|ziplist|skiplist|\n\n## 回收\n\nredis的对象资源垃圾回收是基于引用计数\n\n当一个对象被使用一次,引用计数增加1\n\n当一个引用被销毁,对象的引用计数会减1\n\n当一个对象的引用计数为0,会被销毁\n\n>ps: 这有点像PHP的垃圾回收机制\n\n\n## 对象共享\n\nredis默认创建了0到9999的数字对象1万个\n\n其他用到这些对象的时候可以不用创建新对象,直接使用已有的对象\n","categories":["工具原理"],"tags":["redis","nosql"]},{"title":"redis的基础数据结构","url":"/2017-01-09-redis-data-structure/","content":"\n# redis基础数据结构\n\nredis中的数据对象有5种,但是这并不是redis中真正的数据存放方式, 只是对底层的数据存放结构进行了封装的对象\n\nredis的几种基础数据结构是redis中的最重要的部分, redis后续的几乎所有功能的设计和实现都依赖于此\n\n# sds简单动态字符串\n\n*对应的上层对象是* `字符串`\n\n## 数据结构\n\n具体的数据结构如下:\n\n```c\ntypedef struct sdstr{\n\tint   len     // 字符串分配的字节\n\tint   free    // 未使用的字节数\n\tchar  buff[]  // 存储字符串的数组\n}\n```\nsds是字符串对象的底层实现之一\n\n## sds的特性\n\n赋值操作会统计字符串的长度然后将字符串存入buff字符数组里面,同时设定长度和使用的长度\n\n例如 \"hello\"这个字符串的存储结构如下\n\n```c\n{\n\tlen:5,\n\tfree:0,\n\tbuff:['h','e','l','l','o','\\0']\n}\n```\n修改的时候会比较麻烦,分为两种情况\n\n一是由段字符串变长:例如:由\"hello\"变为\"hello,redis\".\n\n这个时候系统会检查原本的sds字符串是否有空余空间,剩余空间为0\n\n会分配等同于修改后字符串长度的剩余空间给sds,这个时候字符串的free属性会变为11,然后执行sdscat()\n\n这个时候buff会变为['h','e','l','l','o',',','r','e','d','i','s','\\0']\n\n然后将字符串长度len修改为11\n\n最终结构如下\n\n```c\n{\n\tlen:11,     \n\tfree:11,\n\tbuff:['h','e','l','l','o',',','r','e','d','i','s','\\0']\n}\n```\n\nps:当长度小于1M是翻倍扩容,超过1M时是以1M为标准定量扩容\n\n二是由长字符串变短\n\n例如:由\"hello,redis\"变为\"redis\",这个时候会释放多余空间,同时把free值设为多出来的空间,以便下次使用方便\n\n修改后的结构大概如下\n\n```c\n{\n\tlen:5,      // 字符串长度\n\tfree:17,    // 原本11,加上释放到的6个字节\n\tbuff:['r','e','d','i','s','\\0']\n}\n```\n需要释放的时候可以手动调用函数来释放空间\n\n## 为什么要使用sds?\n\n1. sds可以杜绝缓冲区溢出的问题,获取字符串长度复杂度为常数\n2. 二进制安全,sds使用len属性来判断字符串的结束\n3. 减少字符串修改时的内存重分配次数\n\n# 链表和quicklist\n\n## 数据结构\n\n抄袭自redis的源代码\n\n```c\n\n//链表\ntypedef struct list{\n\tlistNode * head;  \t//头节点\n\tlistNode * tail;\t//尾节点\n\tunsigned long len; \t//节点数量\n\tvoid *(*dup)(void *ptr);\t//节点值复制函数\n\tvoid (*free)(void *ptr); \t//节点值释放函数\n\tvoid (*match)(void *ptr,void *key);\t//节点值对比函数\n}\n\n//链表节点\ntypedef struct listNode{\n\tstruct listNode *pre;\n\tstruct listNode *next;\n\tvoid *value;\n}listNode;\n\n```\n\n换成形象点的json的形式就是如下\n\n```c\n\n{\n    list: {\n        head: {\n            pre: null,\n            next: 2,\n            value: 1\n        },\n        tail: {\n            pre: 99,\n            next: null,\n            value: 100\n        },\n        len: 100,\n        dup:function () {},\n        free:function () {},\n        match:function () {}\n    }\n}\n\n```\n\n链表是列表对象的底层实现之一(version 3.2 之前)\n\n链表在redis中主要负责的是存储和维护某一类对象,所常用到的操主要有遍历,修改等\n\n链表在redis中使用极为广泛,redis的事务,发布与订阅,服务器中维护的redisClient信息等都是用链表结构进行的存储\n\n# quicklist\n\nredis在3.2版本新加入了quicklist数据结构作为list的底层实现\n\n## 数据结构\n\n以下代码来自redis源码\n\n```c\n\ntypedef struct quicklistEntry {\n    const quicklist *quicklist;\n    quicklistNode *node;\n    unsigned char *zi;\n    unsigned char *value;\n    long long longval;\n    unsigned int sz;\n    int offset;\n} quicklistEntry;\n\n/* quicklist is a 32 byte struct (on 64-bit systems) describing a quicklist.\n * 'count' is the number of total entries.\n * 'len' is the number of quicklist nodes.\n * 'compress' is: -1 if compression disabled, otherwise it's the number\n *                of quicklistNodes to leave uncompressed at ends of quicklist.\n * 'fill' is the user-requested (or default) fill factor. */\ntypedef struct quicklist {\n    quicklistNode *head;\n    quicklistNode *tail;\n    unsigned long count;        /* total count of all entries in all ziplists */\n    unsigned int len;           /* number of quicklistNodes */\n    int fill : 16;              /* fill factor for individual nodes */\n    unsigned int compress : 16; /* depth of end nodes not to compress;0=off */\n} quicklist;\n\n/* quicklistNode is a 32 byte struct describing a ziplist for a quicklist.\n * We use bit fields keep the quicklistNode at 32 bytes.\n * count: 16 bits, max 65536 (max zl bytes is 65k, so max count actually < 32k).\n * encoding: 2 bits, RAW=1, LZF=2.\n * container: 2 bits, NONE=1, ZIPLIST=2.\n * recompress: 1 bit, bool, true if node is temporarry decompressed for usage.\n * attempted_compress: 1 bit, boolean, used for verifying during testing.\n * extra: 12 bits, free for future use; pads out the remainder of 32 bits */\ntypedef struct quicklistNode {\n    struct quicklistNode *prev;\n    struct quicklistNode *next;\n    unsigned char *zl;\n    unsigned int sz;             /* ziplist size in bytes */\n    unsigned int count : 16;     /* count of items in ziplist */\n    unsigned int encoding : 2;   /* RAW==1 or LZF==2 */\n    unsigned int container : 2;  /* NONE==1 or ZIPLIST==2 */\n    unsigned int recompress : 1; /* was this node previous compressed? */\n    unsigned int attempted_compress : 1; /* node can't compress; too small */\n    unsigned int extra : 10; /* more bits to steal for future usage */\n} quicklistNode;\n\n\n```\n\n## quicklist特性\n\nquicklist本身是一个双向无环链表，它的每一个节点都是一个ziplist。为什么这么设计呢？\n\n- 双向链表在插入节点上复杂度很低，但它的内存开销很大，每个节点的地址不连续，容易产生内存碎片。\n- ziplist是存储在一段连续的内存上，存储效率高，但是它不利于修改操作，插入和删除数都很麻烦，复杂度高，而且其需要频繁的申请释放内存，特别是ziplist中数据较多的情况下，搬移内存数据太费时！\n\n可以这么理解\n\n一个quicklist内部包含有多个ziplist, 每个ziplist里面又可以包含多个数据节点,\n\n例如: [1,2,3,4,5,6,7,8,9]\n\n上面这个链表的存储如果用quicklist来存储就可以分为3个ziplist\n\n每个ziplist又有3个数据节点,[[1,2,3],[4,5,6],[7,8,9]]\n\n主要目的还是为了在时间和空间上面取得一个平衡,至于每个ziplist分多大可以自定义配置\n\n# 字典\n\n## 数据结构\n\n```c\n\ntypedef struct dict {\n    dictType *type;\n    void *privdata;\n    dictht ht[2];\n    long rehashidx; /* rehashing not in progress if rehashidx == -1 */\n    unsigned long iterators; /* number of iterators currently running */\n} dict;\n\n/* This is our hash table structure. Every dictionary has two of this as we\n * implement incremental rehashing, for the old to the new table. */\ntypedef struct dictht {\n    dictEntry **table;\n    unsigned long size;\n    unsigned long sizemask;\n    unsigned long used;\n} dictht;\n\ntypedef struct dictEntry {\n    void *key;\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n    } v;\n    struct dictEntry *next;\n} dictEntry;\n```\n\nhash 使用json格式表示大概如下\n\n```c\n{\n    dict: {\n        type: hash,\n        privadata: null,\n        ht: [{\n                size: 100,\n                used: 80,\n                sizemask: \"0xff778\",\n                hash: {\n                    key: \"test1\",\n                    value: 22,\n                    next: 34\n                }\n            },\n            {}  // rehash时候使用\n        ],\n        rehashidx: -1\n    }\n}\n```\n字典是数据库的底层实现\n\n整体数据结构由dict持有2个dictht，\n\n其中一个dictht[1]在rehash时候使用，dictht[0]中用来存储数据\n\n持有一个dictEntry组成的数组，每个dictEntry保存一个键值对\n\n## hash过程\n\n采用hash函数对键进行哈希配合dictht的sizemask计算出来索引值\n\n\tindex = hash(key) & sizemask\n\n然后将键值对存入哈希表节点\n\n>ps: 这个过程跟redis中计算键所对应的slot的方法相似\n\n## 解决键冲突\n\nredis使用链地址法(separate chaining)\n\n来解决键冲突,当两个键的index值相同时,会把第二个键放到第一个键的前面,查询时对这个index的哈希节点链表进行遍历\n\n## 渐进式的rehash\n\n当哈希表的负载因子(load factor)大于设定值时(平时为1,在BGREWRITEAOF时为5),哈希表会进行rehash操作\n\nrehash采用渐进式的方式进行执行,具体流程\n\n**把ht[0]里面的数据重新进行哈希计算放到ht[1],此时的哈希查询操作两个表同时提供服务,写入操作则只有ht[1]提供,这样ht[0]处于只减不增的状态,最终当ht[0]里面的所有数据都被转移到ht[1]时,rehashidx被设为-1,表明rehash结束,删除ht[0],并将ht[1]设为ht[0],同时重新分配新的ht[1]**\n\n>ps:负载因子 = used /size;\n\n# 跳跃表\n\n## 数据结构\n\n```c\n//跳跃表\ntypedef struct zskiplist{\n    struct zskiplistNode *header,*tail;//头结点和尾节点\n    unsigned long length;//表中节点数量\n    int level;//表中除头节点外层数最大的节点\n} zskiplist;\n\n//跳跃表节点\ntypedef struct zskiplistNode {\n    //层\n    struct zskiplevel{\n        struct zskiplistNode *forward;//前进指针\n        unsigned int span;//跨度\n    } level[];\n    struct zskiplistNode *backword;//后退指针\n    double score;//分值\n    robj *obj;\n} zskiplistNode;\n\n```\n跳跃表json形式:\n\n```c\n\n{\n    zskiplist: {\n        header: {\n            obj: \"aa\",\n            score: 45,\n            backforward: null,\n            zskiplevel: [{\n                forward: null,\n                span: 9\n            },{\n                forward: *p,\n                span: 8\n            }]\n        },\n        tail: {\n            obj: \"aa\",\n            score: 45,\n            backforward: null,\n            zskiplevel: [{\n                forward: null,\n                span: 9\n            }]\n        },\n        length: 100,\n        level: 32\n    }\n}\n\n```\n\n跳跃表图示:\n\n![跳跃表](IMG_0256.jpeg)\n\n跳跃表是有序集合的底层实现之一\n\n跳跃表中的头结点不计算在length长度之内,跳跃表的节点排序按照分值从小到大排序\n\n每次创建新节点的时候,redis会根据幂次定律随机生成一个1-32的层数作为level数组的大小\n\n每个节点都有指向表尾方向的前进指针和之前表头方向的后退指针\n\n这两个指针可以让程序方便的遍历所有节点,层的跨度用于记录两点之间的距离\n\n跨度可以用来计算rank值.节点的分值是一个double值\n\n节点的对象是一个指针,指向一个保存着sds字符串的字符串对象(下一节讲redis对象)\n\n跳跃表通过每个`zskiplistNode`来保存每个元素的信息，元素的键就是obj的指针指向的对象，对应的分值就是score字段\n\n# 整数集合\n\n## 数据结构\n\n```c\n\ntypedef struct intset {\n    uint32_t encoding;\n    uint32_t length;\n    int8_t contents[];\n} intset;\n```\n\n顾名思义整数集合是用来保存整数值的抽象数据结构\n\n集合中不会出现重复元素\n\ncontents数组中保存的整数值有小到大排列\n\nlength等于contents的长度\n\n虽然contents的定义是int8_t 但实际上contents的值类型由encoding决定\n\n## 升级\n\n当一个新元素超过原来整数集合encoding定义的值的类型时,会进行升级\n\n升级结果会使集合的encoding变成所有数组中元素的值最大的数据类型,并且不支持降级\n\n例如:有一个整数集合[1,2,3],本身的编码为`int8`,现在增加一个300的数字进该集合\n\n会导致集合的编码升级为`int16`,这个时候列表的大小由8x3=24 变为 16x4=64\n\n即便`int8`可以存储前三个值,但是为了简单起见,仍然会为集合中每一个元素分配同样的空间\n\n# 压缩列表(Ziplist)\n\n压缩列表被用作列表键和哈希键的底层实现\n\n压缩列表属于特殊的结构,是一种数据存储的方式,目的是为了节约内存,是一种采用特殊编码的连续内存块组成的顺序型(sequential)数据结构.\n\n大致结构如下:\n\n|zlbytes|zltail|zllen|entry1|entry2|...|zlend|\n|:-|:-|:-|:-|:-|:-|:-|\n|总长度|偏移量|节点数量|节点1|节点2|...|结束|\n\n每个压缩列表节点由如下三部分组成\n\n|previous_entry_length|encoding|content|\n|:-|:-|:-|\n|前一节点的长度|记录content的类型和长度|节点的值|\n\n一个ziplist示例:\n\n```c\n{\n    zlbytes:\"0x50\",\n    zltail:\"0x3c\",\n    zllen:\"0x3\",\n    {\n        previous_entry_length:\"0x05\",\n        encoding:\"00001011\",\n        content:\"hello word\"\n    },{\n        previous_entry_length:\"0xF\",\n        encoding:\"11000000\",\n        content:\"10086\"\n    },\n    zlend:\"0xff\"\n}\n\n```\n\n如果前一个节点长度小于254字节,previous_entry_length会使用1字节空间保存这个长度,\n如果大于254字节,将使用5字节长度保存这个值,这个机制会引起\"连锁更新\"\n\n## ziplist连锁更新的问题\n\n假设现有连续的三个压缩列表节点l1,l2,l3,长度分别为 253,253,253\n\n现在往第一个节点前添加一个长度超过254的节点,这个时候l1要给previous_entry_length分配5个字节来存储长度,所以列表本身长度会变为257,这将导致l2也需要5字节存储l1的长度,l3也会产生同样的变化,这样由一个列表操作引起的一系列更新操作成为连锁更新\n\n连锁更新的发生有可能会严重影响性能，所以要尽量避免\n","categories":["工具原理"],"tags":["redis","数据结构"]},{"title":"2017-追番-看书记录","url":"/2017-01-01-comic-book-2017/","content":"\n# Record\n\n想法来自 [@Sollrei](http://blog.sollrei.me)\n\n## 2017\n\n### 2月\n\n番剧:\n\n- [x] 东皇战影\n\n图书:\n\n- [x] 三体3:死神永生\n- [x] 魔鬼搭讪学\n- [x] 魔鬼约会学\n- [x] 谁动了我的奶酪\n\n电影:\n\n- [x] 假如爱有天意\n\n### 3月\n\n番剧:\n\n- [x] 人渣的本愿\n- [x] 从前有座灵剑山\n- [x] 斗破苍穹\n- [x] 小林家的龙女仆\n\n图书:\n\n- [x] 解忧杂货铺\n- [x] 嫌疑人X的献身\n- [x] 图解博弈论\n- [x] 菊与刀\n- [x] 极简生活:简而美的活着\n\n### 4月\n\n番剧:\n\n- [x] 画江湖之不良人\n\n书:\n\n- [x] 人类简史\n- [x] 人民的名义\n- [x] 好好说话\n\n其他:\n\n- [ ] nice chord\n\n### 5月\n\n番剧:\n\n- [x] 龙的牙医\n- [x] 少年锦衣卫\n\n书:\n\n- [x] 走进搜索引擎\n- [x] 万历十五年\n- [x] 秘密\n- [x] 精进:如何做一个厉害的人\n- [x] Go Web编程\n\n### 6月\n\n番剧:\n\n- [x] 进击的巨人第二季\n\n书:\n\n- [x] redis设计与实现\n\n### 7月\n\n书:\n\n- [x] 枪炮,病菌与钢铁\n\n### 8月\n\n书:\n\n- [x] 时间的形状\n- [x] C++面向对象程序设计\n- [x] 恶意\n- [x] HTTP权威指南\n\n### 9月\n\n番剧:\n\n- [x] FATE/Apocrypha\n- [x] 画江湖之杯莫停\n\n书:\n\n- [x] 人生的智慧\n\n### 10月\n\n书:\n\n- [x] 红楼梦(前80回原版,后四十回不符原意,不看了)\n- [x] 请停止无效努力:如何用正确的方法快速进阶\n\n### 11月\n\n番剧:\n\n- [x] 魆妖纪\n\n书:\n\n- [x] Go语言编程\n- [x] 好好说话\n- [x] redis实战\n\n### 12月\n\n番剧:\n\n- [x] 宝石之国\n\n书:\n\n- [x] 你要做的,只不过是发现生活的美\n- [x] Java从初学到精通\n- [x] 数据结构与算法\n- [x] 乌合之众:大众心理研究\n- [x] 精灵宝钻\n\n合计:\n\n图书: 33本\n番剧: 13部","categories":["年度总结"]},{"title":"谏迎佛骨表--韩愈","url":"/2016-07-07-poem-jianyingfogu/","content":"\n# R\n\n## 灭佛运动\n\n为什么要贴这个呢?\n\n主要是看到当今中国绿化之势不可挡, 有感而发.\n\n也希望某些人能从历史中吸取教训\n\n## 谏迎佛骨表\n\n臣某言：伏以佛者，夷狄之一法耳,自后汉时流入中国,上古未尝有也。昔者黄帝在位百年，年百一十岁；少昊在位八十年，年百岁；颛顼在位七十九年，年九十八岁；帝喾在位七十年，年百五岁；帝尧在位九十八年，年百一十八岁；帝舜及禹，年皆百岁。此时天下太平，百姓安乐寿考，然而中国未有佛也。其后殷汤亦年百岁，汤孙太戊在位七十五年，武丁在位五十九年，书史不言其年寿所极，推其年数，盖亦俱不减百岁。周文王年九十七岁，武王年九十三岁，穆王在位百年。此时佛法亦未入中国，非因事佛而致然也。\n\n汉明帝时，始有佛法，明帝在位，才十八年耳。其后乱亡相继，运祚不长。宋、齐、梁、陈、元魏已下，事佛渐谨，年代尤促。惟梁武帝在位四十八年，前后三度舍身施佛，宗庙之祭，不用牲牢，昼日一食，止于菜果，其后竞为侯景所逼，饿死台城，国亦寻灭。事佛求福，乃更得祸。由此观之，佛不足事，亦可知矣。\n\n高祖始受隋禅，则议除之。当时群臣材识不远，不能深知先王之道，古今之宜，推阐圣明，以救斯弊，其事遂止，臣常恨焉。伏维睿圣文武皇帝陛下，神圣英武，数千百年已来，未有伦比。即位之初，即不许度人为僧尼道，又不许创立寺观。臣常以为高祖之志，必行于陛下之手，今纵未能即行，岂可恣之转令盛也?\n\n今闻陛下令群僧迎佛骨于凤翔，御楼以观，舁入大内，又令诸寺递迎供养。臣虽至愚，必知陛下不惑于佛，作此崇奉，以祈福祥也。直以年丰人乐，徇人之心，为京都士庶设诡异之观，戏玩之具耳。安有圣明若此，而肯信此等事哉!然百姓愚冥，易惑难晓，苟见陛下如此，将谓真心事佛，皆云：“天子大圣，犹一心敬信；百姓何人，岂合更惜身命!”焚顶烧指，百十为群，解衣散钱，自朝至暮，转相仿效，惟恐后时，老少奔波，弃其业次。若不即加禁遏，更历诸寺，必有断臂脔身以为供养者。伤风败俗，传笑四方，非细事也。\n\n夫佛本夷狄之人，与中国言语不通，衣服殊制；口不言先王之法言，身不服先王之法服；不知君臣之义，父子之情。假如其身至今尚在，奉其国命，来朝京师，陛下容而接之，不过宣政一见，礼宾一设，赐衣一袭，卫而出之于境，不令惑众也。况其身死已久，枯朽之骨，凶秽之馀，岂宜令入宫禁？\n\n孔子曰：“敬鬼神而远之。”古之诸侯，行吊于其国，尚令巫祝先以桃茹祓除不祥，然后进吊。今无故取朽秽之物，亲临观之，巫祝不先，桃茹不用，群臣不言其非，御史不举其失，臣实耻之。乞以此骨付之有司，投诸水火，永绝根本，断天下之疑，绝后代之惑。使天下之人，知大圣人之所作为，出于寻常万万也。岂不盛哉!岂不快哉!佛如有灵，能作祸祟，凡有殃咎，宜加臣身，上天鉴临，臣不怨悔。无任感激恳悃之至，谨奉表以闻。臣某诚惶诚恐。\n","categories":["收藏记录"]},{"title":"关于编程语言的一些看法","url":"/2016-06-08-idea-programing-language/","content":"# 编程语言\n\n作为一个程序员, 总是在不断的`制作工具`->`使用工具`->`制作工具`->`使用工具`的循环中\n\n在这个循环中最重要的一个工具, 可能就是编程语言了\n\n编程语言的种类有很多, 目前依然存在的少说也有数千种, 更不用说那些湮没在历史长河中的了, 但是真正出名的不是很多\n\n很多人会疑惑, 为什么会有这么多编程语言呢\n\n其实很多语言都是 在特定时期,在特定领域,为了解决特定问题而出现的\n\n随着语言的进化, 一个语言也可能在2-3个领域获得成功, 但是我目前还没有见过一门可以 全领域通吃的编程语言\n\n## 工具\n\n编程语言是有很强工具特性的东西\n\n其实很多编程语言都是可以做相同的事情的, 比如: \n\n    python 可以做web应用\n    java   可以做web应用\n    node   可以做web应用\n    go/php 可以做web应用\n\n实际上,c/c++/ruby/lisp/lua 都是可以做web应用的, 这不是能不能的问题, 其实就是成本问题\n\n同样, python/php/node/go也都可以做GUI应用, GUI应用其实不仅仅`java/c/c++`可以做\n\n这样问题就来了, 为什么一门编程语言就能做所有事情, 还会出现那么多编程语言呢\n\n答案是 `成本`.\n\n首先, 编程语言是否流行主要看该语言使用的人数和发展趋势\n\n在国内按人数来说目前最流行的3门语言应该是 `Java`,`php`,`JavaScript`\n\n不过如果按热门程度的话(使用者增长比例),前几名应该是 Go,Python,Swift等\n\n其他的还有一些很有特色的编程语言例如 `lisp`,`clojure`,`rust`等\n\n## 思维\n\n编程语言同时也会很深的影响使用者的思维方式, 一个程序员的初学语言会极大的影响这个人的思维方式\n\n编程语言虽然都是工具,但是又不是简单的纸笔一类的工具\n\n编程语言会切实的参与到你制作的产品当中,从这个角度看\n\n> 编程语言更像是一种原材料\n\n同时每一门编程语言基本都蕴含了一套思想体系,无论是`c/c++`,还是`Java`/`python`\n\n很多计算机科学家都建议大家使用设计上来说比较优秀的编程语言来进行使用,这是有道理的\n\n有的语言偏重工程,有的语言重学术, 有的重开发效率,有的重视执行效率,除去这些表面的特性差别,有的语言提倡干净简单,有的提倡完善强大.\n\n初学者没必要大纠结这些语言的倾向\n\n## 一个现象\n\n我观察到很多刚学编程的人有一种心理\n\n老是想学\"最好的\"编程语言, 这个最好的标准可能是最通用, 性价比最高,最有挑战性等等\n\n而且还有一部分人有另一种不好的想法:\n\n**看不起使用者人数众多的语言,希望通过标新立异来表明自己是个多么有独立见解,好像这样就能显得自己多有思想一样**\n\n看Java使用者众多就看不起Java, 心里想着你看你就会Java,这玩意大家都会, 你看看我会的scala/lisp/rust, 多高大上啊, 你不会吧\n\n也就是所谓的要求高逼格\n\n`逼格`来源于门槛,不应该是仅仅根据使用人数来界定, 门槛高的东西注定懂的人不会多, 用的人少并不会带来`逼格`\n\n### 我的看法\n\n从我个人的角度我觉得如果把编程语言领域比作金庸先生书中的江湖\n\nc/c++/Java这种就是传统的武林豪门少林/武当这种\n\n或许在大部分书中这些门派都不是最强的,但一定是不会太差,处于平均水准以上\n\n虽然'九阴真经','北冥神功'这种级别的绝世武功也大多不是出于少林武当\n\n但是,这种绝世武功不是适合所有人的\n\n高收益往往伴随着高风险\n\n所以还是建议大家多看,多学,增广见闻\n\n见的多了,看得多了,了解的多了,最后根据自己的需要去选择,不要一开始就去选择拒绝\n\n> \"当你拒绝一个事物,你就失去了向他学习的机会\"\n\n## 编程语言的分类\n\n大概列举一下常见的编程语言和应用的领域\n\n### 主要领域:\n\nWeb应用: 以网站和浏览器为载体向用户提供服务的应用, 例如: 百度,谷歌等 特点: 使用方便,交互友好,更新迅速\n\n服务器编程: 提供数据存储和服务的应用, 例如:各种软件平台,操作系统,数据库等服务. 特点: 功能专一,性能要求高,稳定性要求高\n\n网络和存储: 基于socket的服务,类型比较多, 多以数据交互和通信为主\n\n嵌入式: 各种嵌入式设备, 属于偏硬件的编程系统\n\n图形: 基于openGL/dx3d/vulkan等图形技术进行图像绘制和处理的服务\n\n游戏: 形式比较多,性能要求高\n\n数据分析: 大数据,AI都属于数据分析的范畴\n\n移动端: iOS,Android等\n\n### 各语言在各领域的分布\n\njava: 主要服务器编程,大数据处理,安卓移动端,web端\n\nc: 系统底层编程, 网络编程, 嵌入式设备\n\nc++: 图形和游戏,系统底层服务,服务器端\n\npython: 数据分析, web应用,以及很多的小工具或者作为嵌入式的脚本语言在各种系统中出现\n\njavascript: web应用, 服务器编程, 移动应用\n\nphp: web应用和服务器编程\n\ngo: web应用, 网络编程 ,服务器编程\n\nswift/object-c: 移动端(iOS), 服务器端\n\n### 其他\n\n我这里大概谈一些我对编程语言的看法\n\n我在工作中发现有不少的人都有一种倾向就是看不起其他编程语言的使用者\n\n*用php的看不起用js的, 用java的看不起用php的, 用c的看不起用java的, 用lisp的看不起其他所有人(^_^)*\n\n其实这是不可取的, 编程语言并不是程序的全部, 甚至都不是程序最重要的部分\n\n每种语言都有不同的适用场景, 不谈业务场景而只说语言好坏都是耍流氓\n\n我们正确的态度应该是就事论事,而不是因为用的工具不同互相diss\n\n#### Finally\n\n不过我也确实觉得有一些语言确实很有潜力, 但这不是说这些语言多好\n\n只是说他们可能更适合将来的一段时间的编程环境\n\n个人认为比较有潜力的语言:`Python`,`Go`\n\n但是之前我有一些朋友想学习编程,让我给他们推荐最适合入门的编程语言\n\n我一般建议按照两个维度给人推荐语言,一个是技能熟练度要求, 一个是语言本身所属的类型\n\n建议的熟练度级别/类型|编译型语言|脚本语言\n:-:|:-:|:-:|\n能看懂即可|汇编,C,C++|PHP|\n最好会用|Go|Python|\n最好熟悉|Java,Go|Python,Javascript|\n值得深入研究|C++,Java|Python,Javascript\n兴趣爱好者|Clojure/Rust|Javascript|\n\n\n------------------------------\n\n18年11月更新\n\n最近查看tiobe的编程语言排行榜(如下), 发现了一些趋势\n\n![11月编程语言排行榜](20181108-11394.png)\n\n1. Python流行程度猛增\n\n2. C / Java / C++  都有比较显著的增长\n\n3. 脚本语言大部分普遍下降\n\n结合这段时间各种语言的更新情况, 总结出来这么个趋势\n\n## php, js 等语言都在加入类型特性\n\n现在的互联网服务体量越来越大, 以前的php和python的快速开发在早期的互联网时代确实很有优势, 但是现在随着互联网服务的逐渐完善, 之前在开发效率方面有优势的语言渐渐地就有点弱势了\n\n原因有以下几点:\n\n- 需求减少\n\n快速开发主要服务于大量的初创公司和项目原型,随着互联网进程的发展, 会有大量的服务逐渐被废弃掉   \n\n存活下来的老服务日积月累下来越来越复杂, 之前快速开发产生的弊端越来越明显, 此时大部分都选择了其他静态语言进行重构   \n\n现在已经过了互联网蓬勃的爆发期, 对快速开发的需求也有一定程度的下降(现在由于小程序的兴起需求又有回升)   \n\n- 适用范围的缩小和新型语言的竞争\n\n前端的工程化现在进度很快, 脚本语言以前的很多优势在前端的快速发展面前变得很鸡肋   \n\n脚本语言以前最大的优势就是开发跟用户交互的界面部分比较快速,同时还能操作后台的数据库级别的数据, 一个人可以同时做两份工作   \n\n但是现在随着社会分工的细化,有更专业的前端工程师来做跟用户交互的事情,而且做得更好, 脚本语言做数据处理等后端部分又完全不是传统静态语言的对手, 导致脚本语言现在处境很尴尬\n\n新型的Go等语言的出现, 做到了开发速度和执行效率之间的平衡, 也抢夺了脚本语言的市场空间\n\n所以现在的脚本语言都在不断进化, 减少动态特性, 增加稳定性, 提升执行效率, 语言新特性越来越往适合数据处理方面靠拢\n\n## Java等语言和新出的语言都在增加函数式编程的特性\n\n随着web服务的逐步发展, 终有一天会达到前端和后端彻底分离的地步, 到那个时候就是前后端完全通过数据进行交互, 前端负责与用户的交互和收集数据, 后端负责数据的存储和计算.   \n\n但是传统的Java/C 等语言在处理数据方面, 其实不如函数式编程的语言方便\n\n所以Java也是意识到这个趋势, 逐渐加入函数式编程特性\n\n新型的rust, julia等编程语言也都在重视性能的同时添加了函数式编程的特性   \n\n## 底层语言重新崛起\n\n最近几年 c/c++/rust等系统编程语言渐渐有重新崛起的趋势\n\n我觉得原因是因为云计算,大数据和机器学习的需要, 因为这几个领域都是对性能要求较高的领域, 之前适合短平快的语言在这种场景下大部分都难以满足现在巨大的数据处理需求\n\nPython之所以现在还能有大的发展一方面是因为python 语言上手简单, 不断发展\n\n我觉得最核心的原因还是因为python 作为一个胶水语言可以很方便的作为c /c++ 这种语言之间的桥梁\n\n用户既能享受python的简单交互的特性, 高性能部分又可以调用底层的c/c++等库来执行, 达到开发和执行效率的平衡\n\n## 一些建议\n\n建议编程初学者最好学习两个语言, 一个编译型一个脚本型\n\n初学者建议  go/java + python / js 这样的搭配\n\n我个人大概是这样的学习路线:\n\n学校时期: C++, Java , PHP, JS, 都是学校时期学的, 当时就懂了个基本概念, 啥都没学会     \n刚工作时: C/C++, JS/node, PHP 早期工作需要     \n工作一段时间:  Python, Go, Java 后来扩展了部分语言希望多看看, 找到自己真正喜欢的语言     \n未来:  Scala, Rust, Clojure   现在希望能多投资Rust, 并且了解一下Clojure     \n\n","categories":["思考"],"tags":["编程语言"]},{"title":"音乐推荐--霹雳音乐集锦","url":"/2016-06-07-pili-music/","content":"\n# 布袋戏中有很多音乐不错\n\n以下挑选几首比较能表现角色的曲子\n\n## 剑者传说\n\n人物:殢(ti)无伤\n\nQQ音乐链接: \n\n[https://y.qq.com/n/yqq/song/000sKibz2FzuW4.html](https://y.qq.com/n/yqq/song/000sKibz2FzuW4.html)\n\n\n>这首音乐是殢无伤的角色配乐,我非常喜欢, 从音乐中感受到一种清静, 自由, 感觉殢无伤的生活很惬意\n\n## 荒人邪影\n\n人物:一剑封禅(shan)\n\nQQ音乐链接:\n\n[https://y.qq.com/n/yqq/song/001EBctt13gzYk.html](https://y.qq.com/n/yqq/song/001EBctt13gzYk.html)\n\n\n荒人邪影之封印记忆\n\n人物:吞佛童子\n\nQQ音乐链接:\n\n[https://y.qq.com/n/yqq/song/000mG2qu0mEOq9.html](https://y.qq.com/n/yqq/song/000mG2qu0mEOq9.html)\n\n\n>两首曲子乐器不同,第一首管乐给人感觉诡异中透漏着一丝丝的正气, 仿佛内心与外表截然不同, 虽然乍听感觉有一股邪气,但是仔细听又会发觉其实内里很正派\n>第二首曲子则不同,换成弦乐之后音调就比较真正的诡谲了,传达的气氛也变得更邪恶了,暗示人物已经被邪气蒙蔽,仔细分析虽然依然能察觉一丝正气, 但是已经很微弱了\n\n## 赮毕钵罗\n\n人物:赮(xia)毕钵(bo)罗\n\nQQ音乐链接:\n\n[https://y.qq.com/n/yqq/song/000AfNL23UeMmU.html](https://y.qq.com/n/yqq/song/000AfNL23UeMmU.html)\n\n\n>开头的马头琴声给人的感觉还是比较空旷,隐隐透漏一股禅意,配合后面的琴声,禅意更浓,不禁让人回想起赮毕钵罗刚出场时候\n\n## 羽獍弦歌\n\n人物:羽人非獍(jing)\n\n网易云链接:\n\n[https://music.163.com/#/song?id=375530](https://music.163.com/#/song?id=375530)\n\n>二胡本就适合悲曲,曲子本身的曲调也偏向悲怆,再回想起羽人非獍的经历真的是让人心中不免悲伤不已\n\n## 夜雨寄北\n\n人物:御不凡\n\n网易云链接:\n\n[https://music.163.com/#/song?id=373525](https://music.163.com/#/song?id=373525)\n\n>这个曲子本不悲伤,但是回想起御不凡此人的经历,就不免心痛了\n","categories":["收藏记录"],"tags":["音乐推荐"]},{"title":"The First Three.js Project","url":"/2016-06-01-threejs-demo/","content":"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r70/three.min.js\" ></script>\n\n# `Three.js`简单演示\n\n`Three.js`是基于`WebGl`封装的一个现成库,更新速度非常快,这里简单列出一些three.js的简单例子和演示\n\n## 准备\n\n要使用`three.js`首先要引入库文件\n首先,到[http://threejs.org/](http://threejs.org/)下载`three.js`类库\n也可以使用cdn服务,例如[http://cdn.bootcss.com/three.js/r83/three.js](http://cdn.bootcss.com/three.js/)\n\n然后这里讲解一下`Three.js`主要用到的知识(这些也是所有3D绘图要用到的基础知识)\n\n## 基础\n\n- **场景**\n  场景就是你要绘制的图形所放置的容器,是所有几何体发生交互和展示的所在,几何体对象必须放到场景中才可以显现出来\n\n- **渲染器**\n  渲染器可以把你所绘制的图形通过像素画出来,比如颜色,材质,纹理,反射效果啥的\n\n- **照相机**\n  相当于人的眼睛,就是你所观看的视角的方向\n\n以下部分可以酌情使用:\n\n- **光源**\n    光源是`WebGL`中必须的部分,如果没有光源,即便渲染出了东西,也是没有办法在屏幕上看到的(没有光当然就是黑漆漆的一片啦)\n    光源还分好多种,常用的有环境光,聚光灯,和点光源等\n\n- **几何体**\n    几何体是我们平常生活中最容易遇到的东西,`WebGL`中提供了几种常用的几何体类\n    每种几何体使用的时候都是这么几个步骤\n\n    1. 实例化类对象\n    2. 设置材质\n    3. 用栅格把几何体对象和材质编织起来,得到3D对象\n    4. 设置3D对象的属性(位置,阴影之类)\n\n    一个复杂的物体可以拆分成几个简单的几何体\n\n## 透视和投影\n\n透视和投影是3D图形中非常重要和基础的概念\n\n这里主要跟`three.js`中的照相机类有关系,照相机代表模拟人眼的观察方向\n\n透视在`three.js`中只有是用线框模型才能很好的表现\n\n投影主要分为正交投影和透视投影\n\n### 正交投影\n\n![](28210109_oXpx.jpg)\n\n正交投影一般用于平面制图,建模,游戏中的小地图也使用正交投影,正交投影不会改变物体的比例\n\n正交投影相机函数如下\n\n`THREE.OrthographicCamera(left, right, top, bottom, near, far)`\n\n传入`视景体`的(左,右,上,下,前边界,后边界),即可完成一个正交投影相机的设定\n\n* example\n\n设置照相机,照相机位置为(0,0,5)\n\n```javascript\nvar camera = new THREE.OrthographicCamera(-2, 2, 1.5, -1.5, 1, 10);\ncamera.position.set(0, 0, 5);\nscene.add(camera);\n```\n在原点处创建一个边长为1的正方体，为了和透视效果做对比，这里我们使用`wireframe(线框模型)`而不是实心的材质，以便看到正方体后方的边：\n\n```javascript\nvar cube = new THREE.Mesh(new THREE.BoxGeometry(1, 1, 1),\n    new THREE.MeshBasicMaterial({\n        color: 0xff0000,\n        wireframe: true\n    })\n);\n```\n效果如下:\n\n<div id=\"Orthographic1\" style=\"margin:0;text-align: center;\"></div>\n\n但是由于角度问题,我们现在只能看到正方体的正面,现在我们调整相机位置\n\n`camera.position.set(4, -3, 5);`\n\n调整视角方向(看向原点),这样我们就能看到整个正方体的线框了\n\n`camera.lookAt(new THREE.Vector3(0, 0, 0));`\n\n<div id=\"Orthographic2\" style=\"margin:0;text-align: center;\"></div>\n\n<script>\nOrthographic1();\nOrthographic2();\nfunction Orthographic2(){\n    // renderer\n    var renderer = new THREE.WebGLRenderer();\n    renderer.setSize(600,400);\n    document.getElementById(\"Orthographic2\").appendChild(renderer.domElement);\n    renderer.setClearColor(new THREE.Color(0X000000,0.5)); // black\n\n    // scene\n    var scene = new THREE.Scene();\n\n    //camara\n    var camera = new THREE.OrthographicCamera(-2, 2, 1.5, -1.5, 1, 10);\n    camera.position.set(4, -3, 5);\n    camera.lookAt(new THREE.Vector3(0, 0, 0));\n    scene.add(camera);\n    //cube\n    var cube = new THREE.Mesh(new THREE.BoxGeometry(1, 1, 1),\n        new THREE.MeshBasicMaterial({\n            color: 0xff0000,\n            wireframe: true\n        })\n    );\n    scene.add(cube);\n    // render\n    renderer.render(scene, camera)\n}\n\nfunction Orthographic1(){\n    // renderer\n    var renderer = new THREE.WebGLRenderer();\n    renderer.setSize(600,400);\n    document.getElementById(\"Orthographic1\").appendChild(renderer.domElement);\n    renderer.setClearColor(new THREE.Color(0X000000,0.5)); // black\n\n    // scene\n    var scene = new THREE.Scene();\n\n    //camara\n    var camera = new THREE.OrthographicCamera(-2, 2, 1.5, -1.5, 1, 10);\n    camera.position.set(0,0,5);\n    // camera.lookAt(new THREE.Vector3(0, 0, 0));\n    scene.add(camera);\n    //cube\n    var cube = new THREE.Mesh(new THREE.BoxGeometry(1, 1, 1),\n        new THREE.MeshBasicMaterial({\n            color: 0xff0000,\n            wireframe: true\n        })\n    );\n    scene.add(cube);\n    // render\n    renderer.render(scene, camera)\n}\n\n</script>\n\n### 透视投影\n\n![透视](28210109_n5sg.jpg)\n\n透视投影类似人眼看到的效果,大多数游戏,应用等都使用透视投影,透视投影会使看到的物体产生形变,产生\"远小近大\"的效果\n\n透视投影相机函数如下\n\n`THREE.PerspectiveCamera(fov, aspect, near, far)`\n\n透视相机需要传入(俯仰角,画面比,近边界,远边界)来完成透视相机的参数设置\n\n* example\n\n设置透视投影照相机，这里Canvas长600px，宽400px，所以aspect设为600 / 400：\n\n```javascript\nvar camera = new THREE.PerspectiveCamera(45, 600 / 400, 1, 10);\ncamera.position.set(0, 0, 5);\nscene.add(camera);\n```\n\n设置一个在原点处的边长为1的正方体:\n\n```javascript\nvar cube = new THREE.Mesh(new THREE.BoxGeometry(1, 1, 1),\n    new THREE.MeshBasicMaterial({\n        color: 0xff0000,\n        wireframe: true\n    })\n);\nscene.add(cube);\n```\n\n效果如下:\n\n<div id=\"Perspective\" style=\"margin:0;text-align: center;\"></div>\n\n<script>\nPerspective();\nfunction Perspective() {\n    var renderer = new THREE.WebGLRenderer();\n    renderer.setSize(600,400);\n    document.getElementById(\"Perspective\").appendChild(renderer.domElement);\n    renderer.setClearColor(new THREE.Color(0X000000,0.5)); // black\n    // scene\n    var scene = new THREE.Scene();\n    //camara\n    var camera = new THREE.PerspectiveCamera(45, 600 / 400, 1, 10);\n    camera.position.set(0, 0, 5);\n    scene.add(camera);\n    //cube\n    var cube = new THREE.Mesh(new THREE.BoxGeometry(1, 1, 1),\n        new THREE.MeshBasicMaterial({\n            color: 0xff0000,\n            wireframe: true\n        })\n    );\n    scene.add(cube);\n    // render\n    renderer.render(scene, camera)\n}\n</script>\n\n## 材质\n\n材质有大量共有属性,这些属性可以设置材质的纹理,颜色,雾化等许多效果,这里挑选几种常用材质进行简单说明\n\n### 基础材质\n\n基础材质不受灯光影响,多用于实现简单展示\n\n构造函数:`THREE.MeshBasicMaterial( parameters )`\n\n### Phong材质\n\nPhong材质= 环境光 + 漫反射 + 镜面反射\n\n该材质具有极高的真实感,可产生高光效果,可以模拟金属等物体\n\n构造函数:`THREE.MeshPhongMaterial( parameters )`\n\n### lambert材质\n\nlambert材质可以模拟一些无需高光反射的哑光效果,例如:皮纹\n\n构造函数:`THREE.MeshLambertMaterial( parameters )`\n\n### 法向量材质\n\n根据表面法向量方向产生不同颜色,多用于调试\n\n构造函数:`THREE.MeshNormalMaterial( parameters )`\n\n## 光源\n\n光源可谓是3D绘图中极其重要的部分,光源分为很多种,除了环境光,点光源这几种常见的之外,还有面光源等特殊光源\n\n所有光源都具有一部分共同属性,在`three.js`中这些属性为缺省值,不填则会有默认值,例如:color\n\n### 环境光\n\n环境光是模拟自然环境中无处不在的被多次反射的光线,环境光的特点\n\n* 无法产生阴影\n* 从四周所有方向照射\n\n环境光构造函数  `THREE.AmbientLight(hex)`\n\nhex:十六进制的颜色值,例如:0xff0000\n\n添加一个环境光源\n\n```javascript\nvar light = new THREE.AmbientLight({0xffffff});\nscene.add(light);\n```\n\n但是只添加环境光而没有物体是无法看出来效果的\n所以再添加两个长方体\n\n```javascript\nvar greenCube = new THREE.Mesh(new THREE.BoxGeometry(2, 2, 2),\n    new THREE.MeshLambertMaterial({color: 0x00ff00}));\ngreenCube.position.x = 3;\nscene.add(greenCube);\n\nvar whiteCube = new THREE.Mesh(new THREE.BoxGeometry(2, 2, 2),\n    new THREE.MeshLambertMaterial({color: 0xffffff}));\nwhiteCube.position.x = -3;\nscene.add(whiteCube);\n```\n\n<div id=\"Ambient\" style=\"margin:0;text-align: center;\"></div>\n\n<script>\nAmbient();\nfunction Ambient() {\n    var renderer = new THREE.WebGLRenderer();\n    var width = 600;\n    var height = 400;\n    document.getElementById(\"Ambient\").appendChild(renderer.domElement);\n    renderer.setClearColor(new THREE.Color(0x000000,0.5));\n    renderer.setSize(width,height);\n    // scene\n    var scene = new THREE.Scene();\n    //camara\n    var camera = new THREE.PerspectiveCamera(45, width / height, 1, 10);\n    camera.position.set(0, 3, 10);\n    camera.lookAt(new THREE.Vector3(0,0,0));\n    scene.add(camera);\n    var light = new THREE.AmbientLight( 0x880000); // soft white light\n    scene.add(light);\n    //cube\n    var greenCube = new THREE.Mesh(new THREE.BoxGeometry(2, 2, 2),\n        new THREE.MeshLambertMaterial({color: 0x00ff00}));\n    greenCube.position.x = 2;\n    scene.add(greenCube);\n\n    var whiteCube = new THREE.Mesh(new THREE.BoxGeometry(2, 2, 2),\n            new THREE.MeshLambertMaterial({color: 0xff0000}));\n    whiteCube.position.x = -2;\n    scene.add(whiteCube);\n    // render\n    renderer.render(scene, camera)\n}\n</script>\n\n### 仿射变换\n\n仿射变换是指计算机图形学中表示物体运动和变化的一系列动作\n\n主要有 平移,旋转,缩放和切变\n\n图形学中一般使用一个四维矩阵来表示仿射变换\n\n具体如下:\n\n    [ 缩放/旋转矩阵(3x3矩阵),0]\n    [ 平移矩阵,1]\n\n原因:\n\n    [2,3]\n    [4,5] \n\n这样的一个矩阵我们可以看成是两个二元方程组, 在图形上表示一个二维平面图形\n\n同样的表示三维平面图形我们用三元方程组\n\n表示为矩阵就是\n\n    [2,5,6]\n    [6,2,1]\n    [-1,3,4]\n\n对三维图形做变换其实就是对矩阵进行操作\n\n### 聚光灯\n\n聚光灯模拟的是舞台上的聚光灯,手电筒等光源效果,特点有\n\n* 可以产生阴影\n* 从一点沿某一方向射出,具有明显边界,影响范围一般呈锥体形状\n\n聚光灯构造函数\n\n`THREE.SpotLight(hex, intensity, distance, angle, penumbra,decay)`\n\nhex: 十六进制颜色值\nindensity: 光强度\ndistance: 光照有效距离\nangle: 角度\npenumbra: 半影\ndecay: 衰减度\n\n### 点光源\n\n点光源模拟的类似于生活中的灯泡,蜡烛等由一点  \n\n点光源构造函数:\n`THREE.PointLight(hex, intensity, distance)`\n\n例如:\n\n```javascript\nvar light = new THREE.PointLight(0xffffff, 2, 100);\nlight.position.set(0, 1.5, 2);\nscene.add(light);\n```\n\n<div id=\"PointLight\" style=\"margin:0;text-align: center;\"></div>\n\n<script>\nPointLight();\nfunction PointLight() {\n    var renderer = new THREE.WebGLRenderer();\n    var width = 600;\n    var height = 400;\n    document.getElementById(\"PointLight\").appendChild(renderer.domElement);\n    renderer.setClearColor(new THREE.Color(0x000000,0.5));\n    renderer.setSize(width,height);\n    // scene\n    var scene = new THREE.Scene();\n    //camara\n    var camera = new THREE.PerspectiveCamera(45, width / height, 1, 10);\n    camera.position.set(0, 5, 5);\n    camera.lookAt(new THREE.Vector3(0,0,0));\n    scene.add(camera);\n\n    var light = new THREE.PointLight(0xffffff, 2, 100);\n    light.position.set(0, 1.5, 2);\n    scene.add(light);\n\n    //cube\n    var greenCube = new THREE.Mesh(new THREE.BoxGeometry(2, 2, 2),\n        new THREE.MeshLambertMaterial({color: 0x00ff00}));\n    greenCube.position.x = 2;\n    scene.add(greenCube);\n\n    var whiteCube = new THREE.Mesh(new THREE.BoxGeometry(2, 2, 2),\n            new THREE.MeshLambertMaterial({color: 0xff0000}));\n    whiteCube.position.x = -2;\n    scene.add(whiteCube);\n    // render\n    renderer.render(scene, camera)\n}\n</script>\n\n\n### 平行光\n\n一般距离极远的点光源表现为平行光,例如:太阳\n\n平行光可以产生阴影\n\n`THREE.DirectionalLight(hex, intensity)`\n\n```javascript\nvar light = new THREE.DirectionalLight();\nlight.position.set(2, 5, 3);\nscene.add(light);\n```\n\n## 在线演示\n\n好啦,了解以上知识,再稍微熟悉一下基础`three.js`类就能做一个简单的东西了\n比如:\n\n```javascript\n\nvar scene = new THREE.Scene();\nvar width = 700;\nvar height = 330;\nvar camera = new THREE.PerspectiveCamera(45,width/height,0.1,1000);\nvar renderer = new THREE.WebGLRenderer();\nrenderer.setClearColor(new THREE.Color(0x000000,0.5));\nrenderer.setSize(width, height);\ncamera.position.set(-30,50,50);\ncamera.lookAt(new THREE.Vector3(10,10,10));\ndocument.getElementById(\"scene\").appendChild(renderer.domElement);\nvar groundGeom = new THREE.PlaneGeometry(100,100);\nvar groundMesh = new THREE.Mesh(groundGeom,new THREE.MeshBasicMaterial({color:0xffee00}));\ngroundMesh.rotation.x = -Math.PI/2-0.08;\nscene.add(groundMesh);\nvar geomCube = new THREE.BoxGeometry(16,32,16);\nvar cube = new THREE.Mesh(geomCube,new THREE.MeshNormalMaterial({color:0x7777ff}));\nscene.add(cube);\nvar ambientLight = new THREE.AmbientLight({color:0xff0000});\nscene.add(ambientLight);\nscene.fog = new THREE.Fog(0x0000ff,0.03,100);\nvar spotLight = new THREE.SpotLight(0x00ff00);\nspotLight.position.set(40,20,10);\nspotLight.castShadow = true;\nscene.add(spotLight);\nrender();\nfunction render(){\n    cube.rotation.y += 0.01;\n    requestAnimationFrame(render);\n    renderer.render(scene,camera);\n}\n\n```\n测试区域(代码复制到下边文本框运行即可):\n<textarea id=\"test\" style=\"width:600px;height:400px; border:1px solid #ccc;border-radius:5px;\"></textarea>\n\n<button class=\"btn btn-info\" onclick=\"eval(document.getElementById('test').value)\">运行测试代码</button>\n<div id=\"scene\" style=\"margin:0;text-align: center;\">\n</div>\n\n## So Sad\n\n由于Three.js更新太快了,所以我打算暂时不更新了,等版本稳定再继续更新...\n","categories":["编程学习"],"tags":["three.js"]},{"title":"菊与刀","url":"/2016-05-12-The-Chrysanthemum-and-the-Sword/","content":"# 记\n\n看<<菊与刀>>的时候,我总有一种感觉, 书中所谓的对美国人来说日本人一些不能理解的地方,到底哪里不能理解了,难道不应该是这样的吗?\n\n1. 崇尚等级与秩序,不同等级享受不同的权利,承担对应的义务\n2. 崇尚统一与纯粹,排斥多元化的世界和文化\n3. 有恩报恩,有仇报仇\n4. 忠,孝为先\n5. 自己怎么样受苦都行,但是不应该给别人添麻烦\n6. 自尊,自立,自强\n7. 相信丛林法则,弱肉强食\n\n## 念\n\n后来,再度回想起来,应该是我被日本文化影响太深了,所以没有发觉其中的不合理之处\n\n但是,究竟是从什么时候开始的呢,从什么时候开始受到这种影响的呢?\n\n## 思\n\n仔细分析,感觉应该是从小学就开始了\n\n小学时期,与家里联系还算紧密,但是当时受动漫影响,已经开始受到日本文化影响了,只是当时这种影响还没有显现出来\n\n1. 初中以后,与家里缺少联系和沟通,学习和受教育途径主要通过学校,社会和网络\n\n2. 本人比较聪明,接受新东西比较快,小的时候就能敏感的感受到日本动漫和电影电视所传达的价值观\n\n3. 受传统思想影响,比较排斥美国那种文化,所以初中以后接触的国外的文化作品,以日本的居多\n\n以上几点可能就是我形成现在这种性格和价值观的原因,但是,现在问题是要怎么改呢?\n\n多看书?多分析?\n\n## 为\n\n1. 多读书, 尝试接受多元的文化和观念\n2. 多做,多体验,多想,多比较\n\n## の\n\n现在发现这个世界的本质就是`混乱`,`无序`. 强行去求得统一和规范很多时候是一种偏执\n\n偏执太过就入魔了\n\n世事本就如此,有些人坚持就被认为是偏执,有些人坚持就认为是有毅力,这种两面解释我接受","categories":["收藏记录"]},{"title":"如何计算圆周率和自然对数e","url":"/2016-03-03-calculate-pi/","content":"<script crossorigin=\"anonymous\" integrity=\"sha384-P75AfVrDnfsoUfx7dDfQM9ivlDhxgE+g4kqO/U7lyXtJwJdpZozbt8L5ywD2PDA0\" src=\"https://lib.baomitu.com/vue/2.5.21/vue.min.js\"></script>\n\n# 如何计算Pi和E的值\n\n从小学就知道 `pi= 3.14159265358979...`\n\n但是一直不知道如何计算这个值\n\n之前听说过祖冲之使用的是割圆法，但是我不会(T_T，流下了没有技术的泪水)\n\n后来偶尔看到数学上有一种方法\n\n`pi= 4 * (1 - 1/3 + 1/5 -1/7 + 1/9...+1/n)`\n\n使用这种方法只要n足够大, 精度就能提高, 所以我就想用程序来尝试计算一下pi的值, 毕竟计算机比人做这种事情合适的多\n\n# 如何计算自然对数\n\n自然对数也一直是我不理解的一个数字\n\n之前听说过一个类比,讲的挺好的,但当时并没有去仔细考虑过计算的方法[数学常数e的含义](http://www.ruanyifeng.com/blog/2011/07/mathematical_constant_e.html)\n\n## 自然对数的意义\n\n> 自然对数代表单位时间内,数量翻倍增长的极限\n\n比如: 你有1万块钱, 假如存到银行, 1年到期的复利是100%, 那你到明年最多可以拿到多少钱 , 答案是: 2.71828万\n\n这里我们看如何计息:\n\n如果按照每半年计息, 1年后等于 (1 + (100%/2)) * (1 + (100%/2)) = 2.25 万\n\n如果按照每3个月计息一次: 1 + (100%/4) ^ 4 = 2.4414万\n\n如果按照每1个月计算一次 1 + (100%/12) ^12 = 2.6034 万\n\n如果再往下, 每天, 每分钟, 每秒, 最终得到的就是 lim (1+100%/n)^n 的极限就是 2.71828...\n\n## 如何计算e\n\n后来也找到一种数学方法可以计算\n\n`e = 1/(0!)+1/(1!)+1/(2!)+1/(3!)+1/(4!)....1/(n!)`\n\n于是一时好奇就使用程序实现了一下,如下:\n\n```python\n\nimport math\n\nclass Calculator:\n\n    num = 10000000\n    a = 1\n    res = 0\n\n    def getPi(self):\n        for n in range(1, self.num):\n            m = 1 / (1 + 2 * n)\n            if n % 2 == 0:\n                self.a = self.a + m\n            else:\n                self.a = self.a - m\n        print(self.a * 4)\n\n    def getE(self):\n        for n in range(0, self.num):\n            self.res = self.res + 1 / math.factorial(n)\n        print(self.res)\n\n\nc = Calculator()\nc.getPi()\nc.getE()\n\n```\n\n## 在线演示\n\n在线测试demo(js版)\n\n1. 计算pi\n\n<div id=\"cal-pi\">\n    <p>精度:<input v-model=\"input\" type =\"number\" value=\"\"></p><button class=\"btn btn-info\"  v-on:click=\"calculate\">Calculate</button>\n    <p>结果: <input v-model=\"result\" readonly=\"true\"> </p>\n</div>\n\n2. 计算E\n\n<div id=\"cal-e\">\n    <p>精度:<input type=\"number\" v-model=\"input\" value=\"\"></p><button class=\"btn btn-info\"  v-on:click=\"calculate\">Calculate</button>\n    <p>结果: <input v-model=\"result\" readonly=\"true\"> </p>   \n</div>\n\n3. 计算你当前的年龄, 精确值, 让你清晰感受时间的流逝\n\n<div id=\"cal-age\">\n    <p>生日:<input type=\"text\" v-model=\"input\" value=\"\" placeholder=\"2017-01-01\"></p><button class=\"btn btn-info\" v-on:click=\"calculate\">Calculate</button>\n    <p>结果: <input v-model=\"result\" readonly=\"true\"> </p>\n</div>\n\n<script>\nvar arr = [{\n    el:\"#cal-e\",\n    data:{\n        result:0,\n        input:100,\n        msg:\"请输入一个精度值\"\n    },\n    methods:{\n        calculate:function(){\n            if (!this.input) {\n                alert(this.msg);\n            }\n            var n = this.input;\n            var s = 0;\n            for (var i = 0; i <= n; i++) {\n                s = s + (1 / this.factorial(i));\n            }\n            this.result = s;\n        },\n        factorial: function(n) {\n            if (n <= 1) return 1;\n            return n * this.factorial(n - 1);\n        }\n    }\n},{\n    el:\"#cal-age\",\n    data:{\n        result:0,\n        input:'2000-01-01',\n        msg:\"请输入一个出生日期\",\n        n:0\n    },\n    methods:{\n        calculate:function(){\n            if (!this.input) {\n                alert(this.msg);\n            }\n            this.n = 0;\n            this.interval = setInterval(this.setAge,100);\n        },\n        setAge:function (){\n            this.n += 1;\n            var b = this.input;\n            var now = new Date().valueOf();\n            var born = new Date(b).valueOf();\n            var age = (now - born) / (365 * 24 * 3600 * 1000);\n            this.result = age;\n            this.stop()\n        },\n        stop:function() {\n            if (this.n > 50) clearInterval(this.interval)\n        }\n    }\n},{\n    el:\"#cal-pi\",\n    data:{\n        result:0,\n        input:100,\n        msg:\"请输入一个精度值\"\n    },\n    methods:{\n        calculate:function(){\n            if (!this.input) {\n                alert(this.msg);\n            }\n            var n = this.input * 100;\n            var s = 1;\n            for (var i = 1; i <= n; i++) {\n                var m = 1 / (1 + 2 * i);\n                if (i % 2 == 0) {\n                    s += m;\n                } else {\n                    s -= m;\n                }\n            }\n            this.result = s * 4;\n        }\n    }\n}];\n\nfor (e in arr) {\n    new Vue(arr[e]);\n}\n\n</script>\n","categories":["数学"],"tags":["math"]},{"title":"Python的GUI小测试","url":"/2016-01-09-python-gui/","content":"# Python的GUI编程\n\n今天用python的tkinter做了一个小的天气查询工具\n\n目的仅仅是为了了解一下python的GUI编程而已\n\n用过以后发现真的不是很好用(主要是界面太丑)\n\n代码如下(python3.x):\n\n```python\n\nfrom tkinter import *\nimport sys, urllib.request, json,tkinter.messagebox\n\ndef alert(item,con):\n        tkinter.messagebox.showinfo(item,con)\ndef putIn(arr):\n        res = arr[\"HeWeather data service 3.0\"][0]\n        addLabel(\"城市:\"+res[\"basic\"][\"city\"])\n        addLabel(\"温度:\"+res[\"now\"][\"fl\"])\n        addLabel(\"风力:\"+res[\"now\"][\"wind\"][\"sc\"])\n        addLabel(\"空气质量:\"+res[\"aqi\"][\"city\"][\"aqi\"])\n#获取天气\ndef getWeather(city):\n        url = 'http://apis.baidu.com/heweather/weather/free?city='+city\n        req = urllib.request.Request(url)\n        req.add_header(\"apikey\", \"*********\")\n        content = urllib.request.urlopen(req).read()\n        con_str = str(content,\"utf-8\")\n        if(content):\n            result = json.loads(con_str)\n            aqi = result[\"HeWeather data service 3.0\"][0][\"aqi\"][\"city\"][\"aqi\"]\n            putIn(result)\n            alert(\"aqi\",aqi)\n        else:\n            result = \"\"\n            alert(\"error\",\"没有获得城市天气数据\")\n\ndef addLabel(name):\n        i = StringVar()\n        i.set(name)\n        lab1 = Label(root,textvariable=i)\n        lab1.pack(side=BOTTOM)\n\ndef deal():\n        u_name = username.get()\n        getWeather(u_name)\n\nroot = Tk()\nroot.geometry('300x200')\n\nusername = StringVar()\npassword = StringVar()\n\ndiv = Frame(root)\ndiv.pack()\n\ndiv1 = Frame(div,width=500)\ndiv1.pack()\n\nUname = Label(div1,text=\"城市:\")\nUname.pack(side=LEFT)\n\nentUname = Entry(div1,textvariable=username)\nentUname.pack(side=RIGHT)\n\nbtn = Button(div,text=\"提交\",command=deal)\nbtn.pack(side=BOTTOM)\nroot.mainloop()\n\n```\n\n期待以后python的GUI变得成熟的日子","categories":["编程学习"],"tags":["Python"]},{"title":"Caman.js的图片处理演示","url":"/2016-08-03-camanjs-demo/","content":"<script src=\"http://libs.baidu.com/jquery/2.0.0/jquery.min.js\"></script>\n<script crossorigin=\"anonymous\" integrity=\"sha384-P75AfVrDnfsoUfx7dDfQM9ivlDhxgE+g4kqO/U7lyXtJwJdpZozbt8L5ywD2PDA0\" src=\"https://lib.baomitu.com/vue/2.5.21/vue.min.js\"></script>\n<script src=\"https://cdn.bootcss.com/camanjs/4.1.2/caman.full.min.js\"></script>\n\n# CamanJS图形处理库\n\n之前我曾想过自己做一个简单的图片处理库自己用,后来做了几个基本效果以后发现了成本太高\n\n然后就放弃了,去找了个现成的图形库:CamanJS\n\n发现用起来也不错,也就没有再做下去\n\n## 简介\n\n[CamanJS](http://camanjs.com/)是一个图片处理类库,能十分方便的处理图片\n\n本身已经提供了许多效果和操作\n\n使用起来也十分方便\n\n项目地址：https://github.com/meltingice/CamanJS/\n\n## 简单使用\n\n在头文件中引入文件[//cdn.bootcss.com/camanjs/4.1.2/caman.full.min.js](//cdn.bootcss.com/camanjs/4.1.2/caman.full.min.js)\n\n然后就可以直接使用内置的函数和效果了\n\n例如：\n\n```javascript\n\nCaman(\"#image\",function(){\n    this.stackBlur(5).render()  //模糊处理，模糊半径5像素\n})\n\n```\n\n## 测试工具\n\n<button class=\"btn btn-info\" id=\"reset\">RESET</button>(尽量使用chrome浏览器,请等待网页加载完毕)\n<div>\n    <div id=\"stage\">\n        <img id=\"image\" src=\"20160803_21.png?v=10086\" style=\"float: auto\">\n    </div>\n</div>\n    \n# 预置效果\n\n`Caman`内置了一批现成的图片效果，使用起来非常简单\n`this.revert()`用来重置图片效果,保证各个效果不互相影响\n`this.lomo()`将lomo效果用到图片上\n`this.render()`渲染图片\n```javascript\nCaman(\"#image\",function(){\n    this.revert();\n    this.lomo();\n    this.render();\n    })\n```\n执行`love`效果: <button class=\"btn btn-info\" onclick=\"javascript:love_render()\">RUN LOVE</button>\n\n其他预置效果还有\n\n`lomo`,`vintage`,`clarity`,`sinCity`,`sunrise`,`crossProcess`,`orangePeel`,`grungy`,`jarques`,\n`pinhole`,`oldBoot`,`glowingSun`,`hazyDays`,`herMajesty`,`nostalgia`,`hemingway`,`concentrate`\n等\n\n将以上方法替换文本框中的`lomo`,例如 `this.hazyDays();`,然后点 RUN 就行了\n\n## Camanjs缺点\n\n不适合用来做粒度极细的像素级操作,虽然提供了方法\n<script type=\"text/javascript\">\n    function love_render(){\n        Caman(\"#image\",function(){\n        this.revert();\n        this.love();\n        this.render();\n        })\n    }\n\n    function init() {\n        var list = [{\n            \"name\": \"brightness\",\n        }, {\n            \"name\": \"contrast\",\n        }, {\n            \"name\": \"vibrance\",\n        }, {\n            \"name\": \"saturation\",\n        }, {\n            \"name\": \"exposure\"\n        }, {\n            \"name\": \"hue\",\n            \"value\": 100\n        }, {\n            \"name\": \"clip\",\n            \"value\": 100\n        }, {\n            \"name\": \"sepia\",\n            \"value\": 100\n        }, {\n            \"name\": \"gamma\",\n            \"value\": 10\n        }, {\n            \"name\": \"noise\",\n            \"value\": 100\n        }, {\n            \"name\": \"sharpen\",\n            \"value\": 100\n        }, {\n            \"name\": \"stackBlur\",\n            \"value\": 30\n        }];\n        var table = document.createElement(\"table\");\n        for (var i = 0; i < list.length; i++) {\n            if (i % 2 == 0) {\n                var tr = document.createElement(\"tr\");\n                $(tr).attr(\"id\", \"tr\" + i);\n            }\n            var td1 = document.createElement(\"td\");\n            var td2 = document.createElement(\"td\");\n            var td3 = document.createElement(\"td\");\n            $(td1).attr(\"width\",\"15%\");\n            $(td2).attr(\"width\",\"20%\");\n            $(td3).attr(\"width\",\"5%\");\n\n            $(td1).append(list[i].name);\n            if (list[i].value > 0) {\n                $(td2).append(\"<input id=\" + list[i].name + \"_i value=0 type='range' min=0 max=\" + list[i].value + \" step=1 data-filter=\" + list[i].name + \">\")\n            } else {\n                $(td2).append(\"<input id=\" + list[i].name + \"_i value=0 type='range' min=-100 max=100 step=1 data-filter=\" + list[i].name + \">\");\n            }\n            $(td3).append(0);\n            $(tr).append(td1).append(td2).append(td3);\n            $(table).append(tr);\n        }\n        $(table).css(\"border\", \"1px solid #ccc\");\n\n        $(\"#stage\").append(table);\n    }\n    init();\n    $(\"input[type=range]\").change(function() {\n        var stackBlur_v = $(\"#stackBlur_i\").val();\n        var brightness_v = $(\"#brightness_i\").val();\n        var contrast_v = $(\"#contrast_i\").val();\n        var vibrance_v = $(\"#vibrance_i\").val();\n        var saturation_v = $(\"#saturation_i\").val();\n        var exposure_v = $(\"#exposure_i\").val()\n        var hue_v = $(\"#hue_i\").val()\n        var clip_v = $(\"#clip_i\").val()\n        var sepia_v = $(\"#sepia_i\").val()\n        var gamma_v = $(\"#gamma_i\").val()\n        var sharpen_v = $(\"#sharpen_i\").val()\n        var noise_v = $(\"#noise_i\").val()\n        $(this).parent().next().text($(this).val());\n\n        Caman(\"#image\", function() {\n            this.revert();\n            if (stackBlur_v > 0) this.stackBlur(stackBlur_v);\n            if (brightness_v > 0) this.brightness(brightness_v);\n            if (contrast_v > 0) this.contrast(contrast_v);\n            if (vibrance_v > 0) this.vibrance(vibrance_v);\n            if (saturation_v > 0) this.saturation(saturation_v);\n            if (exposure_v > 0) this.exposure(exposure_v);\n            if (hue_v > 0) this.hue(hue_v);\n            if (clip_v > 0) this.clip(clip_v);\n            if (sepia_v > 0) this.sepia(sepia_v);\n            if (gamma_v > 0) this.gamma(gamma_v);\n            if (sharpen_v > 0) this.sharpen(sharpen_v);\n            if (noise_v > 0) this.noise(noise_v);\n            this.render();\n        })\n\n        $(\"#reset\").click(function(){\n            Caman(\"#image\",function(){\n                this.revert();\n                this.render();\n            })\n        })\n    });\n</script>\n","categories":["工具使用"],"tags":["javascript","CamanJS","图像处理"]},{"title":"常用的设计模式总结","url":"/2015-12-30-design-pattern/","content":"# 适配器模式\n\n- **概念**\n\n将一个类的接口转换成客户希望的另外一个接口。Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作\n\n- **主要角色**\n\n**目标(Target)角色**：定义客户端使用的与特定领域相关的接口，这也就是我们所期待得到的\n\n**源(Adaptee)角色**：需要进行适配的接口\n\n**适配器(Adapter)角色**：对Adaptee的接口与Target接口进行适配；适配器是本模式的核心，适配器把源接口转换成目标接口，此角色为具体类\n\n- **适用性** \n\n1. 你想使用一个已经存在的类，而它的接口不符合你的需求\n2. 你想创建一个可以复用的类，该类可以与其他不相关的类或不可预见的类协同工作\n3. 你想使用一个已经存在的子类，但是不可能对每一个都进行子类化以匹配它们的接口。对象适配器可以适配它的父类接口（仅限于对象适配器）\n\n在实际应用中，适配器模式分为类适配器和对象适配器\n\n**类适配器**\n\n```php\n\n//目标角色\ninterface ITarget  \n{  \n    function operation1();  \n    function operation2();  \n}  \n//源角色  \ninterface IAdaptee  \n{  \n    function operation1();  \n}  \n  \nclass Adaptee implements IAdaptee  \n{  \n    public  function operation1()  \n    {  \n        echo \"原方法\";  \n    }  \n}  \n\n//适配器角色  \nclass Adapter extends Adaptee implements IAdaptee, ITarget  \n{  \n    public  function operation2()  \n    {  \n        echo \"适配方法\";  \n    }  \n}  \n  \nclass Client  \n{  \n    public  function test()  \n    {  \n        $adapter = new Adapter();  \n        $adapter->operation1();//原方法  \n        $adapter->operation2();//适配方法  \n    }  \n}\n\n```\n\n**对象适配器**\n\n```php\n//目标角色\ninterface ITarget  \n{  \n    function operation1();  \n    function operation2();  \n}  \n//源角色   \ninterface IAdaptee  \n{  \n    function operation1();  \n}  \n  \nclass Adaptee implements IAdaptee  \n{  \n    public  function operation1()  \n    {  \n        echo \"原方法\";  \n    }  \n}  \n//适配器角色  \nclass Adapter implements ITarget  \n{  \n    private $adaptee;  \n  \n    public function __construct($adaptee)  \n    {  \n        $this->adaptee = $adaptee;  \n    }  \n  \n    public  function operation1()  \n    {  \n         return $this->adaptee->operation1();  \n    }  \n  \n    public  function operation2()  \n    {  \n        echo \"适配方法\";  \n    }  \n    \n}  \n  \n  \nclass Client  \n{  \n    public  function test()  \n    {  \n        $adapter = new Adapter(new Adaptee(null));  \n        $adapter->operation1();//原方法  \n        $adapter->operation2();//适配方法  \n    }  \n}\n\n```\n\n>类适配器中适配器继承原有的Adaptee类，自己实现原类没有的操作，使用的是继承模式，而对象适配器使用的是组合模式，将adaptee作为adapter的一个引用。由于组合在耦合性上小于继承，对象适配器显得更加灵活但缺点是增加代码量。 需要重写adapee中的方法的数量太大的话，可以考虑在adapter类中添加`__call`方法委托adapee取得客户端调用的方法\n\n```php\n\npublic function __call($func, $args)  \n{  \n    if (is_callable(array($this->adaptee, $func))) {  \n        return $this->adaptee->$func($args);  \n    }  \n    trigger_error('*********', E_USER_ERROR);  \n}\n\n```\n\n\n# 装饰器模式\n\n- **装饰器模式概念**\n\n>在不必改变原类文件和使用继承的情况下，动态地扩展一个对象的功能，它是通过创建一个包装对象，也就是装饰来包裹真实的对象。\n\n- **装饰器模式特点**\n\n1. 装饰对象和真实对象有相同的接口。这样客户端对象就能以和真实对象相同的方式和装饰对象交互。\n2. 装饰对象包含一个真实对象的引用（reference）\n3. 装饰对象接受所有来自客户端的请求。它把这些请求转发给真实的对象。\n4. 装饰对象可以在转发这些请求以前或以后增加一些附加功能。这样就确保了在运行时，不用修改给定对象的结构就可以在外部增加附加的功能。在面向对象的设计中，通常是通过继承来实现对给定类的功能扩展。\n\n- **适用性**\n\n1. 需要扩展一个类的功能，或给一个类添加附加职责。\n2. 需要动态的给一个对象添加功能，这些功能可以再动态的撤销。\n3. 需要增加由一些基本功能的排列组合而产生的非常大量的功能，从而使继承关系变的不现实。\n4. 当不能采用生成子类的方法进行扩充时。一种情况是，可能有大量独立的扩展，为支持每一种组合将产生大量的子类，使得子类数目呈爆炸性增长。另一种情况可能是因为类定义被隐藏，或类定义不能用于生成子类。\n\n- **优点**\n\n1. Decorator模式与继承关系的目的都是要扩展对象的功能，但是Decorator可以提供比继承更多的灵活性。\n2. 通过使用不同的具体装饰类以及这些装饰类的排列组合，设计师可以创造出很多不同行为的组合。\n\n- **缺点**\n\n1. 这种比继承更加灵活机动的特性，也同时意味着更加多的复杂性。\n2. 装饰模式会导致设计中出现许多小类，如果过度使用，会使程序变得很复杂。\n3. 装饰模式是针对抽象组件（Component）类型编程。但是，如果你要针对具体组件编程时，就应该重新思考你的应用架构，以及装饰者是否合适。当然也可以改变Component接口，增加新的公开的行为，实现“半透明”的装饰者模式。在实际项目中要做出最佳选择。\n\n- **设计原则**\n\n1. 多用组合，少用继承。\n2. 类应设计的对扩展开放，对修改关闭。\n\n- **装饰器模式实例**\n\n```php\n\n//抽象接口类\ninterface IDecorator{\n  function sayMsg();\n}\n\n//具体装饰类1\nclass decorator1 implements IDecorator{\n  function sayMsg(){\n    echo \"增加功能1\";\n  }\n}\n//具体装饰类2\nclass decorator2 implements IDecorator{\n  function sayMsg(){\n    echo \"增加功能2\";\n  }\n}\n\nclass MailTest{\n    private $decorators;\n    function addDecorator(IDecorator $decorator){\n        $this->decorators[] = $decorator;\n    }\n\n    function addExtraFunction(){\n        foreach ($this->decorators as $decorator) {\n            $decorator->sayMsg();\n        }\n    }\n\n    function test(){\n        $this->addExtraFunction();\n        echo \"I am test\";\n    }\n}\n\n$mailTest = new MailTest();\n\n$decorator1 = new decorator1();\n$decorator2 = new decorator2();\n\n$mailTest->addDecorator($decorator1);\n$mailTest->addDecorator($decorator2);\n\n$mailTest->test();\n\n```\n\n# 工厂模式\n\n- **概念及特点**\n\n面向对象设计强调抽象类高于实现，也就是说我们要尽量一般化而不是特殊化，工厂模式解决了当代码关于抽象类型时如何创建对象实例的问题。\n\n工厂模式就是把创建对象的过程封装起来，这样随时可以产生一个新的对象，减少代码之间耦合。\n\n通俗的说，常规的创建一个对象要使用new，工厂模式就是把这个过程封装起来，使用一个工厂类来创建对象\n\n如果不使用工厂模式，那么很多地方调用类Database，代码就会这样子创建一个实例：new Database(),假设某天需要修改Database类的名称那么调用Database类的代码都要修改。\n\n- **工厂模式举例**\n\n假如已经有一个数据库类Database\n\n```php\n\nclass Factory{\n\n    static function createDatabase(){\n\t$db = new Database();\n\treturn $db;\n    }\n}\n\n```\n创建数据库类\n\n```php\n\n$db = Factory::createDatabase();\n\n```\n\n# 抽象工厂模式\n\n- **概念**\n\n>为创建一组相关或相互依赖的对象提供一个接口，而且无需指定他们的具体类\n\n\n- **特点**\n\n抽象工厂模式（Abstact Factory）是一种常见的软件设计模式，该模式为一个产品族提供了统一的创建接口。当需要这个产品族的某一系列的时候，可以为此系列的产品族创建一个具体的工厂类。\n\n- **主要角色**\n\n**抽象工厂(Abstract Factory)角色**：它声明一个创建抽象产品对象的接口。通常以接口或抽象类实现，所有的具体工厂类必须实现这个接口或继承这个类。\n\n**具体工厂(Concrete Factory)角色**：实现创建产品对象的操作。客户端直接调用这个角色创建产品的实例。这个角色包含有选择合适的产品对象的逻辑。通常使用具体类实现。\n\n**抽象产品(Abstract Product)角色**：声明一类产品的接口。它是工厂方法模式所创建的对象的父类，或它们共同拥有的接口。\n\n**具体产品(Concrete Product)角色**：实现抽象产品角色所定义的接口，定义一个将被相应的具体工厂创建的产品对象。其内部包含了应用程序的业务逻辑。\n\n- **优缺点**\n\n**抽象工厂模式的优点**:\n\n1. 分离了具体的类\n2. 使增加或替换产品族变得容易\n3. 有利于产品的一致性\n\n**抽象工厂模式的缺点**:\n\n难以支持新种类的产品。这是因为AbstractFactory接口确定了可以被创建的产品集合。支持新各类的产品就需要扩展访工厂接口，从而导致AbstractFactory类及其所有子类的改变。\n抽象工厂就是以一种倾斜的方式支持增加新的产品中，它为新产品族的增加提供了方便，而不能为新的产品等级结构的增加提供这样的方便。\n\n- **适用性**\n\n1. 一个系统不应当依赖于产品类实例如何被创建、组合和表达的细节，这对于所有形态的工厂模式都是重要的。\n2. 这个系统的产品有多于一个的产品族，而系统只消费其中某一族的产品。\n3. 同属于同一个产品族的产品是在一起使用的，这一约束必须在系统的设计中体现出来。\n4. 系统提供一个产品类的库，所有的产品以同样的接口出现，从而使用客户端不依赖于实现\n\n- **抽象工厂模式实例**\n\n```php\n\n//抽象工厂\ninterface AnimalFactory {\n\n    public function createCat();\n    public function createDog();\n\n}\n\n//具体工厂\nclass BlackAnimalFactory implements AnimalFactory {\n\n    function createCat(){\n        return new BlackCat();\n    }\n\n    function createDog(){\n        return new BlackDog();\n    }\n}\n\nclass WhiteAnimalFactory implements AnimalFactory {\n\n    function createCat(){\n        return new WhiteCat();\n    }\n\n    function createDog(){\n        return new WhiteDog();\n    }\n}\n\n//抽象产品\ninterface Cat {\n    function Voice();\n}\n\ninterface Dog {\n    function Voice();\n}\n\n//具体产品\nclass BlackCat implements Cat {\n\n    function Voice(){\n        echo '黑猫喵喵喵';\n    }\n}\n\nclass WhiteCat implements Cat {\n\n    function Voice(){\n        echo '白猫喵喵喵';\n    }\n}\n\nclass BlackDog implements Dog {\n\n    function Voice(){\n        echo '黑狗汪汪汪';\n    }\n}\n\nclass WhiteDog implements Dog {\n\n    function Voice(){\n        echo '白狗汪汪汪';\n    }\n}\n\n//客户端\nclass Client {\n\n    public static function main() {\n        self::run(new BlackAnimalFactory());\n        self::run(new WhiteAnimalFactory());\n    }\n\n    public static function run(AnimalFactory $AnimalFactory){\n        $cat = $AnimalFactory->createCat();\n        $cat->Voice();\n\n        $dog = $AnimalFactory->createDog();\n        $dog->Voice();\n    }\n}\nClient::main();\n\n```\n\n# 迭代器模式\n\n- **迭代器模式概念**\n\n>在不需要了解内部实现的前提下，遍历一个聚合对象的内部元素而又不暴露该对象的内部表示。\n\n- **适用场景**\n\n* 访问一个聚合对象的内容而无需暴露它的内部表示\n* 支持对聚合对象的多种遍历\n* 为遍历不同的聚合结构提供一个统一的接口\n\n- **迭代器模式实例**\n\n```php\n\nclass ConcreteIterator implements Iterator{\n\tprivate $position = 0;\n\tprivate $arr;\n\tfunction __construct(array $arr){\n\t\t$this->arr = $arr;\n\t}\n\n\tfunction rewind(){\n\t\t$this->position = 0;\n\t}\n\n\tfunction current(){\n\t\treturn $this->arr[$this->position];\n\t}\n\n\tfunction key(){\n\t\treturn $this->position;\n\t}\n\n\tfunction next(){\n\t\t++$this->position;\n\t}\n\n\tfunction valid(){\n\t\treturn isset($this->arr[$this->position]);\n\t}\n}\n\n$arr = array('xiao hong','xiao ming','xiaohua');\n$concreteIterator = new ConcreteIterator($arr);\nforeach ($concreteIterator as $key => $value) {\n\techo $key.\"=>\".$value.\"\\n\";\n}\n\n```\n\n# 观察者模式\n\n- **观察者模式概念**\n\n>观察者模式（有时又被称为发布（publish）-订阅（Subscribe）模式、模型-视图（View）模式、源-收听者(Listener)模式或从属者模式），在此种模式中，当一个对象状态发生改变时，依赖它的对象全部会收到通知，并自动更新。\n\n- **使用场景**\n\n一个事件发生以后，要执行一连串更新操作，传统编程方法就是在事件的代码之后直接加入处理逻辑，当更新的逻辑增多之后，代码会变得难以维护，这种方式是耦合的，侵入式的，增加新的逻辑需要修改事件主体的代码。观察者模式实现了低耦合非侵入式的通知与更新机制。\n\n- **实现方式**\n\n从根本上说，该模式必须包含两个角色：观察者和被观察对象。观察者和被观察者之间存在“观察”的逻辑关联，当被观察者发生改变的时候，观察者就会观察到这样的变化。\n\n- **观察者模式实例**\n\n```php\n\n//观察者，需要用到观察者模式的类需实现此接口\ninterface Observer\n{\n    function update($event_info = null);\n}\n//被观察者（一个抽象类，方便扩展）\nabstract class Observable{\n    private $observers = array();\n\n    function addObserver(Observer $observer)\n    {\n        $this->observers[] = $observer;\n    }\n\n    function notify()\n    {\n        foreach($this->observers as $observer)\n        {\n            $observer->update();\n        }\n    }\n}\n\nclass ConcreteObservable extends Observable{\n    function trigger()\n    {\n        $this->notify();\n    }\n}\n\nclass Observer1 implements Observer{\n    function update($event_info = null){\n        echo \"action one\";\n    }\n}\n\nclass Observer2 implements Observer{\n    function update($event_info = null){\n        echo \"action two\";\n    }\n}\n\n$event = new ConcreteObservable();\n//添加观察者\n$event->addObserver(new Observer1);\n$event->addObserver(new Observer2);\n$event->trigger();\n\n```\n\n# 数据对象映射(ORM)\n\n- **数据对象映射模式概念**\n\n>将对象和数据存储映射起来，对一个对象的操作会映射为对数据存储的操作\n\n- **数据对象映射模式实例**\n\n```php\nclass User\n{\n    protected $id;\n    protected $data;\n    protected $db;\n    protected $change = false;\n\n    function __construct($id)\n    {\n        $this->db = Factory::getDatabase();\n        $res = $this->db->query(\"select * from user where id = $id limit 1\");\n        $this->data = $res->fetch_assoc();\n        $this->id = $id;\n    }\n\n    function __get($key)\n    {\n        if (isset($this->data[$key]))\n        {\n            return $this->data[$key];\n        }\n    }\n\n    function __set($key, $value)\n    {\n        $this->data[$key] = $value;\n        $this->change = true;\n    }\n\n    function __destruct()\n    {\n        if ($this->change)\n        {\n            foreach ($this->data as $k => $v)\n            {\n                $fields[] = \"$k = '{$v}'\";\n            }\n            $this->db->query(\"update user set \" . implode(', ', $fields) . \"where\n            id = {$this->id} limit 1\");\n        }\n    }\n}\n\n$user = new User(1);\n$user->mobile = '18888888888'；\n$user->name = 'test'；\n```\n\n# 原型模式\n\n- **原型模式概念**\n\n>用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。\n\n-**使用场景**\n\n它主要面对的问题是：“某些结构复杂的对象”的创建工作；由于需求的变化，这些对象经常面临着剧烈的变化，但是他们却拥有比较稳定一致的接口。原型模式适用于大型对象的创建，创建一个大型对象需要很大的开销，如果每次new就会消耗很大，原型模式只需内存拷贝即可\n\n-**主要角色**\n\n1. 抽象原型(Prototype)角色：声明一个克隆自身的接口\n2. 具体原型(Concrete Prototype)角色：实现一个克隆自身的操作\n\n-**原型模式实例**\n\n```php\n  \n//抽象原型\ninterface Prototype {  \n    public function copy();   \n}     \n  \n//具体原型\nclass ConcretePrototype implements Prototype {  \n    private $name;  \n      \n    function __construct($name){  \n        $this->name = $name;  \n    }  \n      \n    function getName(){  \n        return $this->name;  \n    }  \n      \n    function setName($name){  \n        $this->name = $name;  \n    }  \n      \n    //克隆  \n    function copy(){  \n        return clone $this;  \n    }  \n}  \n  \n//客户端  \nclass Client {  \n      \n    public static function main(){  \n          \n        $pro = new ConcretePrototype('test');  \n        $pro2 = $pro->copy();  \n        echo $pro->getName();  \n        echo $pro2->getName();  \n    }   \n}  \n  \nClient::main();  \n\n```\n\n# 代理模式\n\n- **代理模式定义**\n\n>为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用\n\n- **主要角色**\n\n    * 抽象角色：通过接口或抽象类声明真实角色实现的业务方法。\n    * 代理角色：实现抽象角色，是真实角色的代理，通过真实角色的业务逻辑方法来实现抽象方法，并可以附加自己的操作。\n    * 真实角色：实现抽象角色，定义真实角色所要实现的业务逻辑，供代理角色调用。\n\n- **优点**\n\n1. 职责清晰\n2. 代理对象可以在客户端和目标对象之间起到中介的作用，这样起到了中介的作用和保护了目标对象的作用。\n3. 高扩展性\n\n- **代理模式实例**\n\n```php\n//抽象角色\ninterface IGiveGift  \n{  \n    function giveRose();  \n    function giveChocolate();  \n}  \n  \n//真实角色\nclass Follower implements IGiveGift  \n{  \n    private $girlName;  \n  \n    function __construct($name='Girl')  \n    {  \n        $this->girlName=$name;  \n    }  \n  \n    function giveRose()  \n    {  \n        echo \"{$this->girlName}:送你的玫瑰<br/>\";  \n    }  \n  \n    function giveChocolate()  \n    {  \n        echo \"{$this->girlName}:送你的巧克力<br/>\";  \n    }  \n}  \n  \n\n//代理角色\nclass Proxy implements IGiveGift  \n{  \n    private $follower;  \n  \n    function __construct($name='Girl')  \n    {  \n        $this->follower=new Follower($name);  \n    }  \n  \n    function giveRose()  \n    {  \n        $this->follower->giveRose();  \n    }  \n  \n    function giveChocolate()  \n    {  \n        $this->follower->giveChocolate();  \n    }  \n}\n\n$proxy=new Proxy('xxx');  \n$proxy->giveRose();  \n$proxy->giveChocolate();\n\n```\n\n# 注册树模式\n\n- **注册树模式概念**\n\n>注册树模式也叫注册模式或注册器模式。注册树模式将对象实例注册到一棵全局的对象树上，需要的时候从对象树上获取即可。   \n\n- **注册树模式优点**\n\n　　单例模式创建唯一对象的过程本身还有一种判断，即判断对象是否存在，存在则返回对象，不存在则创建对象并返回。 工厂模式更多考虑的是扩展维护的问题。 总的来说，单例模式和工厂模式可以产生更加合理的对象。怎么方便调用这些对象呢？注册树模式是一种不错的选择。不管是通过单例模式还是工厂模式还是二者结合生成的对象，都统统给我插入到注册树上，用某个对象的时候，直接从注册树上获取即可。\n\n- **注册树模式实例**\n\n假如已经存在类Database；\n \n```php\n\nclass Register\n{\n    protected static $objects;\n\n    static function set($alias, $object)\n    {\n        self::$objects[$alias] = $object;\n    }\n\n    static function get($key)\n    {\n        if (!isset(self::$objects[$key]))\n        {\n            return false;\n        }\n        return self::$objects[$key];\n    }\n\n    function _unset($alias)\n    {\n        unset(self::$objects[$alias]);\n    }\n}\n\nclass Factory{\n    static function createDatabase(){\n\t$db = new Database();\n\t//插入到注册树\n\tRegister::set('db1', $db);\n    }\n}\n\n//从注册树里获取\n$db = Register::get('db1');\n\n```\n\n\n# 单例模式\n\n- **单例模式概念**\n\n>一个类有且仅有一个实例，并且自行实例化向整个系统提供\n\n- **单例模式的特点**\n\n1. 一个类在整个应用中只有一个实例\n2. 类必须自行创建这个实例\n3. 必须自行向整个系统提供这个实例\n\n- **单例模式举例**\n\n一个应用中有一个数据库的类Database，如果不用单例模式，每次new都会消耗大量的资源，而且每次打开和关闭数据库连接也会消耗一些资源，如果使用单例模式则不会存在这些问题。\n使用单例模式实现代码：\n\n```php\n\n<?php\n\nclass Database\n{\n    static private $db;\n\n    private function __construct()\n    {\n\n    }\n    \n    static function getInstance()\n    {\n        if (empty(self::$db)) {\n            self::$db = new self;\n            return self::$db;\n        } \n        return self::$db;\n    }\n}\n\n```\n使用方法：\n\n`$db = Database::getInstance();`\n\n\n# state模式\n\n- **概念**\n\n>不同的状态,不同的行为;或者说,每个状态有着相应的行为.\n\n- **使用场景**\n\nState模式在实际使用中比较多,适合\"状态的切换\".因为我们经常会使用`If elseif else` 进行状态切换, 如果针对状态的这样判断切换反复出现,我们就要联想到是否可以采取State模式了.\n\n不只是根据状态,也有根据属性.如果某个对象的属性不同,对象的行为就不一样,这点在数据库系统中出现频率比较高,我们经常会在一个数据表的尾部,加上property属性含义的字段,用以标识记录中一些特殊性质的记录,这种属性的改变(切换)又是随时可能发生的,就有可能要使用State.\n\n**适用性**：\n\n在下面的两情况下均可以使用State模式：\n\n1. 一个对象的行为取决于它的状态，并且必须在运行时刻根据状态改变它的行为。\n2. 一个操作中含有庞大的多分支的条件豫剧，并且这些分支依赖于该对象的状态，这个状态通常用一个或多个枚举常量表示。通常，有多个操作包含这一相同的条件结构，State模式将每一个条件分支放入一个单独的类中。这使得你可以根据对象自身的情况将对象的状态作为一个对象，这一对象可以不依赖于其他对象而独立变化。\n\n- **参与者**\n\n- Context(环境，Person)定义客户感兴趣的类。\n- State(Moodstate)：定义一个接口以封装与Context的一个特定状态相关的行为\n- ConcreteState Subclasses(具体状态子类，如Angry)每一个子类实现一个与Context的状态相关的行为。\n\n他们的协作关系是：\n\n- Context将于状态相关的请求委托给当前的ConcreteState对象处理。\n- Context可将自身作为一个参数传递给处理该请求的状态对象，这使得状态对象在必要的时候可访问Context。\n- Context是客户使用的主要接口，客户可用状态对象来配置一个Context，一旦一个Context配置完毕，他的客户不再需要直接与状态对象打交道。\n- Context或者ConcreteState子类都可以决定哪个状态是另外那个状态的后继者，以及是在何种条件下进行状态转换。\n\n- **如何使用**\n\nState需要两种类型实体参与:\n\n1. state manager 状态管理器 ,就是开关 ,如上面例子的Context实际就是一个state manager, 在state manager中有对状态的切换动作.\n2. 用抽象类或接口实现的父类,,不同状态就是继承这个父类的不同子类.\n\n以上面的Context为例.我们要修改它,建立两个类型的实体.\n第一步: 首先建立一个父类:\n\n```php\n\ninterface MoodState\n{\n    public function doSomething();\n    public function changeState();\n}\n\n```\n\n父类中的方法要对应state manager中的开关行为,在state manager中 本例就是Context中,开关动作为changeState.那么在状态父类中就要有具体处理这个动作:changeState(); 同时还需要一个doSomething();\n\n下面是具体子类的实现:\n\n```php\n\nclass Angry implements MoodState\n{\n    public $p;\n    public function __construct($p)\n    {\n        $this->p = $p;\n    }\n\n    public function doSomething()\n    {\n        echo \"i am angry\\r\\n\";\n    }\n\n    public function changeState()\n    {\n        $this->p->setState(new Happy($this->p));\n    }\n}\n\n```\n\n同样 其他状态的子类实现如Angry一样.\n\n第二步: 要重新改写State manager 也就是本例的Context:\n\n```php\n\nclass Person\n{\n    public function __construct()\n    {\n        $this->state = new Mad($this);\n    }\n\n    public function setState($state)\n    {\n        $this->state = $state;\n    }\n\n    public function doSomething()\n    {\n        $this->state->doSomething();\n        $this->state->changeState();\n    }\n}\n\n```\n\n至此,我们也就实现了State的refactorying过程.\n\n以上只是相当简单的一个实例,在实际应用中,处理是复杂的.\n\n**状态模式优点**：\n\n1. 封装转换过程，也就是转换规则\n2. 枚举可能的状态，因此，需要事先确定状态种类。\n\n>状态模式可以允许客户端改变状态的转换行为，而状态机则是能够自动改变状态，状态机是一个比较独立的而且复杂的机制，具体可参考一个状态机开源项目：[项目地址][1]\n\n状态模式在工作流或游戏等各种系统中有大量使用，甚至是这些系统的核心功能设计，例如政府OA中，一个批文的状态有多种：未办；正在办理；正在批示；正在审核；已经完成等各种状态，使用状态机可以封装这个状态的变化规则，从而达到扩充状态时，不必涉及到状态的使用者。\n\n在网络游戏中，一个游戏活动存在开始；开玩；正在玩；输赢等各种状态，使用状态模式就可以实现游戏状态的总控，而游戏状态决定了游戏的各个方面，使用状态模式可以对整个游戏架构功能实现起到决定的主导作用。\n\n状态模式实质：\n\n**使用状态模式前，客户端外界需要介入改变状态，而状态改变的实现是琐碎或复杂的。**\n\n使用状态模式后，客户端外界可以直接使用事件Event实现，根本不必关心该事件导致如何状态变化，这些是由状态机等内部实现。\n\n这是一种Event-condition-State，状态模式封装了condition-State部分。\n\n每个状态形成一个子类，每个状态只关心它的下一个可能状态，从而无形中形成了状态转换的规则。如果新的状态加入，只涉及它的前一个状态修改和定义。\n\n状态转换有几个方法实现：一个在每个状态实现next()，指定下一个状态；还有一种方法，设定一个StateOwner，在StateOwner设定stateEnter状态进入和stateExit状态退出行为。\n\n状态从一个方面说明了流程，流程是随时间而改变，状态是截取流程某个时间片。\n\n- **实例**\n\n```php\n/**\n * state 设计模式.\n */\ninterface MoodState\n{\n    public function doSomething();\n    public function changeState();\n}\n\nclass Angry implements MoodState\n{\n    public $p;\n    public function __construct($p)\n    {\n        $this->p = $p;\n    }\n\n    public function doSomething()\n    {\n        echo \"i am angry\\r\\n\";\n    }\n\n    public function changeState()\n    {\n        $this->p->setState(new Happy($this->p));\n    }\n}\n\nclass Happy implements MoodState\n{\n    public $p;\n    public function __construct($p)\n    {\n        $this->p = $p;\n    }\n\n    public function doSomething()\n    {\n        echo \"i am Happy\\r\\n\";\n    }\n\n    public function changeState()\n    {\n        $this->p->setState(new Mad($this->p));\n    }\n}\n\nclass Mad implements MoodState\n{\n    public $p;\n    public function __construct($p)\n    {\n        $this->p = $p;\n    }\n\n    public function doSomething()\n    {\n        echo \"i am mad\\r\\n\";\n    }\n\n    public function changeState()\n    {\n        $this->p->setState(new Angry($this->p));\n    }\n}\n\nclass Person\n{\n    public function __construct()\n    {\n        $this->state = new Mad($this);\n    }\n\n    public function setState($state)\n    {\n        $this->state = $state;\n    }\n\n    public function doSomething()\n    {\n        $this->state->doSomething();\n        $this->state->changeState();\n    }\n}\n\nclass client\n{\n    public function __construct()\n    {\n        $p = new Person();\n        for ($i = 0;$i < 10;++$i) {\n            echo \"the $i times:\";\n            $p->doSomething();\n        }\n    }\n}\n\n$c = new Client();\n\n```\n[1]:http://sourceforge.net/projects/smframework/\n\n\n\n# 策略模式\n\n- **策略模式概念**\n\n>策略模式定义了一系列的算法，并将每一个算法封装起来，而且使它们还可以相互替换。策略模式让算法独立于使用它的客户而独立变化。\n\n- **主要角色**\n\n* 抽象策略角色： 策略类，通常由一个接口或者抽象类实现。\n* 具体策略角色：包装了相关的算法和行为。\n* 环境角色：持有一个策略类的引用，最终给客户端调用。\n\n- **应用场景**\n\n1. 多个类只区别在表现行为不同，可以使用Strategy模式，在运行时动态选择具体要执行的行为。\n2. 需要在不同情况下使用不同的策略(算法)，或者策略还可能在未来用其它方式来实现。\n3. 对客户隐藏具体策略(算法)的实现细节，彼此完全独立。\n\n- **优点**\n\n1. 策略模式提供了管理相关的算法族的办法。策略类的等级结构定义了一个算法或行为族。恰当使用继承可以把公共的代码转移到父类里面，从而避免重复的代码。\n2. 策略模式提供了可以替换继承关系的办法。继承可以处理多种算法或行为。如果不是用策略模式，那么使用算法或行为的环境类就可能会有一些子类，每一个子类提供一个不同的算法或行为。但是，这样一来算法或行为的使用者就和算法或行为本身混在一起。决定使用哪一种算法或采取哪一种行为的逻辑就和算法或行为的逻辑混合在一起，从而不可能再独立演化。继承使得动态改变算法或行为变得不可能。\n3. 使用策略模式可以避免使用多重条件转移语句。多重转移语句不易维护，它把采取哪一种算法或采取哪一种行为的逻辑与算法或行为的逻辑混合在一起，统统列在一个多重转移语句里面，比使用继承的办法还要原始和落后。\n\n- **缺点**\n\n 1. 客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择恰当的算法类。换言之，策略模式只适用于客户端知道所有的算法或行为的情况。\n 2. 策略模式造成很多的策略类，每个具体策略类都会产生一个新类。有时候可以通过把依赖于环境的状态保存到客户端里面，而将策略类设计成可共享的，这样策略类实例可以被不同客户端使用。换言之，可以使用享元模式来减少对象的数量。\n\n- **策略模式实例**\n\n```php\n\n/**\n*策略模式\n*定义一系列的算法,把每一个算法封装起来,并且使它们可相互替换。\n*本模式使得算法可独立于使用它的客户变化\n*/\n\n/**\n*出行旅游\n*/\ninterface TravelStrategy{\n    public function travelAlgorithm();\n}\n\n/**\n*具体策略类(ConcreteStrategy)\n*1：乘坐飞机\n*/\nclass AirPlanelStrategy implements TravelStrategy{\n    public function travelAlgorithm(){\n        echo\"travelbyAirPlain\",\"<BR>\\r\\n\";\n    }\n}\n\n/**\n*具体策略类(ConcreteStrategy)\n*2：乘坐火车\n*/\nclass TrainStrategy implements TravelStrategy{\n    public function travelAlgorithm(){\n        echo\"travelbyTrain\",\"<BR>\\r\\n\";\n    }\n}\n/**\n*具体策略类(ConcreteStrategy)\n*3：骑自行车\n*/\nclass BicycleStrategy implements TravelStrategy{\n    public function travelAlgorithm(){\n        echo\"travelbyBicycle\",\"<BR>\\r\\n\";\n    }\n}\n\n/**\n*\n*环境类(Context):\n*用一个ConcreteStrategy对象来配置。\n*维护一个对Strategy对象的引用。可定义一个接口来让Strategy访问它的数据。\n*算法解决类，以提供客户选择使用何种解决方案：\n*/\nclass PersonContext{\n    private$_strategy = null;\n    public function __construct(TravelStrategy $travel){\n        $this->_strategy=$travel;\n    }\n    /**\n    *旅行\n    */\n    public function setTravelStrategy(TravelStrategy $travel){\n        $this->_strategy=$travel;\n    }\n    /**\n    *旅行\n    */\n    public function travel(){\n        return$this->_strategy->travelAlgorithm();\n    }\n\n}\n//乘坐火车旅行\n$person=new PersonContext(new TrainStrategy());\n$person->travel();\n\n//改骑自行车\n$person->setTravelStrategy(new BicycleStrategy());\n$person->travel();\n\n```\n\n","categories":["设计模式"],"tags":["design-pattern"]},{"title":"学习A*寻路算法","url":"/2015-09-29-Astar-algorithm/","content":"# `A*`寻路\n\n## 背景介绍\n\n我们日常生活中的很多决策问题都可以转化为对应的路径规划问题,如何从复杂的路径中寻找两个或者多个点之间的最短距离就是一个很值得研究的东西\n\n`A*`算法是一种寻路算法,解决的是路径规划问题的一种\n\n目的是:\n\n>找出某地图中两点之间的最短路径\n\n## 寻路过程\n\n先来看个地图\n\n    s:起点   e:终点  #:障碍\n    | | | | | | | |          \n    | | | |#| | | |\n    | |s| |#| |e| |\n    | | | |#| | | |\n    | | | | | | | |\n\n现在有这样的需求,我们需要找出s->e的最短路径  \n但是,s和e之间有一堵'墙',就是\"#\"啦  \n这样怎么才能找出最短路径呢?  \n\n第一种做法(Dijkstra算法):\n\n    s:起点   e:终点  *:检索路径 #:障碍\n    |*|*|*| | | | |\n    |*|*|*|#| | | |\n    |*|s|*|#| |e| |\n    |*|*|*|#|*|*| |\n    |*|*|*|*|*| | |\n\n或者我们可以这样做(A*):\n\n    s:起点   e:终点 *:检索路径 #:障碍\n    | | | | | | | |       \n    |*|*|*|#| | | |\n    |*|s|*|#| |e| |\n    |*|*|*|#|*| | |\n    | | |*|*|*| | |\n\n很明显,第二种做法比第一种做法检索的路径要少很多,当然,速度上就要快一些,对一些更复杂的地图,`A*`要比普通广度优先的算法快上许多\n\n例如:\n\n    s:起点  e:终点  *:检索路径  #:障碍\n    | | | | | | | | | | | | | |    \n    | | | | | | | | |e| | | | |    \n    | | | |#|#|#|#|#|#|#| | | |    \n    | | |#| | | | | | | |#| | |    \n    | | |#| | | | | | | |#| | |    \n    | | |#| | | | | | | |#| | |    \n    | | |#| | | | | | | |#| | |    \n    | | | | | | | | | | | | | |\n    | | | | | | |s| | | | | | |\n    | | | | | | | | | | | | | |\n    | | | | | | | | | | | | | |\n\n\n这个地图中从s到e,如果使用普通寻路可能是这样的\n\n    s:起点  e:终点  *:最终路径  #:障碍\n    | | | | | | | | | | | | | |    \n    | | | | | | | | |e|*|*| | |    \n    | | | |#|#|#|#|#|#|#|*|*| |    \n    | | |#| | | |*|*|*|*|#|*| |    \n    | | |#| | | |*| | |*|#|*| |    \n    | | |#| | | |*| | |*|#|*| |    \n    | | |#| | | |*| | |*|#|*| |    \n    | | | | | | |*| | | |*|*| |\n    | | | | | | |s| | | | | | |\n    | | | | | | | | | | | | | |\n    | | | | | | | | | | | | | |\n\n很明显,寻路过程中出现了较多的无用步数,寻路进入了布袋口里面,我们期望的是寻路尽量快速,寻找最短路径,`A*`的做法就比较符合我们的期望\n\n`A*`寻路:\n\n    s:起点  e:终点  *:最终路径 #:障碍\n    | | | | | | | | | | | | | |    \n    | | | | | | | | |e|*|*| | |    \n    | | | |#|#|#|#|#|#|#|*|*| |    \n    | | |#| | | | | | | |#|*| |    \n    | | |#| | | | | | | |#|*| |    \n    | | |#| | | | | | | |#|*| |    \n    | | |#| | | | | | | |#|*| |    \n    | | | | | | |*|*|*|*|*|*| |\n    | | | | | | |s| | | | | | |\n    | | | | | | | | | | | | | |\n    | | | | | | | | | | | | | |\n\n\n## `A*`寻路的主要过程\n\n1. 将起点S加入到开放列表(开放列表中的点都是可用的)\n2. 寻找起点S周围所有可到达的点,并计算F值(最终衡量陆静距离的值),设置这些点的父节点为起点,将这些点加入到一个开放列表\n3. 将起点从开放列表中删除,并添加到关闭列表,从开放列表中选取F值最小的点M(如果有多个最小F值,随机取其一)\n4. 将M从开放列表中删除,并添加到关闭列表,计算M周围可到达的点,重新计算F值,将周围这些点都存入开放列表,设置他们的父节点为M\n5. 如果M周围某个点已经在开放列表中,重新计算F值和G值(已消耗路径),选取新旧G值中最小的点\n6. 最后如果发现终点在开放列表中,终止程序\n\n**`A*`寻路的精髓**\n\n核心公式：**F = G + H**\n\nF:用来评价点距起点距离的值\n\nG:实际已耗费的路径\n\nH:未来还需要耗费的路径\n\n`A*`算法的实质是通过维护一个`待检测点的列表(open list)`和一个`已检测点的列表(closed list)`来记录寻路过程,从图形上来看，OPEN集是已访问区域的边界，CLOSED集是已访问区域的内部。每个节点还包含一个指向父节点的指针，以确定追踪关系。\n\n算法有一个主循环,重复地从OPEN集中取最优节点n(即f值最小的节点)来检测.如果n是目标节点,那么算法结束; \n否则,将节点n从OPEN集删除,并添加到CLOSED集中,然后查看n的所有邻节点n',如果邻节点在CLOSED集,它已被检测过,则无需再检测; \n如果邻节点在OPEN集,它将会被检测,则无需此时检测; \n否则,将该邻节点加入OPEN集,设置其父节点为n,到n'的路径开销`F(n') = G(n) + H(n,n')`\n\n\n## `A*`的变种\n\n`A*`算法可以通过`动态加权`,`跳跃点搜索`,`双向搜索`,`迭代深化`等进行性能和功能的优化\n\n此外还有`动态A*`与`终身规划A*`等变化,这些变化其实都是基于基本的`A*`理论来进行优化\n\n## 寻路算法的应用\n\n比较常见的是寻路算法在游戏中的应用,因为很多游戏中会有地图的概念,涉及到地图就很容易有寻路规划的需要\n\n比如:许多RPG游戏中会有去寻找某个NPC接任务或者去某个地方打败某个BOSS\n\n寻路算法在生活中也有应用,比如 探索和侦查,道路建设,地形分析,城市规划等\n\n总之,深入研究寻路算法是非常有意义的\n\n## 推荐阅读\n\n如果有希望深入了解`A*`的读者,强烈推荐一篇文章,作者写的非常用心,讲的也特别细\n\n地址:[http://theory.stanford.edu/~amitp/GameProgramming/index.html](http://theory.stanford.edu/~amitp/GameProgramming/index.html)\n\n## 代码演示\n\n下面是一个Python实现的`A*寻路`的代码:\n\n```python\n\nclass Node_Elem:\n    #开放列表和关闭列表的元素类型，parent用来在成功的时候回溯路径\n    def __init__(self, parent, x, y, dist):\n        self.parent = parent\n        self.x = x\n        self.y = y\n        self.dist = dist\n\n```\n\n主要程序\n\n```python\n\nclass A_Star:\n\n    #A星算法实现类\n    #注意w,h两个参数，如果你修改了地图，需要传入一个正确值或者修改这里的默认参数\n    def __init__(self, s_x, s_y, e_x, e_y, w=60, h=30):\n        self.s_x = s_x\n        self.s_y = s_y\n        self.e_x = e_x\n        self.e_y = e_y\n\n        self.width = w\n        self.height = h\n\n        self.open = []\n        self.close = []\n        self.path = []\n\n    #查找路径的入口函数\n    def find_path(self):\n        #构建开始节点\n        p = Node_Elem(None, self.s_x, self.s_y, 0.0)\n        while True:\n            #扩展F值最小的节点\n            self.extend_round(p)\n            #如果开放列表为空，则不存在路径，返回\n            if not self.open:\n                return\n            #获取F值最小的节点\n            idx, p = self.get_best()\n            #找到路径，生成路径，返回\n            if self.is_target(p):\n                self.make_path(p)\n                return\n            #把此节点压入关闭列表，并从开放列表里删除\n            self.close.append(p)\n            del self.open[idx]\n\n    def make_path(self,p):\n        #从结束点回溯到开始点，开始点的parent == None\n        while p:\n            self.path.append((p.x, p.y))\n            p = p.parent\n\n    def is_target(self, i):\n        return i.x == self.e_x and i.y == self.e_y\n\n    def get_best(self):\n        best = None\n        #开放列表中最好的值\n        bv = self.width*self.height*10000 #这个值应该大于地图的最大格子数量\n        #开放列表中最好的键\n        bi = -1\n        for idx, i in enumerate(self.open):\n            value = self.get_dist(i)#获取F值\n            if value < bv:#比以前的更好，即F值更小\n                best = i\n                bv = value\n                bi = idx\n        return bi, best\n\n    def get_dist(self, i):\n        # F = G + H\n        # G 为已经走过的路径长度， H为估计还要走多远\n        # 这个公式就是A*算法的精华了。\n        return i.dist + math.sqrt((self.e_x-i.x)*(self.e_x-i.x)+ (self.e_y-i.y)*(self.e_y-i.y))*1.4#这里的1.4为优化数字，可选范围[1.0-1.4],\n\n    def extend_round(self, p):\n        #可以从8个方向走\n        xs = (-1, 0, 1, -1, 1, -1, 0, 1)\n        ys = (-1,-1,-1,  0, 0,  1, 1, 1)\n        #只能走上下左右四个方向\n        #xs = (0, -1, 1, 0)\n        #ys = (-1, 0, 0, 1)\n        for x, y in zip(xs, ys):\n            new_x, new_y = x + p.x, y + p.y\n            #无效或者不可行走区域，则勿略\n            if not self.is_valid_coord(new_x, new_y):\n                continue\n            #构造新的节点\n            node = Node_Elem(p, new_x, new_y, p.dist+self.get_cost(p.x, p.y, new_x, new_y))\n            #新节点在关闭列表，则忽略\n            if self.node_in_close(node):\n                continue\n            i = self.node_in_open(node)\n            if i != -1:\n                #新节点在开放列表\n                if self.open[i].dist > node.dist:\n                    #现在的路径到比以前到这个节点的路径更好~\n                    #则使用现在的路径\n                    self.open[i].parent = p\n                    self.open[i].dist = node.dist\n                continue\n            self.open.append(node)\n\n    def get_cost(self, x1, y1, x2, y2):\n\n        #上下左右直走，代价为1.0，斜走，代价为1.4\n\n        if x1 == x2 or y1 == y2:\n            return 1.0\n        return 1.4\n\n    def node_in_close(self, node):\n        for i in self.close:\n            if node.x == i.x and node.y == i.y:\n                return True\n        return False\n\n    def node_in_open(self, node):\n        for i, n in enumerate(self.open):\n            if node.x == n.x and node.y == n.y:\n                return i\n        return -1\n\n    def is_valid_coord(self, x, y):\n        if x < 0 or x >= self.width or y < 0 or y >= self.height:\n            return False\n        return test_map[y][x] != '#'\n\n    def get_searched(self):\n        l = []\n        for i in self.open:\n            l.append((i.x, i.y))\n        for i in self.close:\n            l.append((i.x, i.y))\n        return l\n\n```\n","categories":["编程学习"],"tags":["A*算法"]},{"title":"学习smallpt全局光照引擎","url":"/2015-09-28-smallpt/","content":"\n# smallpt\n\n今天给大家介绍一个**全局光照引擎**\n\n该程序作者是[kevinbeason](http://www.kevinbeason.com/smallpt/)\n\n代码不长,只要`100`行左右,采用了[Monte Carlo](http://baike.baidu.com/link?url=RQRnSUL-7NapJO695uvrH7FuHTXTB1tixzbM5tC65PS2gNjFhyTdpsrLCP-sBKSbhWWnwULdK3v3mEEjip7Caq)算法\n\n# 图片效果\n\n渲染出来的图片最终效果\n\n![result](result_25k.png)\n\n# 代码动态演示\n\n展示区域就在下边这个`canvas`里面吧(注意:这个非常非常非常消耗性能,慎点)\n\n该程序通过像素采样和作者设定好的对象数值进行渲染\n\n**采样率越高,绘图质量越好,性能消耗越大**\n\n实际采样率达到25000就已经是超级高的质量了,可惜性能...\n\n在作者的网站里面还给出了其他集中场景的数值设定[其他场景数值](http://www.kevinbeason.com/smallpt/extraScenes.txt)\n可以通过修改参数渲染出不同的场景\n\n设置采样率(实际值要*4):&nbsp;<input type=\"number\" min=\"0\" max=\"10000000\" step=\"25\" value=\"25\" id=\"samp\" style=\"border:1px solid #ccc;padding:3px;border-radius:2px;\">&nbsp;&nbsp;&nbsp;<button onclick=\"javascript:eval_render();\" class=\"btn btn-info\">Run</button>\n\n<div style=\"text-align: center\">\n    <canvas id=\"renderCanvas\" width=\"128\" height=\"128\" style=\"display:none\"></canvas>\n    <div id=\"status\"></div>\n</div>\n源代码如下:\n\n```javascript\n\nfunction RandomLCG(seed) {\n    return function() {\n        seed = (214013 * seed + 2531011) % 0x100000000;\n        return seed * (1.0 / 4294967296.0);\n    };\n}\nfunction Vec(x, y, z) { this.x = x; this.y = y; this.z = z; }\nVec.prototype =\n{\n    add: function(b) {\n        return new Vec(this.x + b.x, this.y + b.y, this.z + b.z);\n    },\n    sub: function(b) {\n        return new Vec(this.x - b.x, this.y - b.y, this.z - b.z);\n    },\n    mul: function(b) {\n        return new Vec(this.x * b, this.y * b, this.z * b);\n    },\n    mult: function(b) {\n        return new Vec(this.x * b.x, this.y * b.y, this.z * b.z);\n    },\n    norm: function() {\n        return this.mul(1.0 / Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z));\n    },\n    dot: function(b) {\n        return this.x * b.x + this.y * b.y + this.z * b.z;\n    },\n    cross: function(b) {\n        return new Vec(this.y * b.z - this.z * b.y, this.z * b.x - this.x * b.z, this.x * b.y - this.y * b.x);\n    }\n};\nVec.Zero = new Vec(0, 0, 0)\nVec.XAxis = new Vec(1, 0, 0)\nVec.YAxis = new Vec(0, 1, 0)\nVec.ZAxis = new Vec(0, 0, 1)\n\nRefl = {DIFF: 0,SPEC: 1,REFR: 2};\nfunction Ray(o, d) { this.o = o; this.d = d }\nfunction Sphere(rad, p, e, c, refl) {\n    this.rad = rad;\n    this.p = p;\n    this.e = e;\n    this.c = c;\n    this.refl = refl;\n\n    this.sqRad = rad * rad;\n    this.maxC = Math.max(Math.max(c.x, c.y), c.z);\n    this.cc = c.mul(1.0 / this.maxC);\n}\nSphere.prototype =\n{\n    intersect: function(r) {\n        // Solve t^2*d.d + 2*t*(o-p).d + (o-p).(o-p)-R^2 = 0\n        var op = this.p.sub(r.o);\n        var b = op.dot(r.d);\n        var det = b * b - op.dot(op) + this.sqRad;\n        var eps = 1e-4;\n        if (det < 0)\n            return 0;\n        else {\n            var dets = Math.sqrt(det)\n\n            if (b - dets > eps)\n                return b - dets;\n            else if (b + dets > eps)\n                return b + dets;\n            else\n                return 0;\n        }\n    }\n};\n// Scene: radius, position, emission, color, material\nspheres = [\n    new Sphere(1e5, new Vec(1e5 + 1, 40.8, 81.6), Vec.Zero, new Vec(.75, .25, .25), Refl.DIFF), //Left\n    new Sphere(1e5, new Vec(-1e5 + 99, 40.8, 81.6), Vec.Zero, new Vec(.25, .25, .75), Refl.DIFF), //Rght\n    new Sphere(1e5, new Vec(50, 40.8, 1e5), Vec.Zero, new Vec(.75, .75, .75), Refl.DIFF), //Back\n    new Sphere(1e5, new Vec(50, 40.8, -1e5 + 170), Vec.Zero, Vec.Zero, Refl.DIFF), //Frnt\n    new Sphere(1e5, new Vec(50, 1e5, 81.6), Vec.Zero, new Vec(.75, .75, .75), Refl.DIFF), //Botm\n    new Sphere(1e5, new Vec(50, -1e5 + 81.6, 81.6), Vec.Zero, new Vec(.75, .75, .75), Refl.DIFF), //Top\n    new Sphere(16.5, new Vec(27, 16.5, 47), Vec.Zero, new Vec(1, 1, 1).mul(.999), Refl.SPEC), //Mirr\n    new Sphere(16.5, new Vec(73, 16.5, 78), Vec.Zero, new Vec(1, 1, 1).mul(.999), Refl.REFR), //Glas\n    new Sphere(600, new Vec(50, 681.6 - .27, 81.6), new Vec(12, 12, 12), Vec.Zero, Refl.DIFF)  //Lite\n];\n\nvar rand = RandomLCG(0)\nfunction clamp(x) {\n    if (x < 0)\n        return 0;\n    else if (x > 1)\n        return 1;\n    else\n        return x;\n}\nfunction toInt(x) {\n    return Math.pow(clamp(x), 1 / 2.2) * 255 + .5\n}\n\nfunction intersect(r) {\n    var t = 1e20;\n    var obj;\n\n    for (var i in spheres) {\n        var s = spheres[i];\n        var d = s.intersect(r);\n        if (d != 0 && d < t) {\n            t = d;\n            obj = s;\n        }\n    }\n    return [obj, t];\n}\n\nfunction radiance(r, depth) {\n    var ires = intersect(r);\n    var obj = ires[0];\n    var t = ires[1];   // distance to intersection\n\n    if (obj == null) {\n        return Vec.Zero;       // if miss, return black\n    }\n    else {\n        var newDepth = depth + 1;\n        var isMaxDepth = newDepth > 100;\n\n        // Russian roulette for path termination\n        var isUseRR = newDepth > 5;\n        var isRR = isUseRR && rand() < obj.maxC;\n\n        if (isMaxDepth || (isUseRR && !isRR))\n            return obj.e;\n        else {\n            var f = (isUseRR && isRR) ? obj.cc : obj.c;\n            var x = r.o.add(r.d.mul(t));\n            var n = x.sub(obj.p).norm();\n            var nl = n.dot(r.d) < 0 ? n : n.mul(-1);\n\n            if (obj.refl == Refl.DIFF) // Ideal DIFFUSE reflection\n            {\n                var r1 = 2 * Math.PI * rand();\n                var r2 = rand();\n                var r2s = Math.sqrt(r2);\n\n                var w = nl;\n                var wo = Math.abs(w.x) > .1 ? new Vec(0, 1, 0) : new Vec(1, 0, 0);\n                var u = wo.cross(w).norm();\n                var v = w.cross(u);\n\n                var d = (u.mul(Math.cos(r1) * r2s).add(v.mul(Math.sin(r1) * r2s)).add(w.mul(Math.sqrt(1 - r2)))).norm();\n\n                return obj.e.add(f.mult(radiance(new Ray(x, d), newDepth)));\n            }\n            else if (obj.refl == Refl.SPEC) // Ideal SPECULAR reflection\n            {\n                return obj.e.add(f.mult(radiance(new Ray(x, r.d.sub(n.mul(2 * n.dot(r.d)))), newDepth)));\n            }\n            else // Ideal dielectric REFRACTION\n            {\n                var reflRay = new Ray(x, r.d.sub(n.mul(2 * n.dot(r.d))));\n                var into = n.dot(nl) > 0; // var from outside going in?\n                var nc = 1;\n                var nt = 1.5;\n                var nnt = into ? nc / nt : nt / nc;\n                var ddn = r.d.dot(nl);\n                var cos2t = 1 - nnt * nnt * (1 - ddn * ddn);\n\n                if (cos2t < 0)  // Total internal reflection\n                {\n                    return obj.e.add(f.mult(radiance(reflRay, newDepth)));\n                }\n                else {\n                    var tdir = (r.d.mul(nnt).sub(n.mul((into ? 1 : -1) * (ddn * nnt + Math.sqrt(cos2t))))).norm();\n                    var a = nt - nc;\n                    var b = nt + nc;\n                    var R0 = a * a / (b * b);\n                    var c = 1 - (into ? -ddn : tdir.dot(n));\n                    var Re = R0 + (1 - R0) * c * c * c * c * c;\n                    var Tr = 1 - Re;\n                    var P = .25 + .5 * Re;\n                    var RP = Re / P;\n                    var TP = Tr / (1 - P);\n\n                    var result;\n                    if (newDepth > 2) {\n                        // Russian roulette and splitting for selecting reflection and/or refraction\n                        if (rand() < P)\n                            result = radiance(reflRay, newDepth).mul(RP);\n                        else\n                            result = radiance(new Ray(x, tdir), newDepth).mul(TP);\n                    }\n                    else\n                        result = radiance(reflRay, newDepth).mul(Re).add(radiance(new Ray(x, tdir), newDepth).mul(Tr));\n\n                    return obj.e.add(f.mult(result));\n                }\n            }\n        }\n    }\n}\n\nfunction render(canvas, status) {\n    var start = new Date().getTime();\n    var w = canvas.attributes.width.value;\n    var h = canvas.attributes.height.value;\n    var samps = 25;\n\n    // cam pos, dir\n    var cam = new Ray(new Vec(50, 52, 295.6), new Vec(0, -0.042612, -1).norm());\n    var cx = new Vec(w * .5135 / h, 0, 0);\n    var cy = (cx.cross(cam.d)).norm().mul(.5135);\n\n    // final color buffer\n    var c = new Array(w * h);\n    for (var i = 0; i < w * h; i++)\n        c[i] = Vec.Zero;\n\n    // Output\n    var ctx = canvas.getContext(\"2d\");\n    var imgdata = ctx.getImageData(0, 0, w, h);\n    var pixels = imgdata.data;\n\n    // Loop over image rows\n    var y = 0;\n    setTimeout(renderLine, 0);\n\n    function renderLine()\n    {\n        status.innerHTML = \"Rendering (\" + samps * 4 + \" spp) \" + (100.0 * y / (h - 1)).toFixed(2) + \"%\";\n\n        // Loop cols\n        for (var x = 0; x < w; x++) {\n            // 2x2 subpixel rows\n            for (var sy = 0; sy < 2; sy++) {\n                var i = (h - y - 1) * w + x;\n\n                // 2x2 subpixel cols\n                for (var sx = 0; sx < 2; sx++) {\n                    var r = Vec.Zero;\n                    for (var s = 0; s < samps; s++) {\n                        var r1 = 2 * rand();\n                        var r2 = 2 * rand();\n                        var dx = r1 < 1 ? Math.sqrt(r1) - 1 : 1 - Math.sqrt(2 - r1);\n                        var dy = r2 < 1 ? Math.sqrt(r2) - 1 : 1 - Math.sqrt(2 - r2);\n\n                        var d = cx.mul(((sx + .5 + dx) / 2 + x) / w - .5).add(\n                        cy.mul(((sy + .5 + dy) / 2 + y) / h - .5)).add(cam.d);\n\n                        // Camera rays are pushed forward to start in interior\n                        var camRay = new Ray(cam.o.add(d.mul(140)), d.norm());\n\n                        // Accumuate radiance\n                        r = r.add(radiance(camRay, 0).mul(1.0 / samps));\n                    }\n\n                    // Convert radiance to color\n                    c[i] = c[i].add((new Vec(clamp(r.x), clamp(r.y), clamp(r.z))).mul(.25));\n                }\n            }\n        }\n\n        renderOutput();\n\n        y++;\n        if (y < h)\n            setTimeout(renderLine, 0);\n        else\n            status.innerHTML = (new Date().getTime() - start) / 1000 + \" sec\";\n    }\n\n    function renderOutput() {\n        var i = (h - y - 1) * w * 4, j = (h - y - 1) * w;\n        for (var x = 0; x < w; x++) {\n            pixels[i++] = toInt(c[j].x);\n            pixels[i++] = toInt(c[j].y);\n            pixels[i++] = toInt(c[j].z);\n            pixels[i++] = 255;\n            j++;\n        }\n        ctx.putImageData(imgdata, 0, 0);\n    }\n}\n```\n\n\n\n<script>\nfunction RandomLCG(seed) {\n    return function() {\n        seed = (214013 * seed + 2531011) % 0x100000000;\n        return seed * (1.0 / 4294967296.0);\n    };\n}\n\nfunction Vec(x, y, z) {\n    this.x = x;\n    this.y = y;\n    this.z = z;\n}\n\nVec.prototype = {\n    add: function(b) {\n        return new Vec(this.x + b.x, this.y + b.y, this.z + b.z);\n    },\n\n    sub: function(b) {\n        return new Vec(this.x - b.x, this.y - b.y, this.z - b.z);\n    },\n    \n    mul: function(b) {\n        return new Vec(this.x * b, this.y * b, this.z * b);\n    },\n    \n    mult: function(b) {\n        return new Vec(this.x * b.x, this.y * b.y, this.z * b.z);\n    },\n    \n    norm: function() {\n        return this.mul(1.0 / Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z));\n    },\n    \n    dot: function(b) {\n        return this.x * b.x + this.y * b.y + this.z * b.z;\n    },\n    \n    cross: function(b) {\n        return new Vec(this.y * b.z - this.z * b.y, this.z * b.x - this.x * b.z, this.x * b.y - this.y * b.x);\n    }\n};\n\nVec.Zero = new Vec(0, 0, 0)\nVec.XAxis = new Vec(1, 0, 0)\nVec.YAxis = new Vec(0, 1, 0)\nVec.ZAxis = new Vec(0, 0, 1)\n\nRefl = {\n    DIFF: 0,\n    SPEC: 1,\n    REFR: 2\n};\n\nfunction Ray(o, d) {\n    this.o = o;\n    this.d = d\n}\n\nfunction Sphere(rad, p, e, c, refl) {\n    this.rad = rad;\n    this.p = p;\n    this.e = e;\n    this.c = c;\n    this.refl = refl;\n\n    this.sqRad = rad * rad;\n    this.maxC = Math.max(Math.max(c.x, c.y), c.z);\n    this.cc = c.mul(1.0 / this.maxC);\n}\n\nSphere.prototype = {\n    intersect: function(r) {\n        var op = this.p.sub(r.o);\n        var b = op.dot(r.d);\n        var det = b * b - op.dot(op) + this.sqRad;\n        var eps = 1e-4;\n\n        if (det < 0)\n            return 0;\n        else {\n            var dets = Math.sqrt(det)\n    \n            if (b - dets > eps) {\n                return b - dets;\n            } else if (b + dets > eps) {\n                return b + dets;\n            } else {\n                return 0;\n            }\n        }\n    }\n};\n\nspheres = [\n    new Sphere(1e5, new Vec(1e5 + 1, 40.8, 81.6), Vec.Zero, new Vec(.75, .25, .25), Refl.DIFF),\n    new Sphere(1e5, new Vec(-1e5 + 99, 40.8, 81.6), Vec.Zero, new Vec(.25, .25, .75), Refl.DIFF),\n    new Sphere(1e5, new Vec(50, 40.8, 1e5), Vec.Zero, new Vec(.75, .75, .75), Refl.DIFF),\n    new Sphere(1e5, new Vec(50, 40.8, -1e5 + 170), Vec.Zero, Vec.Zero, Refl.DIFF),\n    new Sphere(1e5, new Vec(50, 1e5, 81.6), Vec.Zero, new Vec(.75, .75, .75), Refl.DIFF),\n    new Sphere(1e5, new Vec(50, -1e5 + 81.6, 81.6), Vec.Zero, new Vec(.75, .75, .75), Refl.DIFF),\n    new Sphere(16.5, new Vec(27, 16.5, 47), Vec.Zero, new Vec(1, 1, 1).mul(.999), Refl.SPEC),\n    new Sphere(16.5, new Vec(73, 16.5, 78), Vec.Zero, new Vec(1, 1, 1).mul(.999), Refl.REFR),\n    new Sphere(600, new Vec(50, 681.6 - .27, 81.6), new Vec(12, 12, 12), Vec.Zero, Refl.DIFF)\n];\n\nvar rand = RandomLCG(0)\n\nfunction clamp(x) {\n    if (x < 0) {\n        return 0;\n    } else if (x > 1) {\n        return 1;\n    } else {\n        return x;\n    }\n}\n\nfunction toInt(x) {\n    return Math.pow(clamp(x), 1 / 2.2) * 255 + .5\n}\n\nfunction intersect(r) {\n    var t = 1e20;\n    var obj;\n\n    for (var i in spheres) {\n        var s = spheres[i];\n        var d = s.intersect(r);\n        if (d != 0 && d < t) {\n            t = d;\n            obj = s;\n        }\n    }\n    return [obj, t];\n}\n\nfunction radiance(r, depth) {\n    var ires = intersect(r);\n    var obj = ires[0];\n    var t = ires[1];\n\n    if (obj == null) {\n        return Vec.Zero;\n    } else {\n        var newDepth = depth + 1;\n        var isMaxDepth = newDepth > 100;\n    \n        var isUseRR = newDepth > 5;\n        var isRR = isUseRR && rand() < obj.maxC;\n    \n        if (isMaxDepth || (isUseRR && !isRR)) {\n            return obj.e;\n        } else {\n            var f = (isUseRR && isRR) ? obj.cc : obj.c;\n            var x = r.o.add(r.d.mul(t));\n            var n = x.sub(obj.p).norm();\n            var nl = n.dot(r.d) < 0 ? n : n.mul(-1);\n    \n            if (obj.refl == Refl.DIFF) {\n                var r1 = 2 * Math.PI * rand();\n                var r2 = rand();\n                var r2s = Math.sqrt(r2);\n    \n                var w = nl;\n                var wo = Math.abs(w.x) > .1 ? new Vec(0, 1, 0) : new Vec(1, 0, 0);\n                var u = wo.cross(w).norm();\n                var v = w.cross(u);\n    \n                var d = (u.mul(Math.cos(r1) * r2s).add(v.mul(Math.sin(r1) * r2s)).add(w.mul(Math.sqrt(1 - r2)))).norm();\n    \n                return obj.e.add(f.mult(radiance(new Ray(x, d), newDepth)));\n            } else if (obj.refl == Refl.SPEC) {\n                return obj.e.add(f.mult(radiance(new Ray(x, r.d.sub(n.mul(2 * n.dot(r.d)))), newDepth)));\n            } else {\n                var reflRay = new Ray(x, r.d.sub(n.mul(2 * n.dot(r.d))));\n                var into = n.dot(nl) > 0;\n                var nc = 1;\n                var nt = 1.5;\n                var nnt = into ? nc / nt : nt / nc;\n                var ddn = r.d.dot(nl);\n                var cos2t = 1 - nnt * nnt * (1 - ddn * ddn);\n    \n                if (cos2t < 0) {\n                    return obj.e.add(f.mult(radiance(reflRay, newDepth)));\n                } else {\n                    var tdir = (r.d.mul(nnt).sub(n.mul((into ? 1 : -1) * (ddn * nnt + Math.sqrt(cos2t))))).norm();\n                    var a = nt - nc;\n                    var b = nt + nc;\n                    var R0 = a * a / (b * b);\n                    var c = 1 - (into ? -ddn : tdir.dot(n));\n                    var Re = R0 + (1 - R0) * c * c * c * c * c;\n                    var Tr = 1 - Re;\n                    var P = .25 + .5 * Re;\n                    var RP = Re / P;\n                    var TP = Tr / (1 - P);\n    \n                    var result;\n                    if (newDepth > 2) {\n    \n                        if (rand() < P) {\n                            result = radiance(reflRay, newDepth).mul(RP);\n                        } else {\n                            result = radiance(new Ray(x, tdir), newDepth).mul(TP);\n                        }\n                    } else {\n                        result = radiance(reflRay, newDepth).mul(Re).add(radiance(new Ray(x, tdir), newDepth).mul(Tr));\n                    }\n    \n                    return obj.e.add(f.mult(result));\n                }\n            }\n        }\n    }\n}\n\nfunction render(canvas, status) {\n    var start = new Date().getTime();\n    var w = canvas.attributes.width.value;\n    var h = canvas.attributes.height.value;\n    var samps = 25;\n\n    var samps = document.getElementById(\"samp\").value;\n    \n    var cam = new Ray(new Vec(50, 52, 295.6), new Vec(0, -0.042612, -1).norm());\n    var cx = new Vec(w * .5135 / h, 0, 0);\n    var cy = (cx.cross(cam.d)).norm().mul(.5135);\n    var c = new Array(w * h);\n    for (var i = 0; i < w * h; i++)\n        c[i] = Vec.Zero;\n    \n    var ctx = canvas.getContext(\"2d\");\n    var imgdata = ctx.getImageData(0, 0, w, h);\n    var pixels = imgdata.data;\n    \n    var y = 0;\n    setTimeout(renderLine, 0);\n    \n    function renderLine() {\n        status.innerHTML = \"Rendering (\" + samps * 4 + \" spp) \" + (100.0 * y / (h - 1)).toFixed(2) + \"%\";\n    \n        for (var x = 0; x < w; x++) {\n            for (var sy = 0; sy < 2; sy++) {\n                var i = (h - y - 1) * w + x;\n    \n                for (var sx = 0; sx < 2; sx++) {\n                    var r = Vec.Zero;\n                    for (var s = 0; s < samps; s++) {\n                        var r1 = 2 * rand();\n                        var r2 = 2 * rand();\n                        var dx = r1 < 1 ? Math.sqrt(r1) - 1 : 1 - Math.sqrt(2 - r1);\n                        var dy = r2 < 1 ? Math.sqrt(r2) - 1 : 1 - Math.sqrt(2 - r2);\n    \n                        var d = cx.mul(((sx + .5 + dx) / 2 + x) / w - .5).add(\n                            cy.mul(((sy + .5 + dy) / 2 + y) / h - .5)).add(cam.d);\n    \n                        var camRay = new Ray(cam.o.add(d.mul(140)), d.norm());\n    \n                        r = r.add(radiance(camRay, 0).mul(1.0 / samps));\n                    }\n    \n                    c[i] = c[i].add((new Vec(clamp(r.x), clamp(r.y), clamp(r.z))).mul(.25));\n                }\n            }\n        }\n    \n        renderOutput();\n    \n        y++;\n        if (y < h) {\n            setTimeout(renderLine, 0);\n        } else {\n            status.innerHTML = (new Date().getTime() - start) / 1000 + \" sec\";\n        }\n    }\n    \n    function renderOutput() {\n        var i = (h - y - 1) * w * 4,\n            j = (h - y - 1) * w;\n        for (var x = 0; x < w; x++) {\n            pixels[i++] = toInt(c[j].x);\n            pixels[i++] = toInt(c[j].y);\n            pixels[i++] = toInt(c[j].z);\n            pixels[i++] = 255;\n            j++;\n        }\n    \n        ctx.putImageData(imgdata, 0, 0);\n    }\n}\n\nfunction eval_render()\n{\n    var canvas = document.getElementById(\"renderCanvas\");\n    var status = document.getElementById(\"status\");\n    canvas.style.display=\"block\";\n    render(canvas,status);\n}\n</script>\n","categories":["编程学习"],"tags":["全局光照"]},{"title":"一个简单的用JS实现的光线追踪效果","url":"/2016-09-27-simple-raytracing/","content":"# 什么是光线追踪\n\n光线追踪是计算机图形领域实现全局光照效果的一种手段\n\n光线追踪由于实现简单,效果优秀,但是效率比较低\n\n所以一直以来大多作为学习之用\n\n<!--more-->\n# 一个简单的光线追踪的例子\n\n点击下方的按钮就可以渲染出一张图片哦,纯渲染出的哦(渲染很消耗性能可能会有少许的等待时间)\n\n## 在线测试\n\n视角坐标:\n\nX:<input type=\"number\" min=\"-100\" max=\"100\" step=\"5\" value=\"0\" id=\"pos_x\" >&nbsp;&nbsp;Y:<input type=\"number\" min=\"-100\" max=\"100\" step=\"5\" value=\"5\" id=\"pos_y\" >&nbsp;&nbsp;Z:<input type=\"number\" min=\"-100\" max=\"100\" step=\"5\" value=\"15\" id=\"pos_z\" >&nbsp;&nbsp;反射次数:&nbsp;&nbsp;<input type=\"number\" min=\"0\" max=\"30\" step=\"1\" value=\"5\" id=\"reflect_times\">&nbsp;&nbsp;<button onclick=\"javascript:render_pic();\" class=\"btn btn-info\">RENDER</button>\n\n<div style=\"text-align: center;\">\n    <canvas id=\"renderCanvas\" width=\"512\" height=\"512\" style=\"display:none\"></canvas>\n</div>\n\n## 代码解释\n\n查看本页的源代码可以查找到源代码\n\n核心的代码就是如下几行\n\n```javascript\nvar canvas = document.getElementById('renderCanvas'); // 获取画布对象\ncanvas.style.display = \"block\";\nvar plane = new Plane(new Vector3(0, 1, 0), 0);   // 基本平面 该平面的法向量为(0,1,0)\nvar sphere1 = new Sphere(new Vector3(-10, 10, -10), 10); //球1 位置(-10,10,-10),半径 10\nvar sphere2 = new Sphere(new Vector3(10, 10, -10), 10);  //球2 位置(10,10,-10),半径 10\nplane.material = new CheckerMaterial(0.1, 0.5);  // 国际象棋棋盘材质\nsphere1.material = new PhongMaterial(Color.red, Color.white, 20, 0.25); //球1 Phong材质\nsphere2.material = new PhongMaterial(Color.blue, Color.white, 20, 0.25);//球2 Phong材质\nrayTraceReflection(\n    canvas,\n    new Union([plane, sphere1, sphere2]),\n    new PerspectiveCamera(new Vector3(0, 5, 15), new Vector3(0, 0, -1), new Vector3(0, 1, 0), 90),\n    5);// 渲染参数,视角位置(0,5,15),视角90度,反射5次\n```\n\n## 光线追踪\n\n本文的例子实际上是一种光线追踪(ray tracing)的实现.\n光线追踪是全局光照(Global Illumination)的其中一中实现方式,该方法原理和实现方法都很简单但需要的计算量比较大,普通游戏无法使用,多用于学习研究性质或离线渲染(offline rendering),游戏中大多用其他技术手段实现类似效果\n\n优点:\n\n1. 效果逼真,实现简单\n2. 自带消隐(消除隐藏面)功能\n3. 有阴影效果\n4. 可以并行\n5. 隐含透视性质\n\n缺点:\n\n1. 光线追踪只能模拟光线的镜面反射(specular)行为,无法很好地模拟漫反射(diffuse)\n2. 容易出现图形走样现象,因为透过两个相邻像素的光线到物体表面的距离会被放大,两像素之间的细节无法表现\n\n## 基本原理\n\n光线追踪的基本原理比较简单,如下图\n\n![原理图](2010032819542028.png)\n\n> 从人眼的位置往屏幕上的每个像素发射光线,如果遇到具有反射性质的表面,继续追踪反射光线,最终根据光线返回的颜色去给像素进行着色\n\n因而可以比较简单的表现,反射,阴影折射等效果,但缺点是计算量较大\n现在也有很多其他方式可以实现全局光照的效果(例如:辐射度算法,光子映射,甚至采用光照贴图模拟)\n\n这里的光线返回的颜色既是改像素点计算得到的颜色,具体计算方法是根据光线在多个物体表面的反射得到\n\n## 渲染深度\n\n渲染深度通俗的讲就是根据某一点距离摄像机的距离渲染出不同的颜色,越远的点颜色越暗,近的点略亮\n\n通过计算模拟眼睛与第一个看到的画面上的点的距离,映射到0-255的区间,进行色彩数值的处理\n\n## 材质\n\n材质是渲染物体所必不可少的一项要素,材质根据自身的光学特性和物理特性决定了光线照射到物体表面某一点所呈现的颜色\n\nPhong光照模型是一种基本的光照模型,可以较为真实的模拟物体表面的某些特性\n\n> 环境光 + 漫反射 + 镜面反射  = Phong反射\n\n实现材质效果需要一定的特征函数配合\n\n材质往往和纹理一起配合出现\n\n## 色彩\n\n色彩本身是个极其庞大的学科,本文用到的色彩只是比较简单\n\n仅仅使用增色系统的三原色(RGB)来做一些基本的颜色模拟\n\n使用简单的三元数(R,G,B)来表示颜色的基本信息\n\n<script>\n\nVector3 = function(x, y, z) {\n    this.x = x;\n    this.y = y;\n    this.z = z;\n};\nVector3.prototype = {\n    copy: function() {\n        return new Vector3(this.x, this.y, this.z);\n    },\n    length: function() {\n        return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z);\n    },\n    sqrLength: function() {\n        return this.x * this.x + this.y * this.y + this.z * this.z;\n    },\n    normalize: function() {\n        var inv = 1 / this.length();\n        return new Vector3(this.x * inv, this.y * inv, this.z * inv);\n    },\n    negate: function() {\n        return new Vector3(-this.x, -this.y, -this.z);\n    },\n    add: function(v) {\n        return new Vector3(this.x + v.x, this.y + v.y, this.z + v.z);\n    },\n    subtract: function(v) {\n        return new Vector3(this.x - v.x, this.y - v.y, this.z - v.z);\n    },\n    multiply: function(f) {\n        return new Vector3(this.x * f, this.y * f, this.z * f);\n    },\n    divide: function(f) {\n        var invf = 1 / f;\n        return new Vector3(this.x * invf, this.y * invf, this.z * invf);\n    },\n    dot: function(v) {\n        return this.x * v.x + this.y * v.y + this.z * v.z;\n    },\n    cross: function(v) {\n        return new Vector3(-this.z * v.y + this.y * v.z, this.z * v.x - this.x * v.z, -this.y * v.x + this.x * v.y);\n    }\n};\n\nVector3.zero = new Vector3(0, 0, 0);\nColor = function(r, g, b) {\n    this.r = r;\n    this.g = g;\n    this.b = b\n};\nColor.prototype = {\n    copy: function() {\n        return new Color(this.r, this.g, this.b);\n    },\n    add: function(c) {\n        return new Color(this.r + c.r, this.g + c.g, this.b + c.b);\n    },\n    multiply: function(s) {\n        return new Color(this.r * s, this.g * s, this.b * s);\n    },\n    modulate: function(c) {\n        return new Color(this.r * c.r, this.g * c.g, this.b * c.b);\n    },\n    saturate: function() {\n        this.r = Math.min(this.r, 1);\n        this.g = Math.min(this.g, 1);\n        this.b = Math.min(this.b, 1);\n    }\n};\n\nColor.black = new Color(0, 0, 0);\nColor.white = new Color(1, 1, 1);\nColor.red = new Color(1, 0, 0);\nColor.green = new Color(0, 1, 0);\nColor.blue = new Color(0, 0, 1);\n\n\nPhongMaterial = function(diffuse, specular, shininess, reflectiveness) {\n    this.diffuse = diffuse;\n    this.specular = specular;\n    this.shininess = shininess;\n    this.reflectiveness = reflectiveness;\n};\nPhongMaterial.prototype = {\n    sample: function(ray, position, normal) {\n        var NdotL = normal.dot(lightDir);\n        var H = (lightDir.subtract(ray.direction)).normalize();\n        var NdotH = normal.dot(H);\n        var diffuseTerm = this.diffuse.multiply(Math.max(NdotL, 0));\n        var specularTerm = this.specular.multiply(Math.pow(Math.max(NdotH, 0), this.shininess));\n        return lightColor.modulate(diffuseTerm.add(specularTerm));\n    }\n};\n\nPerspectiveCamera = function(eye, front, up, fov) {\n    this.eye = eye;\n    this.front = front;\n    this.refUp = up;\n    this.fov = fov;\n};\nPerspectiveCamera.prototype = {\n    initialize: function() {\n        this.right = this.front.cross(this.refUp);\n        this.up = this.right.cross(this.front);\n        this.fovScale = Math.tan(this.fov * 0.5 * Math.PI / 180) * 2;\n    },\n    generateRay: function(x, y) {\n        var r = this.right.multiply((x - 0.5) * this.fovScale);\n        var u = this.up.multiply((y - 0.5) * this.fovScale);\n        return new Ray3(this.eye, this.front.add(r).add(u).normalize());\n    }\n};\n\nPlane = function(normal, d) {\n    this.normal = normal;\n    this.d = d;\n};\nPlane.prototype = {\n    copy: function() {\n        return new plane(this.normal.copy(), this.d);\n    },\n    initialize: function() {\n        this.position = this.normal.multiply(this.d);\n    },\n    intersect: function(ray) {\n        var a = ray.direction.dot(this.normal);\n        if (a >= 0) {\n            return IntersectResult.noHit;\n        }\n        var b = this.normal.dot(ray.origin.subtract(this.position));\n        var result = new IntersectResult();\n        result.geometry = this;\n        result.distance = -b / a;\n        result.position = ray.getPoint(result.distance);\n        result.normal = this.normal;\n        return result;\n    }\n};\n\nSphere = function(center, radius) {\n    this.center = center;\n    this.radius = radius;\n};\nSphere.prototype = {\n    copy: function() {\n        return new Sphere(this.center.copy(), this.radius.copy());\n    },\n    initialize: function() { this.sqrRadius = this.radius * this.radius; },\n    intersect: function(ray) {\n        var v = ray.origin.subtract(this.center);\n        var a0 = v.sqrLength() - this.sqrRadius;\n        var DdotV = ray.direction.dot(v);\n        if (DdotV <= 0) {\n            var discr = DdotV * DdotV - a0;\n            if (discr >= 0) {\n                var result = new IntersectResult();\n                result.geometry = this;\n                result.distance = -DdotV - Math.sqrt(discr);\n                result.position = ray.getPoint(result.distance);\n                result.normal = result.position.subtract(this.center).normalize();\n                return result;\n            }\n        }\n        return IntersectResult.noHit;\n    }\n};\n\nIntersectResult = function() {\n    this.geometry = null;\n    this.distance = 0;\n    this.position = Vector3.zero;\n    this.normal = Vector3.zero;\n};\nIntersectResult.noHit = new IntersectResult();\n\n\nUnion = function(geometries) { this.geometries = geometries; };\nUnion.prototype = {\n    initialize: function() {\n        for (var i in this.geometries)\n            this.geometries[i].initialize();\n    },\n    intersect: function(ray) {\n        var minDistance = Infinity;\n        var minResult = IntersectResult.noHit;\n        for (var i in this.geometries) {\n            var result = this.geometries[i].intersect(ray);\n            if (result.geometry && result.distance < minDistance) {\n                minDistance = result.distance;\n                minResult = result;\n            }\n        }\n        return minResult;\n    }\n};\n\nRay3 = function(origin, direction) {\n    this.origin = origin;\n    this.direction = direction;\n}\nRay3.prototype = {\n    getPoint: function(t) {\n        return this.origin.add(this.direction.multiply(t));\n    }\n};\n\nvar lightDir = new Vector3(1, 1, 1).normalize();\nvar lightColor = Color.white;\n\nCheckerMaterial = function(scale, reflectiveness) {\n    this.scale = scale;\n    this.reflectiveness = reflectiveness;\n};\n\nCheckerMaterial.prototype = {\n    sample: function(ray, position, normal) {\n        return Math.abs((Math.floor(position.x * 0.1) + Math.floor(position.z * this.scale)) % 2) < 1 ? Color.black : Color.white;\n    }\n};\n\nfunction rayTraceRecursive(scene, ray, maxReflect) {\n    var result = scene.intersect(ray);\n\n    if (result.geometry) {\n        var reflectiveness = result.geometry.material.reflectiveness;\n        var color = result.geometry.material.sample(ray, result.position, result.normal);\n        color = color.multiply(1 - reflectiveness);\n\n        if (reflectiveness > 0 && maxReflect > 0) {\n            var r = result.normal.multiply(-2 * result.normal.dot(ray.direction)).add(ray.direction);\n            ray = new Ray3(result.position, r);\n            var reflectedColor = rayTraceRecursive(scene, ray, maxReflect - 1);\n            color = color.add(reflectedColor.multiply(reflectiveness));\n        }\n        return color;\n    } else\n        return Color.black;\n}\n\nfunction rayTraceReflection(canvas, scene, camera, maxReflect) {\n    if (!canvas || !canvas.getContext)\n        return;\n\n    var ctx = canvas.getContext(\"2d\");\n    if (!ctx.getImageData)\n        return;\n\n    var w = canvas.attributes.width.value;\n    var h = canvas.attributes.height.value;\n    ctx.fillStyle = \"rgb(0,0,0)\";\n    ctx.fillRect(0, 0, w, h);\n\n    var imgdata = ctx.getImageData(0, 0, w, h);\n    var pixels = imgdata.data;\n\n    scene.initialize();\n    camera.initialize();\n\n    var i = 0;\n    for (var y = 0; y < h; y++) {\n        var sy = 1 - y / h;\n        for (var x = 0; x < w; x++) {\n            var sx = x / w;\n            var ray = camera.generateRay(sx, sy);\n            var color = rayTraceRecursive(scene, ray, maxReflect);\n            pixels[i++] = color.r * 255;\n            pixels[i++] = color.g * 255;\n            pixels[i++] = color.b * 255;\n            pixels[i++] = 255;\n        }\n    }\n    ctx.putImageData(imgdata, 0, 0);\n}\n\nfunction render_pic(){\n    var canvas = document.getElementById('renderCanvas');\n    canvas.style.display = \"block\";\n    var plane = new Plane(new Vector3(0, 1, 0), 0);\n    var sphere1 = new Sphere(new Vector3(-10, 10, -10), 10);\n    var sphere2 = new Sphere(new Vector3(10, 10, -10), 10);\n    plane.material = new CheckerMaterial(0.1, 0.5);\n    sphere1.material = new PhongMaterial(Color.red, Color.white, 20, 0.25);\n    sphere2.material = new PhongMaterial(Color.blue, Color.white, 20, 0.25);\n    \n    var zx,zy,zz,reflect_times,camera;\n    zx = parseInt(document.getElementById('pos_x').value,10);\n    zy = parseInt(document.getElementById('pos_y').value,10);\n    zz = parseInt(document.getElementById('pos_z').value,10);\n    reflect_times = parseInt(document.getElementById('reflect_times').value,10);\n\n    console.log([zz,zy,zx]);\n\n    camera =  new PerspectiveCamera(new Vector3(zx, zy, zz), new Vector3(0, 0, -1), new Vector3(0, 1, 0), 90);\n\n    rayTraceReflection(\n    canvas,\n    new Union([plane, sphere1, sphere2]),\n    camera,\n    reflect_times);\n}\n\n</script>","categories":["编程学习"],"tags":["raytracing"]},{"title":"别害怕","url":"/2015-09-18-do-not-afraid/","content":"\n**别害怕**\n\n上天很公平\n\n你选择什么，就必定要放弃什么\n\n你得到什么，就必定要舍弃什么\n\n人生的道路上\n\n若要前行，就必须要离开现在停留的地方\n\n若要挥别过去，就必须拥有涅磐重生的勇气\n\n\n就算爱情欺骗了我们\n\n这并非我们绝望的原因\n\n我们还有很多热情\n\n给分开，给荡漾，给爱人，给安寂\n\n\n就算过去刺痛了我们\n\n这并非是我们逃避的原因\n\n我们依然有很多憧憬\n\n对梦想，对记忆，对失败，对希冀\n\n\n就算现实撕裂了我们\n\n这并非是我们茫然的原因\n\n我们依然有很多完整\n\n至少我可以成全我自己\n\n\n不管什么时候 不管身处何地\n\n只要我们还在期待 只要我们还会感觉到寂寞\n\n只要我们还心怀着荡漾 只要我们没有放弃自己\n\n那么我们就没有老去\n\n那么我们至少还拥有青春\n\n四时可爱唯春色 一事能痴便少年\n\n\n趁着千载难逢的机会\n\n去抛弃那些你想要放弃却不敢忘记的过往\n\n去尝试那些你想要尝试而没有做的转变\n\n去迎接那些你虽然忐忑却注定美丽的未来\n","tags":["别害怕"]},{"title":"git简单使用指南","url":"/2015-06-01-simple-git-operation/","content":"\n# git操作基础\n\n推荐一个git官方的GUI客户端:https://desktop.github.com/\n\n## 基本流程\n\n![image](git-process.png)\n\ngit基本命令格式\n\n\tgit 命令 参数\n\n部分名词解释:\n\n\torigin: 本地代码库  (可以自己设置)\n\t\n\tremote: 远端代码库地址\n\t\n\thead: 版本指针\n\t\n\tbranch: 分支\n\nGit的相关配置有两份一份在项目中的`.git`文件价中\n\n一份全局的位于用户目录下的`.git`目录中\n\n项目配置优先于全局配置, 会覆盖掉全局中的配置\n\n## 获取项目\n\n1. 新建仓库\n\n* 对已存在的项目目录使用 `git init`\n\n2. 克隆仓库\n\n* https方式\n\n例如: `git clone  https://git.coding.net/gongchang/gc.buyer.git`\n\t\n该方式推送更新可能需要先设置用户名和密码\n\n* ssh方式(推荐)\n\n例如:`git clone git@git.coding.net:gongchang/gc.buyer.git`\n\t\n该方式获取项目建议先生成ssh-key, 并将ssh-key添加到授权中(github/gitlab等设置中都有添加ssh-key的方法)\n\n对应svn命令 : `svn clone XXXXXX`\n\n### 生成ssh-key \n\n`ssh-keygen -t rsa -C \"youremail@example.com\"` \n\n使用ssh生成ssh-key\n\n生成的ssh-key位于用户目录下的.ssh目录中, 一共有两个一个公钥, 一个私钥\n\n将`xxx.pub`中的公钥copy到git服务器中,再检查用户名和密码,就可以用ssh登录git了\n\t \n3. 获取更新\n\n```bash\ngit pull origin master   //origin代表当前版本库,master是远端分支名,如果要更新dev分支就是 git pull origin dev \n\n或者简化版\n\ngit pull  //这种方式有时候默认拉下来的不是master分支,需要自己手动切换一下\n```\n此命令等同`git fetch`+ `git merge`, 对应svn命令:`svn update`\n\n## 提交代码\n\n1. 暂存区\n\n修改完代码以后需要将修改添加到暂存区 \n\n```bash\ngit add .                 //.代表当前目录\n如果要添加当前目录下的 1.txt文件,相应的命令就是\ngit add 1.txt\n```\n\n未添加到暂存区的修改可以用`git checkout` 撤销,对应svn命令 `svn revert -R .`\n\n```bash\ngit checkout .    //.代表当前目录\n```\n\n2. 提交\n\n```bash\ngit commit -m \"测试提交\"  //\"测试提交\"是对本次提交的描述\n```\n\n3. 推送\n\n```bash\ngit push origin master   //origin 当前版本库  master远端分支名\n \ngit push origin dev      //往dev分支上推送代码\n```\n\n下面三条命令 相当于 svn的一条命令  `svn commit -m \"测试\"`\n\n```bash\ngit add .\ngit commit -m \"测试\"\ngit push origin master\n```\n## 分支操作\n\n1.  查看当前分支, *号所在就是你当前分支\n```bash\ngit branch\n```\n2.  新建分支\n\n新建分支dev_test,假设当前在dev分支\n\n命令:`git checkout -b dev_test`或`git branch dev_test`\n\n对应svn命令 :`svn copy dev dev_test `\n\n3.  切换分支\n\n命令:\n\n```bash\ngit checkout dev_test   //切换到dev_test分支\n```\n3.  合并dev_test到dev\n\n当前所在分支为dev,命令:\n\n```bash\ngit merge origin/dev_test\n```\n\n4. 删除分支\n\n```bash\ngit branch -d dev_test\n```\n\n## 解决冲突\n\n1. 处理冲突\n\n下面是冲突代码的显示形式,表明两个代码库此处代码不一致,需要手动解决冲突\n```php\n<<<<<<< HEAD\ntest1\n=======\ntest2\n>>>>>>> \n```\n将代码手动修改为\n\n```bash\ntest2\n```\n然后执行 1. `git add .` 2.`git commit -m \"解决冲突\"`    3.`git push origin master`\n\n## 其他\n\n1. 查看日志   `git log` \n2. 查看状态   `git status`\n3. 查看修改   `git diff`\n4. `git log --pretty=oneline 文件名` 可以查看某文件的修改记录\n\n## 高级操作\n\n* 场景1: 如果觉得Git的提交记录太多太乱,想清理git的提交记录,变得整洁\n\n`git rebase ` \n\n重新设定分支,十分少用,把当前提交定位到某次提交之后\n\n* 场景2: 有时候部分修改已经提交,但后来发现这个功能不用上线了,你当然可以手动切换一个新分支, 但是也可以使用另一个命令将当前分支设置为之前的某一个版本\n\n`git reset `\n\n放弃所有未推送的提交\n\n* 场景3: 线上某个版本上线之后出了问题,需要紧急会退到上一个正常的版本\n\n`git revert`\n\n版本回退,可用于撤销已推送的错误提交\n\n*ps: `git reset HEAD` 然后`git push -f`这样也能达到撤销错误提交的作用,但是如果在你错误提交之后,有同学进行了新提交,这个新提交也会被撤销*\n\n* 场景4: 你正在A分支上面开发新功能,此时有个紧急bug需要你处理\n\n可以使用`git stash`暂存起来, 切换到其他分支上去开发功能, 开发完毕切换回来, 用 `git stash apply`恢复之前的修改\n\n`git stash list`:列出储藏列表\n\n`git stash drop`: 删除一个储藏\n\n`git stash apply stash@{2}`: 应用储藏\n\n`git stash pop`: 应用最新的一个储藏\n\n`git stash clear`: 清理所有储藏\n\n`git stash branch testchanges`: 从储藏中创建分支","categories":["工具使用"],"tags":["git"]},{"title":"学习游戏程序设计","url":"/2015-05-05-game-design/","content":"# E\n\n这篇文章是写给编程初学者和完全不懂编程的\b小白的, 目的是希望能通过这篇文章, 让大家知道一下子大概是怎么工作的，游戏中的画面是怎么显示出来的和游戏程序的大概结构\n\n这个游戏是我在准备毕业设计时候遇到的，当时好奇就花了点时间研究了一下\n\n## 游戏地址\n\n先上游戏地址: [https://github.com/oldj/html5-tower-defense](https://github.com/oldj/html5-tower-defense)\n\n我们拿这个游戏来举例子进行分析\n\n## 背景\n\n之前我自己做五子棋的游戏的时候,在网上找别人做过的小游戏做参考, 无意中发现了这个小游戏\n\n期间发现这个游戏虽然很小, 但是设计还是很有意思的, 于是就顺便结合这个小游戏做一点游戏设计层面的分析\n\n介绍一下一款游戏大概的工作流程\n\n## 游戏分析\n\n### 游戏的形式\n\n几乎市面上所有常见游戏都是通过\n\n```c\n给玩家展示一些画面 -> 然后获取到玩家的反馈动作 -> 对游戏画面进行更新, 显示游戏画面 -> 获取玩家反馈动作 ...\n```\n\n这么一个循环来的, 所谓的玩游戏的过程也就是游戏通过设备(键盘, 鼠标, 屏幕触控, 话筒)等形式获取到玩家反馈数据对游戏进行更新, 不断重复该过程, 直到达到游戏结束条件为止\n\n### 游戏画面的显示\n\n我们看到的游戏的画面, 不管多酷炫, 归根到底可以看做一系列的连续播放的图片, 而每张图片我们又可以看做是一个固定分辨率的色彩数组\n\n拿 1080*1920 分辨率, 60fps 的某一款游戏来说, 就是1s中给你播放60张1080p的图片给你看\n\n那到底播放什么图片呢 ?\n\n图片的内容可以看成是一个 `1080(宽) * 1920(长) * 4(RGBA) `的数组, 只要把这个数组发送给显卡, 显卡就知道应该怎么显示, (为什么要用一维数组是因为基于性能考虑，一位数组的处理效率比高维数组要高)\n\n游戏渲染的过程, 可以看做是根据用户反馈计算这一些列数组的过程\n\n### 游戏的通用结构\n\n从结构上说, 任何游戏, 实质上都是一个不断循环的程序, 当画面的处理和输出速度达到人眼视觉暂留的极限时(一般在30fps以上)\n\n人就分不出来是不是真的实时了, 以此来模拟实时的效果, 早期的胶片电影使用的也是类似的原理\n\n任何游戏理论上都可以套用以下过程, 使用伪代码描述:\n\n```c\nload( config );              // 加载游戏配置\nwhile( game_is_running() ) { // 游戏是否继续进行\n    get_user_input(); \t     // 接受用户的输入\n    do_something();  \t       // 根据用户输入处理数据处理\n    check_stop();\t\t         // 查看是否满足结束条件\n    render();\t\t\t           // 渲染页面,渲染一次就是fps\n}\n\n```\n\n游戏的实质就是根据与用户交互, 不断的修改参数对页面进行渲染, 再接受用户输入, 这整个循环称为游戏的主循环\n\n下面我将对一个简单的小塔防游戏进行分析, 来说明一下一个简单游戏的内部组成和功能实现\n\n# TF游戏\n\n>ps: TF只是一个游戏名字 \n\n## 游戏地址\n\n游戏地址: [https://github.com/oldj/html5-tower-defense](https://github.com/oldj/html5-tower-defense)\n\n## TF中的主循环做的事情\n\ntf既然也是一个游戏自然就遵循上面所说的基本规则,\n\ntf游戏中的主要过程如下\n\n1. 响应用户的点击事件\n2. 根据用户的输入和触发的事件,更新游戏对象数据\n3. 然后根据对象进行渲染\n4. 判断游戏输赢(是否达到结束条件)\n\n## TF游戏中的各种子系统\n\ntf游戏虽小,但是却也是一个比较完善的游戏, 内部也是有许多的子系统构成\n\n### 基本对象系统\n\n对象系统是tf的基础, 游戏中的所有会运动的怪物, 炮塔, 甚至包括文字, 按钮 都是对象系统的成员\n\n但是,这些对象又具有一定的层级关系\n\n游戏中的所有对象可以根据继承关系形成一个树状结构\n\n之所以要建立对象系统是为了更好地以面向对象的形式来构建游戏\n\n这种开发方式有助于降低开发难度\n\n基本的对象系统是承载游戏数据的主要对象\n\n各种游戏参数基本都表现为各种对象的各种属性\n\n对象系统对上层的渲染系统提供渲染参数, 可以通过渲染系统把当前游戏运行状态可视化的显示出来\n\n### 事件系统\n\n事件系统是用户和游戏系统进行交互的窗口, 用户的所有操作都作为事件的形式被游戏所捕获\n\n事件系统的功能主要是:收集用户的输入,提供事件来触发对数据的处理,实时的更新对象的数据\n\n事件系统是控制游戏进程和与用户交互的重要通道\n\n事件系统在游戏中起到触发器的作用, 告诉游戏中的对象,什么时候用户做了什么事情,你们需要做些什么\n\n一般来说事件系统会用一个具有优先级的队列来实现\n\n### 渲染引擎\n\ntf中的渲染系统主要负责根据对象参数渲染对象的UI效果\n\n画面中看到的小怪物,子弹, 文字, 建筑都是渲染系统来负责\n\n因为tf中没有用到图片,所有怪物和防御设施都是使用canvas绘制出来的, tf中的渲染系统承担的工作要更重一些\n\n渲染系统是游戏的核心功能之一\n\n渲染程序的运行依赖于当前游戏中的各种对象和参数状态\n\n用户的某种动作触发了事件之后,对应的对象的参数和状态会进行重新计算\n\n新的对象需要有渲染引擎来进行绘图和显示\n\n渲染系统是游戏内部状态的展示窗口, 核心功能是讲当前游戏内部状态以友好的方式呈现给用户\n\n### 物理引擎\n\n物理引擎在游戏中主要充当工具箱的作用, 属于渲染系统中的基础组件\n\n主要的功能像`寻路算法`, `碰撞检测`等都属于物理引擎的范畴\n\n物理引擎可以赋予对象真实世界物体的各种效果\n\n负责计算渲染系统需要的各种描述状态的参数数据\n\n物理引擎是我们衡量一个游戏等级的重要依据\n\n目前还没有游戏能实现完整的模拟现实世界的物理引擎\n\n更加复杂的化学引擎也目前没人能实现\n\n理想的游戏引擎是能按照现实世界的各种粒子特性\n\n原子级的模拟整个现实世界,但是这在未来数百年显然是不可能的\n\n### 音频/视频系统\n\n其他大型游戏一般还有会有音频和视频系统来增强用户的游戏体验\n\n不过这个游戏并没有包含这一部分\n\n### 资源系统\n\n大型游戏中的`音频`,`视频`,`文件`,`内存`,`I/0设备`等资源都需要进行管理\n\n一般会自己实现一套资源管理机制","categories":["编程学习"],"tags":["游戏"]},{"title":"霹雳布袋戏语录","url":"/2015-01-23-pili-words/","content":"我看布袋戏很久了,一直以来都很佩服布袋戏的编剧 (编剧号称\"十车书\", 其实是一个编剧组, 很多人一起进行编剧，每个人只负责一部分)\n\n因为我不仅仅看剧情, 同时还会去琢磨剧里面人物怎么处理问题怎么解决矛盾 \n\n我还曾试图学习素还真的为人处世方式 😂 (然而很明显, 素老奸的境界我是肯定模仿不来的)\n\n一个人的性格和行为习惯哪是那么容易就能改变的啊, 没有那份阅历, 就做不到那样的境界\n\n不过这不妨碍我喜欢里面的一些观点和台词\n\n**下面收集了一些看布袋戏里面, 我觉得不错的台词**\n---\n\n1. 不懂幽默的人，总是拿着幽默当成盾牌，为自己的尖锐与伤害言语包装，强迫他人要为自己的流血的伤口大笑。你不能强迫别人接受肤浅的玩笑来当成幽默\n\n2. 很多时候，事情不能以对错来论，而是要用更温柔的心来表达自己的坚持与想法，如此一来，才不会伤人伤己。这世上，就是有太多自认为没错的人，将似是而非的道理当成了伤害他人的利器，站在道理高点的人，不代表他就是有依循道理的人\n\n3. 得意时谦卑，失意时纵容，向现实低头，是为自己下一次抬头做准备\n\n4. 宁可心在江湖言江湖，不可身在江湖厌江湖。\n\n5. 过去点滴都是圆满生命的一种过程，不管是遗憾或是悲伤，都要升华成为面对未来的一种智慧\n\n6. 非黑即白的想法，有时是苦了自己，更会伤害他人\n\n7. 不懂不代表没有，不说不代表不在意。人会为了想保护自己、朋友而选择沉默或是据理力争，甚至是蒙骗，这都是人性之一\n\n8. 缄默沉静者大用有余，轻薄浮躁者小用不足；以浮躁为才则必坏事，以沉静为拙则必失人\n\n9. 遇横逆之来而不怒，遭变故之起而不惊，当非常之谤而不辩，可以任大事矣。\n\n10. 不必言而言，是谓多言，多言招尤；不当言而言，是谓盲言，盲言贾祸。\n\n11. 善良是一种美德，因为懦弱的不敢伤害别人，自卑的恐惧被人伤害，所以将施舍称为同情将暴露弱点叫作信任。\n\n12. 信用，是将自己利益无条件交给他人掌控，弱者遵守信用，因为他们必须依靠一套名叫道德的规则存活，敢背信的人，是拥有对方不敢报复的自信。\n\n13. 人啊，总是节制著自己当下的想法，总是期盼著下一秒、下一天、下一年，或者下辈子，所以才会错过机会。\n\n14. 你的生命对吾有何意义，为什么你为别人而死，吾却要感到你伟大，因为弱者多而强者少，所以弱者洗脑强者，强者阿，赶紧替我们牺牲，这样我们会永远记得你，等你死了，我们会继续吃好睡饱，有空时替你上一炷香。\n\n15. 这世上蠢人多，而聪明人少，多数表决其实是让多数蠢辈决定蠢事。\n\n16. 礼仪，是上者逼使下者更加屈服的心理枷锁，因为违背礼仪将招致祸害，所以让下者对上者，更加敬畏\n\n17. 当维持比重建更费心力时，就有人用历史与传统当作阻挡进步的藉口，如果百年是历史，那九十九年就不是了?认清吧，不过就是拆掉的危楼而已。\n\n18. 当你报不了仇的时候，你只能选择原谅。\n\n19. 爱是什么?明明是需求与依赖，却被包装成纯粹无理由的伟大情操。吾配合这世间的荒谬，做出最忠诚的表现。\n\n20. 无知与自信永远是结果论，胜利就是自信，失败就是无知。\n\n21. 企望所谓的报应，只不过是一种廉价的美丽幻想，用来宽慰自己的愤怒以及掩饰自己的无能\n\n22. 多虚伪的言语，压抑心中的恐惧，说出自欺欺人的词句，谎言、哪有什么善意与恶意，本身都是因为无法承担后果而欺骗。\n\n23. 代价?所以你口中所谓的忏悔，就是让对方得到满足，无论是心灵或者物质上的满足，那?就叫利益交换。事后的弥补不能改变已发生的事实，宽恕是因为诚意，或者是换到足够的利益，甚至是被强加的恩惠逼得让步。\n\n24. 怜悯是什么?因为期望被人帮助，所以订下了帮助别人的规则。恻隐是什么?是恐惧这样被人对待，所以伸出援手，潜藏在人心深处的美德，真相是这个世间最大最丑陋的利益勾结。\n\n25. 理念不同便是魔，作风不同便是外道，这世上的人阿，因为不敢标新立异，所以苟同于别人的价值，这样的活著，何等的卑微。\n\n26. 佛修者广布慈悲，渡化魔邪，或者，渡化不成大义捐躯，魔阿，总是成就佛之功德，所有留传万世，可歌可泣的事迹，皆有魔之踪迹。\n\n27. 信仰，是一种排除异己的方式，就因为佛渡不了，所以将魔驱逐，这就是你所信奉的教义。\n\n28. 错谬啊，是他们被一种名叫道德的东西压抑了本性，因为一但违背了道德，就会被一股更强的群众力量制裁，所以压抑了自身的贪婪、欲望，更可悲是，他们被这股力量压得喘不过气之后却自愿成为这股力量的帮凶，再将仁义道德束缚在其他人的身上。看看这个世间，看看自己，多少东西是自己想要却是不敢去取，只因道德两字。吾，只是比天下间所有的人更透澈明嘹而已。\n\n29. 诸像心生，佛心见佛，魔心见魔，你们说我是魔，你们，心魔已生。\n\n30. 「忠、孝、节、义」就是作奴才的方式；忠是对君主作奴才；孝是对父母作奴才；节是对婚姻作奴才；义是对同侪作奴才，不是吗？\n","categories":["日常记录"],"tags":["霹雳布袋戏"]}]